[{"authors":null,"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461110400,"objectID":"ef97a961da13acaf8e4ef83cfbc1881a","permalink":"/code/projects/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/code/projects/","section":"code","summary":"","tags":null,"title":"**Code**","type":"code"},{"authors":null,"categories":null,"content":" here -- Undergraduate  Beginning Spanish Elementary Spanish Intermediate Spanish Introduction to the study of language Introduction to Spanish Phonetics and Phonology Introduction to Spanish Phonetics and Phonology for the Heritage Speaker Culture and composition for Heritage Speakers Introduction to Hispanic Linguistics Current Issues in Second Language Acquisition History of the Spanish Language Applied Linguistics High Beginner Spanish in Context (Middlebury College)  Graduate  Spanish phonetics/phonology The phonetics/phonology of bilingualism Data science for linguists Research methods: Open science and reproducible research in Linguistics  Workshops  Spanish pronunciation workshop for beginners Using PsychoPy2 for linguistic research Introduction to Praat Introduction to R LaTeX for linguists  ","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461110400,"objectID":"f14fa52f45a615a62ab3c101e6157df1","permalink":"/teaching/teaching/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/teaching/teaching/","section":"teaching","summary":" here -- Undergraduate  Beginning Spanish Elementary Spanish Intermediate Spanish Introduction to the study of language Introduction to Spanish Phonetics and Phonology Introduction to Spanish Phonetics and Phonology for the Heritage Speaker Culture and composition for Heritage Speakers Introduction to Hispanic Linguistics Current Issues in Second Language Acquisition History of the Spanish Language Applied Linguistics High Beginner Spanish in Context (Middlebury College)  Graduate  Spanish phonetics/phonology The phonetics/phonology of bilingualism Data science for linguists Research methods: Open science and reproducible research in Linguistics  Workshops  Spanish pronunciation workshop for beginners Using PsychoPy2 for linguistic research Introduction to Praat Introduction to R LaTeX for linguists  ","tags":null,"title":"**Teaching**","type":"teaching"},{"authors":null,"categories":null,"content":"","date":1540598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540598400,"objectID":"5b74c6c3b91c89f596c1ac317ae249b5","permalink":"/talk/future-talk/","publishdate":"2018-10-27T00:00:00Z","relpermalink":"/talk/future-talk/","section":"talk","summary":"","tags":null,"title":"Syllabic Affiliation of Prevocalic Glides in Sonoran Spanish: Dialectal variation in syllabic affiliation","type":"talk"},{"authors":null,"categories":null,"content":"","date":1540512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540512000,"objectID":"3c6fa38580d0785853424bc8a7f14b4e","permalink":"/talk/next-talk/","publishdate":"2018-10-26T00:00:00Z","relpermalink":"/talk/next-talk/","section":"talk","summary":"","tags":null,"title":"The use of lexical stress and vowel duration for morphological anticipation in L2 learners of Spanish","type":"talk"},{"authors":null,"categories":["Linguistics"],"content":" Packaging         Previous   Next    Assembly             Previous   Next    Aftermath       Previous   Next    Walkthrough     Previous   Next   \n ","date":1537150394,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537150394,"objectID":"105313a86e542c03fd6ea855add1c34c","permalink":"/post/2018-09-16_setting_up_a_whisper_room_sound_booth/","publishdate":"2018-09-16T21:13:14-05:00","relpermalink":"/post/2018-09-16_setting_up_a_whisper_room_sound_booth/","section":"post","summary":" Packaging         Previous   Next    Assembly             Previous   Next    Aftermath       Previous   Next    Walkthrough     Previous   Next   \n ","tags":["Linguistics","Phonetics","Equipment","Whisper room","Sound booth"],"title":"Setting up a whisper room sound booth","type":"post"},{"authors":["JV Casillas","M Simonet"],"categories":null,"content":"","date":1532044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532044800,"objectID":"850d97d12c519d4db5e8e85aca8156b8","permalink":"/publication/casillas_simonet_jphon_2018/","publishdate":"2018-07-20T00:00:00Z","relpermalink":"/publication/casillas_simonet_jphon_2018/","section":"publication","summary":"In the present study, Spanish-English bilinguals’ perceptual boundaries between voiced and voiceless stops (a /b/-/p/ continuum including pre-voiced, voiceless unaspirated, and voiceless aspirated tokens) are shown to be modulated by whether participants are “led to believe” they are classifying Spanish or English sounds. In Experiment 1, simultaneous Spanish-English bilinguals and beginner second-language learners of Spanish labeled the same acoustic continuum in two experimental sessions (Spanish mode, English mode), and both groups were found to display language-specific perceptual boundaries (or session effects). In Experiment 2, early bilinguals and late second-language learners of various levels of proficiency participated in a single session in which, in random order, they labeled nonwords that were designed to prime either Spanish or English language modes. Early bilinguals and relatively proficient second-language learners, but not less proficient learners, displayed mode-specific perceptual normalization criteria even in conditions of rapid, random mode switching. Along with similar ones, the experiments reported here demonstrate that bilinguals are able to exploit language-specific perceptual processes (or norms) when processing speech sounds, which entails some degree of separation between their sound systems.","tags":null,"title":"Perceptual categorization and bilingual language modes: Assessing the double phonemic boundary in early and late bilinguals","type":"publication"},{"authors":["N Sagarra","JV Casillas"],"categories":null,"content":"","date":1532044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532044800,"objectID":"5ee10b126d6474272314299dbc5aff3a","permalink":"/publication/sagarra_casillas_jsl_2018/","publishdate":"2018-07-20T00:00:00Z","relpermalink":"/publication/sagarra_casillas_jsl_2018/","section":"publication","summary":"We use visual-world eye-tracking and gating methods to investigate whether Spanish monolinguals and English late learners of Spanish use prosodic cues (lexical stress) to anticipate morphological information (suffixes) during spoken word recognition, and if they do, whether L2 proficiency and working memory (WM) mediate their anticipatory abilities. Our findings show that the monolinguals used prosodic information to predict word endings in both tasks, regardless of first-syllable stress (stressed, unstressed) and structure (CV, CVC). In contrast, the beginning learners did not use prosodic information to anticipate word suffixes in any task or condition. Importantly, the advanced learners mirrored the monolinguals, except in words with first-syllable CV structure, but were slower than the monolinguals. Finally, WM was not associated with anticipatory eye movements, though results were inconclusive for offline processing. Taken together, the present study shows that suprasegmental information facilitates morphological anticipation during spoken word recognition, and that adult learners can gain anticipatory processing patterns qualitatively, but not quantitatively, similar to monolinguals.","tags":null,"title":"Suprasegmental information cues morphological anticipation during L1/L2 lexical access","type":"publication"},{"authors":null,"categories":["Linguistics"],"content":" TL; DR  In the remixed version of the song “despacito”, Justin Bieber sings in Spanish. Some articles online criticize his pronunciation. I analyzed his realization of “p” and “t” in Praat and find that, while his pronunciation is not perfect, it is pretty good. I don’t believe he commits the “errors” suggested in the article.\n Overview I recently heard the song despacito featuring teen hero Justin Bieber (my wife mentioned to me that he sings in Spanish and my curiosity got the best of me). I distinctly remember being rather impressed by how well he sang in Spanish, so I was surprised when I saw this article pop up in my facebook feed. Basically, J Balvin and Nicky Jam (I have no idea who these guys are) make fun of J Biebs accent. Specifically, they harp on his pronunciation of the title of the song, suggesting the /t/ in the diminutive form of “despacio” (slow) is realized as [ɹ]. In fact, they sing it a few times [des.pa.si.ɹo] (des-pa-see-row, if you aren’t familiar with IPA) and, in jest, claim at one point that he sings ‘dorito’ [ðo.ɹi.ɾo]. You can watch this specific part here:\n   \nNow, this type of non-native pronunciation actually makes a lot of sense, at least I think the ‘dorito’ comment does. In American and Canadian English an intervocalic “t” (and “d”) is usually pronounced as a flap, which in essence corresponds with Spanish “r” in the same position (note: it has to be in the same position, otherwise it would pronounced as a trill). This leads to all kinds of difficulties for learners of Spanish because they have to avoid a phonological process of their native language. For example, a common mispronunciation of the Spanish word “todo” (all) is [to.ɾo], which actually means “toro” (bull). That is, English speakers (mis)pronounce the intervocalic /d/ as a flap, which is most perceptually similar to Spanish “r”. On the other hand, when they try to pronounce “toro”, the “r” is realized as the English rhotic [ɹ].\nThus, if Bieber were pronouncing /ito/ as most native English speakers do, as a flap, it would be perceived as a Spanish “r” (the flap, not the trill). However, there is no real explanation for why he would pronounce it with an English rhotic ([ɹ]) as J Balvin and Nicky Jam claim. I personally did not hear this pronunciation, so I assume they were just teasing the teenage heart throb. Nonetheless, I noticed a lot of comments in the article were also making fun of his pronunciation, so I decided I would take a look in praat to determine if I am going crazy or if the internet is just full of haters. Here is an example of what we will look at:\n Your browser does not support the audio element.   \n The analysis I downloaded the music video from youtube and converted the .mp4 file to .m4a, and then to .wav. In praat I converted the .wav from stereo to mono. Justin sings the chorus as well as some of the verses. I’m just going to look at the chorus because the verses are accompanied by Daddy Yankee and/or Luis Fonsi. Luckily, pretty much every time he says “despacito” in the chorus there is silence, so we can use that for our analysis. I am going to focus on how he pronounces the stop /t/ (though I did get formant frequency measurements for all the vowels… maybe for another post). This only leaves us with about 5 useful tokens, but there are also a good amount of /p/’s that we can compare them with. Here is arguably the best token:\n It’s clear—at least to me—that Justin is not producing an English rhotic where he should be producing [t]. In other words, he is not saying des-pa-see-row. How do I know? Well, if we zoom in on the final /ito/, we notice two things: 1) there is clearly a closure and 2) there is a burst. These are characteristics of a stop consonant. Now, you might be thinking “Yeah, but a flap looks pretty similar in a spectrogram” and you wouldn’t be wrong, but the clear difference here is that after the release there is a short gap before the voicing of the final /o/. This short gap is called voice-onset time (VOT). Stops have VOT; flaps do not. Here is a close up:\n Now a characteristic of English voiceless stops (“p”, “t”, “k”) is that in word initial position they are produced with aspiration and have long-lag VOT, usually around 60 ms. We refer to them with IPA with: [ph, th, kh]. Voiceless stops are different in Spanish, as they are not aspirated and have short-lag VOT, usually from 0 to 25 ms. The “ito” of “despacito” is word internal, thus, in theory, for an English speaker it should not be aspirated because it is normally realized as a flap, though in emphatic speech it could be realized as [th]. Hopefully I have already convinced you that Biebs is not flapping. So our next question is: what kind of VOT do his stops have? If they are short-lag, we can conclude that they are more Spanish-like. If, on the other hand, they are aspirated, then they would be more English-like. So let’s take a look!\nI measured VOT of every p and t every time Justin sings “despacito”. First, let’s load some packages we will need.\nlibrary(lingStuff); library(tidyverse) Now we can load the data and check the structure.\n# Load data bieber_vot \u0026lt;- read_csv(\u0026quot;./data/despacito.csv\u0026quot;) # Check structure of dataframe bieber_vot %\u0026gt;% select(., prefix, votP, votT) %\u0026gt;% gather(., key = phon, value = vot, -prefix) %\u0026gt;% str(.) ## Classes \u0026#39;tbl_df\u0026#39;, \u0026#39;tbl\u0026#39; and \u0026#39;data.frame\u0026#39;: 10 obs. of 3 variables: ## $ prefix: chr \u0026quot;despacito\u0026quot; \u0026quot;despacito1\u0026quot; \u0026quot;despacito2\u0026quot; \u0026quot;despacito3\u0026quot; ... ## $ phon : chr \u0026quot;votP\u0026quot; \u0026quot;votP\u0026quot; \u0026quot;votP\u0026quot; \u0026quot;votP\u0026quot; ... ## $ vot : num 23.3 19.2 19 19.4 15.6 ... Looks good. Let’s plot the VOT of the p’s and t’s and see how they look. I’ve set the x-limit to range from 0 to 60.\n# Plot vot as a function of phon bieber_vot %\u0026gt;% select(., prefix, votP, votT) %\u0026gt;% gather(., key = phon, value = vot, -prefix) %\u0026gt;% ggplot(., aes(x = phon, y = vot, color = phon)) + stat_summary(fun.data = \u0026#39;mean_cl_boot\u0026#39;, geom = \u0026#39;pointrange\u0026#39;, size = 1.1) + stat_summary(fun.y = \u0026#39;mean\u0026#39;, geom = \u0026#39;point\u0026#39;, color = \u0026#39;darkred\u0026#39;, size = 2.75) + ylim(0, 60) + ylab(\u0026quot;VOT (ms)\u0026quot;) + xlab(\u0026quot;\u0026quot;) + scale_x_discrete(labels = c(\u0026#39;/p/\u0026#39;, \u0026#39;/t/\u0026#39;)) + coord_flip() + scale_color_brewer(name = \u0026#39;\u0026#39;, guide = F) + theme_dark(base_size = 22, base_family = \u0026quot;Times\u0026quot;) Recall that an English-like VOT would be around 60 ms (but could range from around 40 to over 100!). We can see that the p’s have a VOT of approximately 20 ms (19.29 ms +/- 2.72 sd, to be exact), and the t’s have a VOT of around 25 ms (23.1 ms +/- 7.39 sd). Both are certainly within range of native Spanish pronunciations.\nInterim conclusion: the internet is full of haters.\n\n Not so fast… There is one last thing to keep in mind before we give JBiebs a pass on his Spanish and it’s an important one. Spanish /t/ and English /t/ are articulated at different places in the mouth. Specifically, Spanish /t/ is dental and English /t/ is alveolar. What this means is that when an English speaker pronounces a word with a “t” in Spanish, like ‘despacito’, she also needs to change the place of articulation, i.e. the tongue needs to make contact with the back of the top teeth, and not the hard ridge right above them. When we looked at VOT in the present analysis we didn’t take this difference into account. My personal opinion is that el señorito does a pretty good job, but if you listen closely to the very last ‘despacito’ in the song, it does sound rather alveolar, i.e. gringo-y.\nConclusion: the internet is full of haters.\nblue { color: #0000CC; font-weight: normal; font-size: 20px; } grey { color: #515151; font-size: 22px; font-weight: normal; } .video-container { position: relative; padding-bottom: 50%; padding-top: 35px; height: 0; overflow: hidden; width: 70%; } .video-container iframe { position: center; top:0; left: 0; width: 100%; height: 100%; }   ","date":1494900794,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494900794,"objectID":"b47d53bd413495f2cbaa47cd3d2068c8","permalink":"/post/2017-05-15_analysis_of_justin_bieber_singing_in_spanish_-_despacito/","publishdate":"2017-05-15T21:13:14-05:00","relpermalink":"/post/2017-05-15_analysis_of_justin_bieber_singing_in_spanish_-_despacito/","section":"post","summary":"TL; DR  In the remixed version of the song “despacito”, Justin Bieber sings in Spanish. Some articles online criticize his pronunciation. I analyzed his realization of “p” and “t” in Praat and find that, while his pronunciation is not perfect, it is pretty good. I don’t believe he commits the “errors” suggested in the article.\n Overview I recently heard the song despacito featuring teen hero Justin Bieber (my wife mentioned to me that he sings in Spanish and my curiosity got the best of me).","tags":["Linguistics","Bieber","Spanish","Phonetics","VOT"],"title":"Justin Bieber sings in Spanish: How'd he do?","type":"post"},{"authors":null,"categories":null,"content":"","date":1492041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492041600,"objectID":"52ae5bf3cfef24aa4a349edb797cdcf2","permalink":"/talk/previous-talk/","publishdate":"2017-04-13T00:00:00Z","relpermalink":"/talk/previous-talk/","section":"talk","summary":"","tags":null,"title":"Technology for teaching: Using Praat to teach L2 pronunciation","type":"talk"},{"authors":["M Llompart","JV Casillas"],"categories":null,"content":"","date":1462060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462060800,"objectID":"f86b84ebbba6d3920879cb36afd21893","permalink":"/publication/llompart_casillas_jasa_2016/","publishdate":"2016-05-01T00:00:00Z","relpermalink":"/publication/llompart_casillas_jasa_2016/","section":"publication","summary":"Limited exposure to ambiguous auditory stimuli results in perceptual recalibration. When unambiguous stimuli are used instead, selective adaptation (SA) effects have been reported, even after few adaptor presentations. Crucially, selective adaptation by an ambiguous sound in biasing lexical contexts had previously been found only after massive adaptor repetition [Samuel (2001). Psychol. Sci. 12(4), 348–351]. The present study shows that extensive exposure is not necessary for lexically driven selective adaptation to occur. Lexically driven selective adaptation can arise after as few as nine adaptor presentations. Additionally, build-up course inspection reveals several parallelisms with the time course observed for SA with unambiguous stimuli.","tags":null,"title":"Lexically driven selective adaptation by ambiguous auditory stimuli occurs after limited exposure to adaptors","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"754fef88cda6050caafa443125ec46f6","permalink":"/project/shiny_bivariate_regression/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/shiny_bivariate_regression/","section":"project","summary":"A shiny web app built in R for teaching the linear model.","tags":["r","statistics","programming","teaching"],"title":"Bivariate linear regression","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"97815a836a5eb2a99ab442edca112d8f","permalink":"/project/shiny_clt/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/shiny_clt/","section":"project","summary":"A shiny web app built in R for teaching the central limit theorem.","tags":["r","statistics","programming","teaching"],"title":"Central limit theorem","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"17085d1b64c36c295107bdd88ec9f35f","permalink":"/project/shiny_crossover/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/shiny_crossover/","section":"project","summary":"A shiny web app built in R for calculating boundary crossover points in logistic regression.","tags":["r","statistics","programming","linguistics","teaching"],"title":"Crossover","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"2b7970afee0cbe1b3570c7d071161374","permalink":"/project/shiny_glm/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/shiny_glm/","section":"project","summary":"A shiny web app built in R for teaching the generalized linear model.","tags":["r","statistics","programming","teaching"],"title":"Generalized linear model","type":"project"},{"authors":null,"categories":null,"content":"    \nI made this repository to simplify the process of using IPA in $\\LaTeX$. It is merely a collection of snippets for the package TIPA. To install LaTeX-IPA see the package control page.\nFile naming Consonants are labeled in the following way:\n voicing -\u0026gt; point of articulation -\u0026gt; mode of articulation\nEx. voiceless-bilabial-aprox.sublime-snippet = [\u0026beta;]  Vowels are labeled in the following way:\n vowel -\u0026gt; tense/lax -\u0026gt; height -\u0026gt; frontedness -\u0026gt; rounding\nEx. vowel-tense-high-front-unrounded.sublime-snippet = [i]  Tab triggers There are 6 main groups:\n Diacritics: type \u0026ldquo;diac\u0026rdquo; + tab\n Vowels: type \u0026ldquo;vowel\u0026rdquo; + tab\n  Consonants are divided into four subcategories:\n Fricatives type \u0026ldquo;fric\u0026rdquo; + tab\n Affricates type \u0026ldquo;affr\u0026rdquo; + tab\n Liquids: type \u0026ldquo;liquid\u0026rdquo; + tab\n Nasals: type \u0026ldquo;nasal\u0026rdquo; + tab  Notes As of now (10/19/2013), I have only included the symbols that I use the most in English and Spanish. I will continue adding to the repository over time. It should be noted that the consonants do not include all categories (i.e. stops). This is because they are not represented by unsual symbols in IPA.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"ba1b868a060aaee9b663abaccec5e065","permalink":"/project/latex_ipa/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/latex_ipa/","section":"project","summary":"A collection of snippets for SublimeText that simplify the process of using IPA in LaTeX.","tags":["latex","ipa","sublimetext","linguistics"],"title":"LaTeX IPA","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c5c04f8530ff5c419593c85cf63b1561","permalink":"/project/shiny_power/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/shiny_power/","section":"project","summary":"A shiny web app built in R for teaching statistical power and sample sizes.","tags":["r","statistics","programming","teaching"],"title":"Power/Sample size calculator","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"7668cfd3f370daa9fe40b2a05687cd2b","permalink":"/project/r_for_linguists/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/r_for_linguists/","section":"project","summary":"A shiny web app built in R for teaching R using the tidyverse.","tags":["r","statistics","programming","teaching"],"title":"R for linguists","type":"project"},{"authors":null,"categories":null,"content":"   \nThis repository is a collection of snippets that I use in SublimeText for doing statistical analysis in R. The goal is straightforward: document the code that I use most often while doing linguistic research and make it readily available (and understandable) to other linguists. If you are interested in helping see the github repository. To install R-snippets see the package control page. To use a snippet, type the trigger and hit the tab key. For example, typing lm brings up the following window:\nSelecting Random slope and random intercept model expands to\u0026hellip;\n# load lme4 for mixed models library(lme4) # random intercept and random slope model modelName = lmer(DV ~ fixedFactor1 +* fixedFactor2 + (1 + randomSlope|randomInt), data=df) modelName hist(residuals(modelName)) qqnorm(residuals(modelName)) qqline(residuals(modelName))  Main triggers:\n \u0026ldquo;plot\u0026rdquo;: templates for plotting in base R \u0026ldquo;edit\u0026rdquo;: options useful for data cleansing and saving \u0026ldquo;desc\u0026rdquo;: descriptive statistics of data \u0026ldquo;ttest\u0026rdquo;: distinct types of t-test \u0026ldquo;aov\u0026rdquo;: distinct analysis of variance models \u0026ldquo;lm\u0026rdquo;: linear and logistic regression \u0026ldquo;lmem\u0026rdquo;: linear mixed effects models  Extras:\n \u0026ldquo;subset\u0026rdquo;: make subsets of a DF \u0026ldquo;read\u0026rdquo;: read/load/install data/packages into R \u0026ldquo;save\u0026rdquo;: save plots, dfs, tables, etc. \u0026ldquo;tikz\u0026rdquo;: template for creating R plots in LaTeX  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"fba3d21e1767e92b420d35f1565934a9","permalink":"/project/r_snippets/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/r_snippets/","section":"project","summary":"A collection of snippets that I use in SublimeText for doing statistical analysis in R","tags":["r","sublimetext","snippets","workflow"],"title":"R-Snippets","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"af7bb9299e90249d6037f3fc0dd3e142","permalink":"/project/shiny_distinctivefeatures/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/shiny_distinctivefeatures/","section":"project","summary":"A shiny web app built in R for teaching the distinctive features of Spanish speech sounds.","tags":["r","programming","linguistics","teaching"],"title":"Spanish allophones and distinctive features","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"24432bdb305febafcffa3134cff7d70b","permalink":"/project/lingstuff/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/lingstuff/","section":"project","summary":"An R package with handy functions I use in my linguistic research.","tags":["r","statistics","programming","linguistics"],"title":"lingStuff","type":"project"},{"authors":null,"categories":null,"content":"  Follow @lingreference !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?\u0026lsquo;http\u0026rsquo;:\u0026lsquo;https\u0026rsquo;;if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+\u0026rsquo;://platform.twitter.com/widgets.js\u0026rsquo;;fjs.parentNode.insertBefore(js,fjs);}}(document, \u0026lsquo;script\u0026rsquo;, \u0026lsquo;twitter-wjs\u0026rsquo;);\n\nUnder development. Created specifically for linguistic terminology, the lingreference.org database currently contains approx. 0,000 terms, phrases and abbreviations. This dictionary is in no way intended to be exhaustive, but rather is a technical resource specializing in the fields of phonetics, phonology, syntax, and sociolinguistics. The terms included were compiled over the past several years during graduate coursework, as well as taken from journal articles, and books.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"dee3af102cd9ca7789a613a64f4d345a","permalink":"/project/lingreference/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/lingreference/","section":"project","summary":"An online, crowd-sourced dictionary specializing in the fields of phonetics, phonology, syntax, and sociolinguistics.","tags":["dictionary","lingreference"],"title":"lingreference.org","type":"project"},{"authors":["JV Casillas","M Simonet"],"categories":null,"content":"","date":1443657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1443657600,"objectID":"a2ec06e034ec17c9cb9211a42cd88fd1","permalink":"/publication/casillas_simonet_slr_2016/","publishdate":"2015-10-01T00:00:00Z","relpermalink":"/publication/casillas_simonet_slr_2016/","section":"publication","summary":"This study investigates how fluent second-language (L2) learners of English produce and perceive the /æ/–/ɑ/ vowel contrast of Southwestern American English. Two learner groups are examined: (1) early, proficient English speakers who were raised by Spanish-speaking families but who became dominant in English during childhood and, as adults, lack communicative abilities in Spanish, and (2) Spanish-speaking late learners of English who continue to be dominant in Spanish. The participants provided data in three tasks: one production and two perceptual. The study finds that both learner groups differ from native controls in their production and perception of the /æ/–/ɑ/ contrast. The findings shed light on our understanding of the relative effects of age (at onset of language exposure) and language dominance (at time of testing) by showing that sequential bilingualism impacts phonetic behavior even when speakers have become dominant in the target language.","tags":null,"title":"Production and perception of the English /æ/-/ɑ/ contrast in switched-dominance speakers","type":"publication"},{"authors":null,"categories":["R"],"content":" ","date":1435025594,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435025594,"objectID":"b5c7283134c48f76b6ced63a98564c7b","permalink":"/post/2015-06-22_tidyr_tutorial/","publishdate":"2015-06-22T21:13:14-05:00","relpermalink":"/post/2015-06-22_tidyr_tutorial/","section":"post","summary":"Tutorial showing the functionality of the tidyr package for data munging.","tags":["R","tidyverse","tidyr","tidy data","data cleaning"],"title":"tidyr tutorial","type":"post"},{"authors":null,"categories":["R"],"content":" Google Forms offers a convenient way to collect data online. It is particularly useful because you can embed the form in a webpage, link the results with a spreadsheet and publish the results online. This post shows how to scrape the data from the spreadsheet (google form) in r using the package RCurl. You should be able to follow along by copying and pasting the code into an R session.\nIdeally you can use this method once you have collected data using a google form. For our purposes I just created a google sheet and I will scrape the data from there.\nGet some data To show how this works, I simulated some data with the following code:\n# create fake data # to save in google sheet set.seed(1) df \u0026lt;- data.frame( subj = 1:30, group = gl(2, 15, labels = c(\u0026quot;mono\u0026quot;, \u0026quot;bi\u0026quot;)), score = c(rnorm(15, 87, 8), rnorm(15, 94, 3)) ) I then copy and pasted the data frame into a google sheet. To do this, open google drive and create a new sheet.\nOnce you have some data in a sheet you need to do a few things before you are ready to fire up R.\nFirst, you need to publish your sheet to the web (File \u0026gt; Publish to the web…):\nPublish the sheet and copy the public link from the window.\nAs you can see, my link is:\nhttps://docs.google.com/spreadsheets/d/1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM/pubhtml Copy your link and save it somewhere. We will need it in just a second.\nNow we’re ready for R. Here are the packages I used:\n# load libraries library(dplyr); library(tidyr); library(RCurl) library(ggplot2); library(DT); library(pander)  Scrape We will use the RCurl package to scrape the data. The command we need is getForm(). The first arguement represents the URI to which the form is posted. You can just use the one shown below for a google sheet. The important part here is the key arguement. You need to copy it from the link you saved above. The key can be found in the last part of the link. Here is my link again:\nhttps://docs.google.com/spreadsheets/d/1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM/pubhtml Specifically we want:\n1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM Therefore we can delete https://docs.google.com/spreadsheets/d/ from the beginning, as well as /pubhtml from the end. Check the key arguement below. Finally, we use the read.csv() command to import the data.\n# scrape data sheet = getForm(\u0026quot;https://spreadsheets.google.com/spreadsheet/pub\u0026quot;, hl =\u0026quot;en_US\u0026quot;, key = \u0026quot;1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM\u0026quot;, output = \u0026quot;csv\u0026quot;, .opts = list(followlocation = TRUE, verbose = TRUE, ssl.verifypeer = FALSE)) df \u0026lt;- read.csv(textConnection(sheet)) Let’s see if it worked…\npandoc.table(df, style = \u0026quot;rmarkdown\u0026quot;, round = 2)   subj group score    1 mono 81.99  2 mono 88.47  3 mono 80.31  4 mono 99.76  5 mono 89.64  6 mono 80.44  7 mono 90.9  8 mono 92.91  9 mono 91.61  10 mono 84.56  11 mono 99.09  12 mono 90.12  13 mono 82.03  14 mono 69.28  15 mono 96  16 bi 93.87  17 bi 93.95  18 bi 96.83  19 bi 96.46  20 bi 95.78  21 bi 96.76  22 bi 96.35  23 bi 94.22  24 bi 88.03  25 bi 95.86  26 bi 93.83  27 bi 93.53  28 bi 89.59  29 bi 92.57  30 bi 95.25    Looks good. Now we can visualize and analyze the data.\ndf %\u0026gt;% ggplot(., aes(x = as.numeric(group), y = score)) + scale_x_discrete(limits = c(2, 1), labels = c(\u0026quot;Bilingual\u0026quot;, \u0026quot;Monolingual\u0026quot;)) + geom_jitter() + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) + labs(x = \u0026quot;Group\u0026quot;, y = \u0026quot;Score\u0026quot;) And that’s it.\n ","date":1434507194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1434507194,"objectID":"f78b96a78d487d1dc788934ec0bc99e4","permalink":"/post/2015-06-16_google_sheets_in_r/","publishdate":"2015-06-16T21:13:14-05:00","relpermalink":"/post/2015-06-16_google_sheets_in_r/","section":"post","summary":"Google Forms offers a convenient way to collect data online. It is particularly useful because you can embed the form in a webpage, link the results with a spreadsheet and publish the results online. This post shows how to scrape the data from the spreadsheet (google form) in r using the package RCurl. You should be able to follow along by copying and pasting the code into an R session.","tags":["R","webscraping","google sheets"],"title":"How to scrape data from Google Sheets in R","type":"post"},{"authors":null,"categories":["R"],"content":" Overview So you thought up a clever experiment, got IRB approval, recruited participants and collected data… now what? New researchers are often confronted with an unfortunate surprise when it comes time to perform some kind of analysis on their data: they don’t know how, or even where to start. This can be a problem for something trivial, like obtaining simple descriptive statistics, or something much more complex, like fitting models, creating plots and making predictions. When we conduct experiments we don’t usually begin by thinking about how we will analyze our data, and in many academic programs this is not explicitly taught to new students. For most people, especially beginners, the data analysis issue arises later on in the process, usually after the data have already been collected (although I think this ultimately changes with experience).\nIn light of all of this, I think that something handy to learn and evaluate early on is how data analysis typically flows: from obtaining data to obtaining new insight from the data. This is the data analysis pipeline, which usually looks something like this:\nIn essence, the process is simple. After collecting your data, you need to tidy it (step 2) so that it can be loaded and analyzed by your statistical software. After tidying your data, you usually have to transform it (step 3) in some way (also called data preprocessing). This can be occur via the creation of new variables, combining variables, sub-setting variables, etc. Once you have transformed your data, it’s time to visualize it (step 4a) via graphs/plots, and, finally, analyze it. The visualization and analysis steps are often iterative: you might notice something in a graph that leads you to a new analysis, or some kind of insight that requires more data transformation and a new analysis, and so on and so forth until you have obtained new insight and are able to answer your research question(s).\nSo, at the heart of data analysis is tidy data. Most new researchers don’t know what it means to tidy and transform their data, nor that it is probably the most important part of any data analysis. Basically, if your data are not formatted in a way in which they can be easily analyzed (via excel, SPSS, R, etc.), then you can’t do anything with them.\nIn order to facilitate the data analysis pipeline, it is crucial to have tidy data. What this means is that every column in your data frame represents a variable and every row represents an observation. This is also referred to as long format (as opposed to wide format). Most statistical software requires your data to be in long format, with few exceptions (i.e. repeated measures ANOVA in SPSS).\nIn what follows, I take you through three packages that have been created in order to facilitate the data analysis pipeline in R. Each package was created by Hadley Wickham with steps 2, 3, and 4a of the pipeline in mind. Thus we can associate each package with the corresponding step:\n tidyr dplyr basic plotting in r / ggvis  (coming soon)\n ","date":1432001594,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1432001594,"objectID":"5e9668527d98e1ef9d9a98be003eee44","permalink":"/post/2015-05-18_data_pipelines/","publishdate":"2015-05-18T21:13:14-05:00","relpermalink":"/post/2015-05-18_data_pipelines/","section":"post","summary":"Overview So you thought up a clever experiment, got IRB approval, recruited participants and collected data… now what? New researchers are often confronted with an unfortunate surprise when it comes time to perform some kind of analysis on their data: they don’t know how, or even where to start. This can be a problem for something trivial, like obtaining simple descriptive statistics, or something much more complex, like fitting models, creating plots and making predictions.","tags":["R","workflow"],"title":"Data pipelines in R","type":"post"},{"authors":["JV Casillas"],"categories":null,"content":"","date":1430438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430438400,"objectID":"3ac329f8dd91ae4ca67843bae1d3d83f","permalink":"/publication/casillas_phonetica_2015/","publishdate":"2015-05-01T00:00:00Z","relpermalink":"/publication/casillas_phonetica_2015/","section":"publication","summary":"The present study explored the production and perception of the /i/-/ɪ/ vowel contrast in second language (L2)-dominant early learners of American English who no longer fluently speak their first language (L1, Spanish). The production task analyzed the extent to which the early learner group differed from controls (native English speakers and L1-Spanish late-onset learners of English) with regard to duration and spectral centroids. The perception experiment examined how these early learners classified resynthesized stimuli drawn from the /i/-/ɪ/ con- trast using distinct acoustic cues – spectral and temporal – in a 2-alternative forced choice identification task. The first experiment revealed that the early learners produced the contrast in a native-like manner in terms of the spectral envelope and duration use. The second experiment found that early learners differed from both control groups in how they categorized the /i/-/ɪ/ continua based on spectrum and duration, and the extent to which they rely on these two cues. The effects of linguistic experience on L2 phonetic behavior are discussed.","tags":null,"title":"Production and perception of the /i/-/ɪ/ vowel contrast: The case of L2-dominant early learners of English","type":"publication"},{"authors":null,"categories":["R"],"content":" ","date":1429582394,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1429582394,"objectID":"16ae477f2362f8b705c1bdc618f8e5d7","permalink":"/post/2015-04-20_plotting_in_r/","publishdate":"2015-04-20T21:13:14-05:00","relpermalink":"/post/2015-04-20_plotting_in_r/","section":"post","summary":"Step-by-step examples for using the three main plotting systems in R.","tags":["R","data viz","base","lattice","ggplot2"],"title":"Basic plotting in R","type":"post"},{"authors":null,"categories":["R"],"content":" ","date":1428977594,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1428977594,"objectID":"be32b1a416da2a488bb053025af9a081","permalink":"/post/2015-04-13_html_widgets/","publishdate":"2015-04-13T21:13:14-05:00","relpermalink":"/post/2015-04-13_html_widgets/","section":"post","summary":"Walkthrough for incorporating HTML widgets into an Rmarkdown document.","tags":["R","html widgets","R markdown"],"title":"HTML widgets in Rmarkdown","type":"post"},{"authors":null,"categories":["R"],"content":" ","date":1427076794,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427076794,"objectID":"25fde71b83848ea57577c718fb32464d","permalink":"/post/2015-03-22_slidify_tutorial/","publishdate":"2015-03-22T21:13:14-05:00","relpermalink":"/post/2015-03-22_slidify_tutorial/","section":"post","summary":"Tutorial for creating HTML presentations using R and slidify.","tags":["R","slidify","presentation software"],"title":"Slidify tutorial","type":"post"},{"authors":null,"categories":["R"],"content":" In this post I’m going to show you how to use TikzDevice to create high quality plots that use the same font as your LaTeX document. I’m assuming that you have already installed tikz. If not, see part I in this series. Moreover, this tutorial assumes that you have set up your project in the same way outlined in part II. An added benefit to this approach is that it allows you to insert IPA symbols into the plot via the tipa package.\nThe LaTeX file Ok. You should start with a LaTeX file that looks like this:\n\\documentclass{article} \\usepackage{tikz} \\usepackage{tipa} \\begin{document} \u0026lt;\u0026lt;\u0026gt;\u0026gt;= require(tikzDevice) tikz(\u0026#39;plot.tex\u0026#39;, standAlone=TRUE) library(stats) plot(cars) lines(lowess(cars)) dev.off() @ \\end{document} If you have experience working with LaTeX, the preamble should be pretty straightforward (If you need a quick primer on LaTeX, see this tutorial). The important part so far is that you have to include \\usepackage{tikz} and \\usepackage{tipa} before \\begin{document}.\n The R code In knitr, R code goes between \u0026lt;\u0026lt;\u0026gt;\u0026gt;= and ends with @. So all of this is R code:\nrequire(tikzDevice) tikz(\u0026#39;plots/cars-plot.tex\u0026#39;, standAlone=TRUE) library(stats) plot(cars) lines(lowess(cars)) dev.off() The command require(tikzDevice) loads tikz into the R workspace. Then, tikz('plots/cars-plot.tex', standAlone=TRUE) calls the tikz device and creates the file cars-plot.tex in the folder plots. It is important to set standAlone to TRUE if you want to have a separate .tex file (this is what allows us to keep the fonts the same as the rest of the document). From this point on until the call dev.off(), we enter what we want to appear in our .tex file. In this case I have plotted the typical cars data from the library stats. Here is the PDF output produced when cars-plot.tex is compiled. Notice the font is different from what you typical get in R.\nNow let’s try something a little more involved and add some IPA. I will use a fake dataset and load it into R.\nmy_data \u0026lt;- read.delim(\u0026quot;assets/my_data.txt\u0026quot;) We will use ggplot2 for this graph.\nlibrary(ggplot2) Now we will call tikz device.\nrequire(tikzDevice) options(tikzLatexPackages = c(getOption(\u0026quot;tikzLatexPackages\u0026quot;), \u0026quot;\\\\usepackage{tipa}\u0026quot;)) tikz(\u0026#39;plots/ipa_plot.tex\u0026#39;, standAlone=TRUE, width=10, height=6) my_data$group \u0026lt;- factor(my_data$group, levels = c(\u0026quot;EL\u0026quot;, \u0026quot;NE\u0026quot;, \u0026quot;LL\u0026quot;)) df\u0026lt;-with(my_data, aggregate(fpro, list(group=group, fstim=fstim), mean)) df$se\u0026lt;-with(my_data, aggregate(fpro, list(group=group, fstim=fstim), function(x) sd(x)/sqrt(10)))[,3] gp \u0026lt;- ggplot(df, aes(x=fstim, y=x, colour=group, ymin=x-se, ymax=x+se)) gp + geom_line(aes(linetype=group), size = .5) + geom_point(aes(shape=group)) + geom_ribbon(alpha = 0.15, linetype=0) + ylim(0, 1) + scale_x_continuous(breaks=seq(0, 10, by=1)) + labs(list(title = \u0026quot;[\\\\textesh ip/\\\\textesh\\\\textsci p]\u0026quot;, x = \u0026quot;Stimuli\u0026quot;, y = \u0026quot;\\\\% [\\\\textesh\\\\textsci p]\u0026quot;)) + theme_bw() + theme(legend.background = element_rect(colour = \u0026#39;grey50\u0026#39;, fill = \u0026#39;grey97\u0026#39;, size = .75, linetype=\u0026#39;solid\u0026#39;)) + scale_linetype_discrete(\u0026quot;Group\u0026quot;) + scale_shape_discrete(\u0026quot;Group\u0026quot;) + scale_colour_discrete(\u0026quot;Group\u0026quot;) dev.off() Notice that after the require(tikzDevice) call, we included\noptions(tikzLatexPackages = c(getOption(\u0026quot;tikzLatexPackages\u0026quot;), \u0026quot;\\\\usepackage{tipa}\u0026quot;))  The key component here is \\\\usepackage{tipa}. This means that tipa will be included in the .tex produced from the code, which, in turn, means that we can include IPA sybold in the plot before it is produced. The tikz('plots/ipa_plot.tex', standAlone=TRUE, width=5, height=5) call creates ipa_plot.tex in the folder plots. The rest of the code (up to dev.off()) is the actual plot. Notice that we have included ipa in the following command:\nlabs(list(title = \u0026quot;[\\\\textesh ip/\\\\textesh\\\\textsci p]\u0026quot;, x = \u0026quot;Stimuli\u0026quot;, y = \u0026quot;\\\\% [\\\\textesh\\\\textsci p]\u0026quot;)) This is the plot that is produced when the resulting .tex file is compiled:\nAnd that’s it. We have produced a beautiful plot that uses the same font as our document and includes IPA symbols. You can download all the files here and try it yourself.\n ","date":1401329594,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1401329594,"objectID":"230bf15b6ae75b98c512da96e5480f61","permalink":"/post/2014-05-28_tikz_-_standalone_plots/","publishdate":"2014-05-28T21:13:14-05:00","relpermalink":"/post/2014-05-28_tikz_-_standalone_plots/","section":"post","summary":"In this post I’m going to show you how to use TikzDevice to create high quality plots that use the same font as your LaTeX document. I’m assuming that you have already installed tikz. If not, see part I in this series. Moreover, this tutorial assumes that you have set up your project in the same way outlined in part II. An added benefit to this approach is that it allows you to insert IPA symbols into the plot via the tipa package.","tags":["R","tikz","data viz"],"title":"TikzDevice tutorial III: standalone plots","type":"post"},{"authors":null,"categories":["R"],"content":" Knitr bootstrap makes generating standalone reports extremely easy and the output looks really neat. Check out the example here. To recreate this you need to download the preview release of R Studio, and set up the front matter as follows:\n--- output: knitrBootstrap::bootstrap_document: title: \u0026quot;\u0026quot; theme: default highlight: sunburst theme.chooser: TRUE highlight.chooser: TRUE --- ","date":1401156794,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1401156794,"objectID":"ce0872f2b52bd9740d8baff2ecff1202","permalink":"/post/2014-05-26_knitr_bootstrap/","publishdate":"2014-05-26T21:13:14-05:00","relpermalink":"/post/2014-05-26_knitr_bootstrap/","section":"post","summary":"Quick and dirty test for knitr boostrap framework.","tags":["R","knitr","bootstrap","R markdown"],"title":"Knitr bootstrap","type":"post"},{"authors":null,"categories":["R"],"content":" HTML5 slides I recently learned how to create HTML5 slides using .Rmd files and pandoc. Click here to check out an example. I will be posting a tutorial on how to do this in the near future (I hope).\nUpdate Here is a much cooler example I found on mages’ blog\nUpdate 2 This process has been streamlined in the newest update to RStudio (check it out here). The results are quite impressive (Ex. 1, Ex. 2)\n ","date":1389147194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1389147194,"objectID":"0179957189111fe48085085352aaaf68","permalink":"/post/2014-01-07_converting_rmarkdown_files_to_html5/","publishdate":"2014-01-07T21:13:14-05:00","relpermalink":"/post/2014-01-07_converting_rmarkdown_files_to_html5/","section":"post","summary":"HTML5 slides I recently learned how to create HTML5 slides using .Rmd files and pandoc. Click here to check out an example. I will be posting a tutorial on how to do this in the near future (I hope).\nUpdate Here is a much cooler example I found on mages’ blog\nUpdate 2 This process has been streamlined in the newest update to RStudio (check it out here). The results are quite impressive (Ex.","tags":["R","R markdown","html","RStudio"],"title":"Converting markdown files to HTML5 in RStudio","type":"post"},{"authors":null,"categories":["R"],"content":" Overview This mini tutorial is part II about incorporating tikzDevice into your workflow. It explains the file structure necessary to successfully include tikzDevice plots into your LaTeX document. You must first have tikzDevice installed. If you don’t, see part I for more information.\n The structure A simple yet effective way to do reproducible research is to use R (for statistical analysis) directly in a LaTeX environment. There are two ways to accomplish this: (1) Sweave and (2) knitr. Knitr seems to be the better choice, as it builds on some of the deficiencies of Sweave, and is what I am currently using in my workflow. In order to successfully “knit” R code into a .tex format we must use a no-web (.nw) file to create the .tex file. There are two types of no-web files: .Rnw and .Snw. I am not completely sure what the differences are between then, but I use .Rnw and that is what I will mention in this tutorial.\nThe first step is to create a project folder. For the purposes of this tutorial let’s call this folder “master”. Next, we will need some data and some R code that analyzes it. The most common, no-hassle way to accomplish this in R is to save your R code in a separate .R file. For this tutorial, we will call our data “my-data.txt” and our R code “example.R”. The fake data we are going to analyze is for a two-alternative forced choice identification experiment. So, our fake data is in the “my-data.txt” file and the R code that analyzes it is in the example.R file.\nThe next step is to create the “no web” .Rnw file. This is as simple as creating a document in your text editor of choice (I use TextMate 2 and Sublime Text 3) and saving it with a .Rnw extension. For this tutorial we will call this file “example.Rnw”. Its purpose is to call the R code written in “example.R” (which uses the fake data in “my-data.txt”) in order to produce a .tex file (in this case “example.tex”). Still with me? Good.\nNext we need to prepare where we are going to keep the plots produced by tikzDevice. I find it most convenient to have a specific folder, “plots_folder”, where I only keep the tikzDevice plots. So, create this folder inside the “master” folder. TikzDevice creates the R plots and converts them to a LaTeX format (the benefits of this are further explained in part III of this tutorial), saves them in “plots_folder” and we will then include them in the example.tex file which can be compiled into a PDF. The image below shows what this should look like when it’s all said and done.\n Check out part III to learn how to create standalone plots that can include IPA sybols.\n ","date":1368843194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1368843194,"objectID":"23e436b3ec7b075886707a8f344a2acf","permalink":"/post/2013-05-17_tikz_-_projects/","publishdate":"2013-05-17T21:13:14-05:00","relpermalink":"/post/2013-05-17_tikz_-_projects/","section":"post","summary":"Overview This mini tutorial is part II about incorporating tikzDevice into your workflow. It explains the file structure necessary to successfully include tikzDevice plots into your LaTeX document. You must first have tikzDevice installed. If you don’t, see part I for more information.\n The structure A simple yet effective way to do reproducible research is to use R (for statistical analysis) directly in a LaTeX environment. There are two ways to accomplish this: (1) Sweave and (2) knitr.","tags":["R","tikz","data viz","workflow","project"],"title":"TikzDevice tutorial II: structuring a project","type":"post"},{"authors":null,"categories":["R"],"content":" Overview This is a short tutorial for getting tikzDevice running on R version 3.0. If you write in LaTeX and use R for statistics, this is a good way to get your plots/graphs/etc. into your .tex document. The advantages are:\nmuch higher quality and you can use IPA symbols   Download tiksDevice TiksDevice is no longer officially supported by CRAN because the author was having trouble keeping it updated in a timely manner (Check out this webpage if you want to read a little more about the situation). Nonetheless, the tikzdevice package is very usable and still available for download. You can download the tar.gz file directly by clicking here.\n Install tiksDevice Installing a package that is no longer supported is by no means difficult, but not as simple as install.package('tikzDevice') (try it if you want to see why). Use the following code install the tar file (make sure to specify your file path to wherever you downloaded the file). This is what it looked like for me.\ninstall.packages(\u0026quot;/Users/USERNAME/Downloads/tikzDevice_0.6.2.tar\u0026quot;, repos = NULL, type=\u0026quot;source\u0026quot;)  Install dependencies In order for tikzDevice to work, you must also install the filehash package. This is much easier.\ninstall.packages(\u0026#39;filehash\u0026#39;) That’s it. Check out this tutorial to see how to set up a project.\n ","date":1368324794,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1368324794,"objectID":"2d400ed105d0cfb810dbb0af3375715e","permalink":"/post/2013-05-11_tikz_-_installation/","publishdate":"2013-05-11T21:13:14-05:00","relpermalink":"/post/2013-05-11_tikz_-_installation/","section":"post","summary":"Overview This is a short tutorial for getting tikzDevice running on R version 3.0. If you write in LaTeX and use R for statistics, this is a good way to get your plots/graphs/etc. into your .tex document. The advantages are:\nmuch higher quality and you can use IPA symbols   Download tiksDevice TiksDevice is no longer officially supported by CRAN because the author was having trouble keeping it updated in a timely manner (Check out this webpage if you want to read a little more about the situation).","tags":["R","tikz","data viz"],"title":"TikzDevice tutorial I: install tikzDevice in R","type":"post"},{"authors":null,"categories":["R"],"content":" This is how I made the colored spectrogram from the homepage (it’s me saying ‘welcome’). You need to load the package phonTools into R.\nlibrary(phonTools) Now you have to load the sound you want to make a spectrogram of (it has to be in your working directory). I recorded mine in Praat.\nsound \u0026lt;- loadsound(\u0026#39;welcome.wav\u0026#39;) Now we’re ready to make a spectrogram.\nspectrogram(sound, fs = 44100, colors = TRUE, maintitle = \u0026quot;Welcome\u0026quot;, maxfreq = 5500) We can also see the oscillogram by using\nplot(sound) That’s it.\n","date":1368151994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1368151994,"objectID":"9319ce108892479c7a69ee2410f6f545","permalink":"/post/2013-05-09_colored_spectrograms_in_r/","publishdate":"2013-05-09T21:13:14-05:00","relpermalink":"/post/2013-05-09_colored_spectrograms_in_r/","section":"post","summary":"This is how I made the colored spectrogram from the homepage (it’s me saying ‘welcome’). You need to load the package phonTools into R.\nlibrary(phonTools) Now you have to load the sound you want to make a spectrogram of (it has to be in your working directory). I recorded mine in Praat.\nsound \u0026lt;- loadsound(\u0026#39;welcome.wav\u0026#39;) Now we’re ready to make a spectrogram.\nspectrogram(sound, fs = 44100, colors = TRUE, maintitle = \u0026quot;Welcome\u0026quot;, maxfreq = 5500) We can also see the oscillogram by using","tags":["R","Praat"],"title":"Colored spectrograms in R","type":"post"}]