{
  "hash": "1fd5fc6304da96a47fd889c3eeae8329",
  "result": {
    "markdown": "---\ntitle: \"Data pipelines in R\"\ndescription: |\n  What button do I press to learn the truth? \ndate: 05-18-2015\nauthor:\n  - name: Joseph V. Casillas \n    url: https://www.jvcasillas.com\n    affiliation: Rutgers University\n    affiliation_url: https://www.rutgers.edu\nbase_url: http://www.jvcasillas.com\ncategories: [r, research, workflow]\ntwitter:\n  creator: \"@jvcasill\"\nengine: knitr\nimage: \"./assets/img/pipeline1.png\"\n---\n\n\n\n\n## Overview\n\nSo you thought up a clever experiment, got IRB approval, recruited participants and collected data... now what? \nNew researchers are often confronted with an unfortunate surprise when it comes time to perform some kind of analysis on their data: they don't know how, or even where to start. \nThis can be a problem for something trivial, like obtaining simple descriptive statistics, or something much more complex, like fitting models, creating plots and making predictions. \nWhen we conduct experiments we don't usually begin by thinking about how we will analyze our data, and in many academic programs this is not explicitly taught to new students. \nFor most people, especially beginners, the data analysis issue arises later on in the process, usually after the data have already been collected (although I think this ultimately changes with experience). \n\nIn light of all of this, I think that something handy to learn and evaluate \nearly on is how data analysis typically flows: from obtaining data to obtaining new insight from the data. \nThis is the data analysis pipeline, which usually looks something like this:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](./assets/img/pipeline1.png){width=100%}\n:::\n:::\n\n\nIn essence, the process is simple. \nAfter collecting your data, you need to *tidy* it (step 2) so that it can be loaded and analyzed by your statistical software. \nAfter tidying your data, you usually have to transform it (step 3) in some way (also called data preprocessing). \nThis can be occur via the creation of new variables, combining variables, sub-setting variables, etc. \nOnce you have transformed your data, it's time to visualize it (step 4a) via graphs/plots, and, finally, analyze it. \nIn exploratory data analysis the visualization and analysis steps are often iterative: you might notice something in a graph that leads you to a new analysis, or some kind of insight that requires more data transformation and a new analysis, and so on and so forth until you have obtained new insight that might lead you to generate new research question(s).\n\nSo, at the heart of data analysis is `tidy data`. \nMost new researchers don't know what it means to tidy and transform their data, nor that it is probably the most important part of any data analysis. \nBasically, if your data are not formatted in a way in which they can be easily analyzed (via excel, SPSS, R, etc.), then you can't do anything with them.\n\nIn order to facilitate the data analysis pipeline, it is crucial to have `tidy data`. \nWhat this means is that **every column in your data frame represents a variable and every row represents an observation**. \nThis is also referred to as *long format* (as opposed to wide format). \nMost statistical software requires your data to be in long format, with few exceptions (i.e. repeated measures ANOVA in SPSS). \n\nIn what follows, I take you through three packages that have been created in order to facilitate the data analysis pipeline in R. \nEach package was created by Hadley Wickham with steps 2, 3, and 4a of the pipeline in mind. \nThus we can associate each package with the corresponding step:\n\n\n\n::: {.cell}\n\n:::\n\n\n<img width=\"100%\" src=\"./assets/img/pipeline2.png\">\n\n- [tidyr](http://www.jvcasillas.com/tidyr_tutorial/)\n- dplyr\n- [basic plotting in r](http://www.jvcasillas.com/base_lattice_ggplot/) / ggvis\n\n(coming soon)\n\n\n",
    "supporting": [
      "2015-05-18_data_pipelines_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}