{
  "hash": "277c309dcbd21b3ca9da0292f2ab0a97",
  "result": {
    "markdown": "---\ntitle: \"Exploring phonemic boundaries using logistic regression\"\ndescription: |\n  In this post I show how to use logistic regression to get interesting info \n  about bilinguals in a two-alternative forced choice task. \ndate: \"2021-05-16\"\nauthor:\n  - name: Joseph V. Casillas \n    url: https://www.jvcasillas.com\n    affiliation: Rutgers University\n    affiliation_url: https://www.rutgers.edu\nbase_url: https://www.jvcasillas.com\ncategories: [stats, glm, bilinguals, double phonemic boundary]\ntwitter:\n  creator: \"@jvcasill\"\nengine: knitr\n---\n\n\n\n\n## A bit of background\n\nThis post is about phonemic boundaries. \nImagine we are interested in understanding stop voicing distinctions in English/Spanish bilinguals. \nEnglish and Spanish have the same stop voicing contrasts at bilabial (/b, p/), coronal (/d, t/), and velar (/g, k/) place, but the phonetic realizations differ in a variety of ways. \nWe will focus on voice-onset time (VOT). \nEnglish has contrasts between lag stops (short-lag vs. long-lag VOT) and Spanish is a true voicing language, i.e., the contrasts are between phonetically voiced and short-lag stops. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"hkwmhpyrkg\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#hkwmhpyrkg .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#hkwmhpyrkg .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#hkwmhpyrkg .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#hkwmhpyrkg .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#hkwmhpyrkg .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#hkwmhpyrkg .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#hkwmhpyrkg .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#hkwmhpyrkg .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#hkwmhpyrkg .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#hkwmhpyrkg .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#hkwmhpyrkg .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#hkwmhpyrkg .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#hkwmhpyrkg .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#hkwmhpyrkg .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hkwmhpyrkg .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#hkwmhpyrkg .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#hkwmhpyrkg .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hkwmhpyrkg .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#hkwmhpyrkg .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hkwmhpyrkg .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#hkwmhpyrkg .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hkwmhpyrkg .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hkwmhpyrkg .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hkwmhpyrkg .gt_left {\n  text-align: left;\n}\n\n#hkwmhpyrkg .gt_center {\n  text-align: center;\n}\n\n#hkwmhpyrkg .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#hkwmhpyrkg .gt_font_normal {\n  font-weight: normal;\n}\n\n#hkwmhpyrkg .gt_font_bold {\n  font-weight: bold;\n}\n\n#hkwmhpyrkg .gt_font_italic {\n  font-style: italic;\n}\n\n#hkwmhpyrkg .gt_super {\n  font-size: 65%;\n}\n\n#hkwmhpyrkg .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#hkwmhpyrkg .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#hkwmhpyrkg .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#hkwmhpyrkg .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#hkwmhpyrkg .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#hkwmhpyrkg .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#hkwmhpyrkg .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Language\">Language</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Stops\">Stops</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Phonetic realization\">Phonetic realization</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"Stops\" class=\"gt_row gt_left\">/bdg/</td>\n<td headers=\"Phonetic realization\" class=\"gt_row gt_left\">short-lag VOT</td></tr>\n    <tr><td headers=\"Language\" class=\"gt_row gt_left\"> </td>\n<td headers=\"Stops\" class=\"gt_row gt_left\">/ptk/</td>\n<td headers=\"Phonetic realization\" class=\"gt_row gt_left\">long-lag VOT</td></tr>\n    <tr><td headers=\"Language\" class=\"gt_row gt_left\">Spanish</td>\n<td headers=\"Stops\" class=\"gt_row gt_left\">/bdg/</td>\n<td headers=\"Phonetic realization\" class=\"gt_row gt_left\">lead VOT</td></tr>\n    <tr><td headers=\"Language\" class=\"gt_row gt_left\"> </td>\n<td headers=\"Stops\" class=\"gt_row gt_left\">/ptk/</td>\n<td headers=\"Phonetic realization\" class=\"gt_row gt_left\">short-lag VOT</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n\nFor an adult English speaker that wants to learn Spanish, one difficulty they encounter is related to VOT, that is, they have to learn the VOT patterns of Spanish, which differ from those of English. \nAs a method of assessing phonological learning in second language acquisition (SLA), we might be interested in knowing if the boundary between a voiced/voiceless pair is different in English than in Spanish for a group of individuals who learned Spanish as adults. \n\nOne way researchers do this is by (re)synthesizing acoustic stimuli to create a VOT continuum and then asking learners to categorize the sounds. \nWhat we typically see is that for one end of the continuum all the stimuli are categorized as being 'voiced' and then at some point there is a shift to 'voiceless'. \nWhere this shift occurs is what we are after in this post. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html/sigmoids-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nThe shift usually occurs further to the left for Spanish speakers than for English speakers, which is a consequence of the phonetic nature of the voicing contrasts, i.e., lead vs. short-lag (Spanish) or short-lag vs. long-lag (English). \nSo, for an adult English speaker that is proficient in Spanish, one might expect different identification functions depending on which language they are identifying, Spanish or English. \n\nIn this post I am going to simulate data from this type of experiment and analyze them in a variety of ways. \nOne fun detail, the experimental design assumes that the participants are always identifying the same stimuli, but we will tell them that they are hearing a different language, Spanish or English, in different experimental sessions. \n\n<aside>\nThere are a series of experiments that do this. \nI won't go into more detail here, but check out [Gonzales et. al (2019)](https://doi.org/10.1016/j.cognition.2018.08.021), and [Lozano et. al (2020)](https://doi.org/10.1017/S0272263120000273) for recent examples. \n</aside>\n\nThese are the packages I will primarily be using: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(\"dplyr\")      # Data wrangling\nlibrary(\"tidyr\")      # Data wrangling\nlibrary(\"purrr\")      # Iteration on lists\nlibrary(\"lme4\")       # Model fitting\nlibrary(\"AICcmodavg\") # Model preds\nlibrary(\"ggplot2\")    # Plotting\n```\n:::\n\n\n## Getting data\n\nThe first thing we need to do is get some data. \nIn this post I am going to simulate data that is similar to the output you would get from a two-alternative forced choice (2AFC) task, but before we simulate we need to discuss the experimental paradigm a bit so that everything makes sense. \n\nA 2AFC task is quite simple. \nThe participant is presented something---in this case auditory stimuli---and then make a binary decision about it. \n\n<aside>\nYou can see code and examples of this type of task in python [here](https://osf.io/g6dcu/). \n</aside>\n\nIn this particular hypothetical experiment participants are presented stimuli that is randomly drawn from a VOT continuum ranging from -60 to 60 ms in 10 ms steps (that's 13 steps total). \nWe will present the entire continuum 15 times, so each participant will provide 195 responses. \nThis would be an extremely boring experiment, but that's another discussion. \nWe will assume the experiment is given in two sessions, a Spanish session and an English session. \nThe only difference between sessions is that the participants will be told that they are going to categorize English stimuli in the English session and Spanish stimuli in the Spanish session. \nImportantly, the actual continuum of stimuli they hear is **exactly the same**. \nTricky, right?\n\n<aside>\nThe crucial question here is whether or not proficient adult language learners adjust their perceptual boundaries based on their underlying expectations about the language. \nIt turns out they do! \nHere is second shameless plug for the [Lozano et. al (2020)](https://doi.org/10.1017/S0272263120000273) paper. 😄\n</aside>\n\n\nWe will simulate data for 25 participants, and two language sessions (or language modes), English and Spanish. \nIf you're doing the math, that is 25 participants $\\times$ 13 steps $\\times$ 15 item repetitions $\\times$ 2 language modes, which gives us a data set with a grand total of 9750 responses (i.e., 9750 rows in the dataframe). \n(Note: If you aren't interested in the whole simulation process just skip the next section.)\n\n## Specifying the model\n\nOur criterion is binary (0/1) responses. \nSpecifically, this refers to whether the participant responds 'voiced' (0) or 'voiceless' (1) to each pull from the VOT continuum. \nFor this reason we will simulate from the binomial distribution. \nOur model will look something like this: \n\n$$\n\\begin{aligned}\nresponse_{i} \\sim & \\ Binomial(p_{i}, m_{i}) \\\\\nlogit(p_{i}) = & \\ \\beta_{0} + \\beta_{1} * VOT_{1} + \\beta_{2} * I_{(language_{i} = Spanish)2} + \\beta_{3} * VOT_{1} * I_{2}\n\\end{aligned}\n$$\n\n...where we analyze the log odds of 'voiceless' responses as a function of VOT, i.e., the step in the continuum, language mode (if they think they are hearing English or Spanish) and the interaction between the two. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Set seed for reproducibility\nset.seed(20210514)\n\n# dataframe params\nn_ids       <- 25\nn_steps     <- 13\nn_lang      <- 2\nn_item_reps <- 15\n\n# Set up dataframe\nid        <- rep(glue::glue(\"id_{1:n_ids}\"), each = n_steps * n_lang)\nvot       <- rep(seq(-60, 60, 10), times = n_ids * n_lang)\nlanguage  <- rep(c(\"English\", \"Spanish\"), each = n_steps, times = n_ids)\ndat       <- data.frame(id, vot, language, n_item_reps)\n\n# Model params\nb0          <- -1.10 # intercept\nb1          <-  0.09 # slope VOT\nb2          <-  0.80 # language effect\nb12         <- -0.06 # slope adj. for Spanish\nid_var      <-  0.20 # id variability\nstep_var    <-  0.50 # step variability\nlang_var    <-  0.11 # lang variability\n\n# Simulate random effects\nid_eff   <- rep(rnorm(n = n_ids, mean = 0, sd = id_var), each = n_steps * n_lang)\nstep_eff <- replicate(n = n_ids, rep(rnorm(n_steps, 0, step_var), times = n_lang), \n              simplify = F) %>% \n            unlist()\n\n# Get log odds from linear predictor and convert to probability\nlog_odds <- b0 + \n            b1 * vot + \n            b2 * (language == \"Spanish\") + \n            b1 * vot * b12 * (language == \"Spanish\") + \n            id_eff + step_eff \nprop     <- plogis(log_odds)\n\n# Generate binomial responses\ndat$response <- rbinom(n = n_ids * n_steps * n_lang, size = n_item_reps, prob = prop)\n\n# Expand binomial responses to binary\ndat_long <- dat %>%\n  nest(data = c(response, n_item_reps)) %>%\n  mutate(response = map(data, ~c(rep(1, .x$response),\n                                 rep(0, .x$n_item_reps - .x$response)))) %>%\n  select(-data) %>%\n  unnest(response) %>% \n  group_by(id, vot, language) %>% \n  mutate(item_rep = seq_along(vot)) %>% \n  ungroup() %>% \n  mutate(item_rep = (item_rep - mean(item_rep)) / sd(item_rep), \n         vot_std = (vot - mean(vot)) / sd(vot))\n  \n```\n:::\n\n\nThe code above simulates the data set. \nI won't go into detail about how it works (maybe for another post), but I do want to point out two things: 1) I've added an `item_rep` variable to keep track of what repetition (out of 15) a given response comes from, and 2) I have standardized `vot` (`vot_std`) and `item_rep` in order to improve computational efficiency of the model. \nIt will be important to keep this in mind when we begin analyzing and plotting the results. \n\n<aside>\nThese models are notoriously slow in `lme4` and often have convergence issues. \nI normally work in a Bayesian framework, so I might update this at some point. \n</aside>\n\nHere is what the output of one block of the experiment for one participant looks like: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat_long %>% \n  filter(item_rep == 0) %>% \n  select(-item_rep, -vot_std) %>% \n  head(., 13) %>% \n  gt::gt()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"wixribalbk\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#wixribalbk .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#wixribalbk .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wixribalbk .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#wixribalbk .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#wixribalbk .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#wixribalbk .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wixribalbk .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wixribalbk .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#wixribalbk .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#wixribalbk .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#wixribalbk .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#wixribalbk .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#wixribalbk .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#wixribalbk .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wixribalbk .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#wixribalbk .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#wixribalbk .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#wixribalbk .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wixribalbk .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#wixribalbk .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#wixribalbk .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wixribalbk .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#wixribalbk .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#wixribalbk .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wixribalbk .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wixribalbk .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#wixribalbk .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#wixribalbk .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wixribalbk .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wixribalbk .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wixribalbk .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wixribalbk .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wixribalbk .gt_left {\n  text-align: left;\n}\n\n#wixribalbk .gt_center {\n  text-align: center;\n}\n\n#wixribalbk .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#wixribalbk .gt_font_normal {\n  font-weight: normal;\n}\n\n#wixribalbk .gt_font_bold {\n  font-weight: bold;\n}\n\n#wixribalbk .gt_font_italic {\n  font-style: italic;\n}\n\n#wixribalbk .gt_super {\n  font-size: 65%;\n}\n\n#wixribalbk .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#wixribalbk .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#wixribalbk .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#wixribalbk .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#wixribalbk .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#wixribalbk .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#wixribalbk .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"id\">id</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"vot\">vot</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"language\">language</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"response\">response</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">-60</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">-50</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">-40</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">-30</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">-20</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">-10</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">0</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">10</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">20</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">30</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">40</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">50</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_left\">id_1</td>\n<td headers=\"vot\" class=\"gt_row gt_right\">60</td>\n<td headers=\"language\" class=\"gt_row gt_left\">English</td>\n<td headers=\"response\" class=\"gt_row gt_right\">1</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\nLooks good. \nNow we are ready to fit the model. \n\n## Multilevel logistic regression model\n\nAs mentioned above, our data is binary and we have repeated measures. \nWe will fit a multilevel logistic regression model to account for nesting in the data. \nA key part here is the random effects structure, which will allow us to do some interesting individual differences analyses post-hoc. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fit partial pooling model\nmod <- glmer(\n  formula = response ~ vot_std * language + \n    (1 | id) + \n    (1 + vot_std + item_rep | id:language), \n  control = glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 2e6)), \n  family = binomial(link = \"logit\"), \n  data = dat_long\n  )\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term                    |  estimate| std.error| statistic|   p.value|\n|:-----------------------|---------:|---------:|---------:|---------:|\n|(Intercept)             | -1.237854| 0.4765846| -2.597343| 0.0093948|\n|vot_std                 |  3.538826| 0.4931981|  7.175262| 0.0000000|\n|languageSpanish         |  1.598023| 0.1950572|  8.192588| 0.0000000|\n|vot_std:languageSpanish | -0.338594| 0.2672184| -1.267106| 0.2051175|\n:::\n:::\n\n\nWe won't focus on interpreting the output. \nInstead let's use the model to generate predictions and plot those. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Setup new dataframe to predict on\nnew_dat <- select(dat, -n_item_reps, -response) %>% \n  mutate(vot_std = (vot - mean(vot)) / sd(vot))\n\n# Get model predictions and SE\nfits <- predictSE(mod, new_dat) %>%\n  as_tibble %>%\n  mutate(ymin = fit - se.fit, ymax = fit + se.fit) %>%\n  bind_cols(new_dat) \n\n# Plot it\np_sigmoids <- fits %>% \n  ggplot(., aes(x = vot_std, y = fit, color = language, fill = language)) + \n    geom_ribbon(aes(ymax = ymax, ymin = ymin), \n      alpha = 0.2, color = NA, show.legend = F) +\n    geom_line(linewidth = 0.75) + \n    geom_point(color = \"white\", stroke = 1.5, size = 4, pch = 21) + \n    geom_jitter(data = dat_long, \n      width = 0.2, height = 0.01, alpha = 0.02, pch = 21, \n      aes(x = vot_std, \n        y = if_else(response == 1, response + 0.05, response - 0.05))) + \n    labs(y = \"P(response = /p/)\", x = \"VOT (ms)\") + \n    scale_y_continuous(breaks = seq(0, 1, 0.25)) + \n    scale_x_continuous(breaks = unique(fits$vot_std)[c(TRUE, FALSE)], \n      labels = seq(-60, 60, 20)) + \n    scale_fill_viridis_d(name = NULL, begin = 0.3, end = 0.7) + \n    scale_color_viridis_d(name = NULL, begin = 0.3, end = 0.7) + \n    ds4ling::ds4ling_bw_theme(base_family = \"Palatino\") + \n    theme(legend.position = c(0.1, 0.87), legend.background = element_blank())\n\np_sigmoids\n```\n\n::: {.cell-output-display}\n![](2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html/model-preds-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nCool. \nWe can see that in our simulated data the Spanish sigmoid function is shifted to the left with regard to the English sigmoid function. \nThis equates to more 'voiceless' responses when the participants believe they are hearing Spanish. \n\n### Category boundaries\n\nOne way this literature has assessed categorical perception in bilinguals is by calculating and comparing the 50% cross over point for each language. \nThis is the point where the probability of responding 'voiceless' is exactly 0.5. \nIf we just eyeball the plot above, we can guess that this is around -5 ms for Spanish and around 13 ms for English, but we can do better than just eyeballing it. \nWe will use the following formula to calculate the boundary, which we'll just call the \"crossover\" (CO), between /b-p/ for each language session: \n\n$$\nCO_{En} = \\frac{\\beta_{0}}{\\beta_{1}} * -1\n$$\n\nThis means, for English, we can calculate the 50% crossover by dividing the intercept by the slope for VOT and multiplying by -1. \nIn case it's not clear, `intercept` and `slope` refer to the fixed effect parameters we just estimated in the model. \nWe can grab those estimates using `fixef`. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfixef(mod)\n##             (Intercept)                 vot_std         languageSpanish \n##               -1.237854                3.538825                1.598023 \n## vot_std:languageSpanish \n##               -0.338594\n```\n:::\n\n\nThe `fixef` function returns a vector containing the parameter estimates. \nSince English is the reference level, we just need the first two elements of the vector and we can calculate the boundary like this: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nen_co <- (fixef(mod)[1] / fixef(mod)[2]) * -1\nen_co\n## (Intercept) \n##   0.3497923\n```\n:::\n\n\nSo the boundary is at 0.35 standard deviations above the mean (0). \nWe can make this value easier to interpret by back-transforming to milliseconds. \nWe do this by adding the mean of the original VOT vector of the dataframe and  multiplying by the standard deviation:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calculate En CO in ms (note the mean is 0, so we could skip that)\n(en_co + mean(dat_long$vot)) * sd(dat_long$vot)\n## (Intercept) \n##     13.0887\n```\n:::\n\n\nSo the English boundary is at about 13.09 ms (my guess was pretty close!). \nLet's calculate the boundary for Spanish and plot them: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add language effect on the intercept and slope adj for language == Spanish\nsp_co <- (fixef(mod)[1] + fixef(mod)[3]) / (fixef(mod)[2] + fixef(mod)[4]) * -1\nsp_co\n## (Intercept) \n##  -0.1125447\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create tibble with boundaries and text\nco_text <- tribble(\n  ~'vot_std', ~'fit', ~'language', ~'text', \n  -1.6, 0.5, \"Spanish\", paste0(\"Spanish boundary = \", round(sp_co * sd(dat_long$vot), 2), \" ms\"), \n   0.6, 0.5, \"English\", paste0(\"English boundary = \", round(en_co * sd(dat_long$vot), 2), \" ms\")\n)\n\n# Add to base plot\np_sigmoids + \n  geom_vline(xintercept = c(en_co, sp_co), lty = 3) + \n  geom_text(data = co_text, aes(label = text), \n            hjust = 0, size = 4, family = \"Times\") \n```\n\n::: {.cell-output-display}\n![](2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html/add-co-to-plot-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n### Contrast coefficient slopes\n\nAnother way we can assess how the acoustic stimuli are categorized is by looking at the slope of the sigmoid functions at the category boundary (i.e., the 50% crossover point). \nWe do this by calculating the contrast coefficient slope (CCS). \nEssentially the CCS in the logistic space is related to the slope of the sigmoid function and represents the rate of change from one category to another (i.e., from /b/ to /p/ in our case) in the probability space. \n\nMorrison (2007) describes CCSs as \"indicators of the crispness of the boundary between the two categories\" (p. 232). \nNative speakers typically have crisp boundaries between categories, whereas non-native speakers can have \"fuzzier\" boundaries for a number of reasons. \n\n<aside>\nSee: Morrison, G. (2007). Logistic regression modeling for first- and second-language perception data. In: Solé M-J, Prieto P, and Mascaró J (eds), *Segmental and prosodic issues in Romance phonology*. Amsterdam: John Benjamins, 219–36.\n</aside>\n\nI will spare you the calculus, but in a few words the CCS in the probability space is the partial derivative of the slope of the sigmoid function at its steepest point. \nConveniently, the steepest value of the slope in the binomial case is when the probability of the criterion is 0.5, i.e., at the crossover boundary. \nWe can calculate the CCS by multiplying the slope of the continuous measure by 0.25:\n\n$$\nCCS_{En} = \\beta_{VOT} * 0.25\n$$\n\nSo for English, the CCS is calculated as: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nen_ccs <- fixef(mod)[2] * 0.25\nen_ccs\n##   vot_std \n## 0.8847064\n```\n:::\n\n\nThis means that when the the probability of responding 'voiceless' is 0.5, the slope of the sigmoid for English is 0.88 in the probability space. \nWe can calculate this for both languages and plot the lines: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsp_ccs <- (fixef(mod)[2] + fixef(mod)[4]) * 0.25\n\nccs_text <- tribble(\n  ~'vot_std', ~'fit', ~'language', ~'text', \n  -1.2, 0.5, \"Spanish\", paste0(\"Spanish CCS = \", round(sp_ccs, 2)), \n   0.6, 0.5, \"English\", paste0(\"English CCS = \", round(en_ccs, 2))\n)\n\np_sigmoids + \n  geom_abline(intercept = 0.5 - en_ccs * en_co, slope = en_ccs, lty = 2) + \n  geom_abline(intercept = 0.5 - sp_ccs * sp_co, slope = sp_ccs, lty = 2) + \n  geom_text(data = ccs_text, aes(label = text), \n            hjust = 0, size = 4, family = \"Times\") \n```\n\n::: {.cell-output-display}\n![](2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html/plot-ccs-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nAs you can see, the two category boundaries are 'crisp' in both cases. \nThis is because I simulated the data to be this way, but this leads us to more interesting territory... we can explore crossover boundaries and contrast coefficient slopes for individuals. \nPerhaps we are interested in 50% crossover differences as a function of language dominance, or boundary crispness as a function of proficiency. \nWe'll look at a few ways to do that now.\n\n## Individual differences\n\nThere are at least 2 ways to calculate 50% crossover boundaries and contrast coefficient slopes for individual participants. \nOne method is to use the random effects from the omnibus model we fit above (i.e., `mod`). \nAnother method is fit a logistic regression to the data of each participant. \nI'll go with this no-pooling method, but one should certainly give careful thought to both methods and decide which makes the most sense for the research questions of interest. \n\nWe can easily fit a model to each individual using the `lmList` function from the `lme4` package: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fit no pooling model(s)\nno_pool_full <- lmList(response ~ vot_std * language | id, family = \"binomial\", \n  data = as.data.frame(dat_long))\n```\n:::\n\n\nI'll use the `coef` and `head` functions to take a peak at the structure of the resulting object. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncoef(no_pool_full) %>% head\n##       (Intercept)  vot_std languageSpanish vot_std:languageSpanish\n## id_1   -1.0814034 3.663940       0.6900609             -0.30420433\n## id_10  -1.1861547 3.059800       1.2626094             -0.24044950\n## id_11  -1.4045661 3.184317       1.1704759             -0.30283595\n## id_12  -0.5402269 3.552218       0.6148052             -0.80768856\n## id_13  -1.0842951 3.457762       0.6257084             -0.46301851\n## id_14  -0.6622088 2.935729       0.5329204             -0.07208159\n```\n:::\n\n\nNice!\nWith a little bit of wrangling and the formulas we looked at previously, we can calculate the CO and CCS of each individual for English and Spanish.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nid_diffs <- no_pool_full %>% \n  coef() %>% \n  as_tibble() %>% \n  transmute(\n    id = rownames(coef(no_pool_full)), \n    int_English = `(Intercept)`, \n    vot_English = vot_std, \n    int_Spanish = int_English + languageSpanish, \n    vot_Spanish = vot_English + `vot_std:languageSpanish`, \n    co_English  = int_English / vot_English * -1, \n    co_Spanish  = int_Spanish / vot_Spanish * -1, \n    ccs_English = vot_English * 0.25, \n    ccs_Spanish = vot_Spanish * 0.25) %>% \n  select(-vot_English, -vot_Spanish) %>% \n  pivot_longer(\n    cols = -id, \n    names_to = c(\".value\", \"language\"), \n    names_sep = \"_\"\n    ) %>% \n  mutate(co_ms = co * sd(dat_long$vot))\n\nhead(id_diffs)\n## # A tibble: 6 × 6\n##   id    language     int      co   ccs co_ms\n##   <chr> <chr>      <dbl>   <dbl> <dbl> <dbl>\n## 1 id_1  English  -1.08    0.295  0.916 11.0 \n## 2 id_1  Spanish  -0.391   0.116  0.840  4.36\n## 3 id_10 English  -1.19    0.388  0.765 14.5 \n## 4 id_10 Spanish   0.0765 -0.0271 0.705 -1.01\n## 5 id_11 English  -1.40    0.441  0.796 16.5 \n## 6 id_11 Spanish  -0.234   0.0812 0.720  3.04\n```\n:::\n\n\nNow we are ready to make some plots. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# COs\np_co <- id_diffs %>% \n  ggplot(., aes(x = co_ms, y = language)) + \n    geom_jitter(width = 0.1, height = 0.2, alpha = 0.5, pch = 16) + \n    stat_summary(fun.data = mean_sdl, geom = \"pointrange\", pch = 21, \n      fill = \"white\", size = 1.2, fun.args = list(mult = 1)) + \n    labs(y = \"Language\", x = \"Crossover boundary (ms)\", caption = \"\") + \n    ds4ling::ds4ling_bw_theme(base_family = \"Palatino\")\n\n# CCSs\np_ccs <- id_diffs %>% \n  ggplot(., aes(x = ccs, y = language)) + \n    geom_jitter(width = 0.1, height = 0.2, alpha = 0.5, pch = 16) + \n    stat_summary(fun.data = mean_sdl, geom = \"pointrange\", pch = 21, \n      fill = \"white\", size = 1.2, fun.args = list(mult = 1)) + \n    labs(y = NULL, x = \"Contrast coefficient slopes\", caption = \"Mean +/- SD\") + \n    ds4ling::ds4ling_bw_theme(base_family = \"Palatino\") + \n    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())\n\np_co + p_ccs\n```\n\n::: {.cell-output-display}\n![](2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html/co-plot1-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nWe can also plot the sigmoids of individuals along with the 50% crossovers, as well as the contrast coefficient slopes. \nLet's find the individuals with the largest and smallest differences between English and Spanish boundaries, plus 6 more participants at random. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calculate boundary diffs\nco_diffs <- id_diffs %>% \n  select(id, language, co) %>% \n  pivot_wider(names_from = language, values_from = co) %>% \n  mutate(diff = English - Spanish) \n\n# Find smallest and largest diffs\nco_min_max <- c(\n  slice_max(co_diffs, diff, n = 1) %>% pull(id), \n  slice_min(co_diffs, diff, n = 1) %>% pull(id)\n)\n\n# Vector of min, max, plus 6 random subjects\nn_8 <- c(\n  co_min_max, \n  filter(dat_long, (!id %in% co_min_max)) %>% \n  distinct(id) %>% \n  sample_n(6) %>% pull\n)\n\n# Use diff column to order from smallest to largest\nordered_8 <- co_diffs %>% \n  filter(id %in% n_8) %>% \n  arrange(diff) %>% \n  pull(id)\n\nco_base <- dat_long %>% \n  filter(id %in% n_8) %>% \n  mutate(id = forcats::fct_relevel(id, ordered_8)) %>% \n  ggplot(., aes(x = vot_std, y = response, color = language)) + \n    facet_wrap(~id, nrow = 2) + \n    geom_jitter(width = 0.2, height = 0.01, alpha = 0.1, pch = 21, size = 0.6, \n      aes(y = if_else(response == 1, response + 0.05, response - 0.05))) + \n    stat_summary(fun = mean, geom = \"line\", \n      aes(y = fitted(no_pool_full)[names(fitted(no_pool_full)) %in% ordered_8])) + \n    labs(y = \"P(response = /p/)\", x = \"VOT (ms)\") + \n    scale_y_continuous(breaks = seq(0, 1, 0.25)) + \n    scale_x_continuous(breaks = unique(dat_long$vot_std)[c(TRUE, FALSE, FALSE)], \n      labels = seq(-60, 60, 30)) + \n    scale_fill_viridis_d(name = NULL, begin = 0.3, end = 0.7) + \n    scale_color_viridis_d(name = NULL, begin = 0.3, end = 0.7) + \n    ds4ling::ds4ling_bw_theme(base_family = \"Palatino\", base_size = 10) + \n    theme(legend.position = \"bottom\", \n      strip.background = element_blank(),\n      strip.placement = \"outside\")\n\nco_base + \n  geom_vline(\n    data = filter(id_diffs, id %in% n_8) %>% \n      mutate(id = forcats::fct_relevel(id, ordered_8)), \n    aes(xintercept = co, color = language), lty = 3, show.legend = F)\n```\n\n::: {.cell-output-display}\n![](2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html/co-plot2-1.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\n\nco_base + \n  geom_abline(\n    data = filter(id_diffs, id %in% n_8) %>% \n      mutate(id = forcats::fct_relevel(id, ordered_8)),\n    aes(intercept = 0.5 - co * ccs, slope = ccs, group = language), lty = 3, \n    show.legend = F)\n```\n\n::: {.cell-output-display}\n![](2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html/co-plot2-2.png){fig-align='center' width=100%}\n:::\n:::\n\n\nAwesome! \nWe can see that there are some individuals that have category boundaries in essentially the same place, while others show clear differences between English and Spanish. \nI simulated the data to have similar slopes (the VOT x language interaction), but we still see a bit of variability in CCS plot. \n\n## Wrapping up\n\nI think that is enough for one post. \nWe've seen that multilevel logistic regression is an awesome tool for exploring different aspects of bilingualism and second language acquisition. \nCategory boundaries and contrast coefficient slopes are a few metrics I have found to be quite handy in my research. \n\n### Bonus\n\nI mentioned that you could calculate the individual boundaries using the random effects from the omnibus model or fit a model to each individual. \nCrossover boundaries tend to be a bit unwieldy in the wild, i.e., when you aren't simulating data with 15 item repetitions. \nIt may be the case that having the regularization that comes with partial pooling is preferable when assessing different areas of individual differences. \nThis is just as easy to do by using the `ranef` function with the original model object, `mod`. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nranef(mod)[[1]] %>% \n  tibble::rownames_to_column(var = \"id\") %>% \n  separate(col = id, into = c(\"id\", \"language\"), sep = \":\") %>% \n  pivot_wider(names_from = language, \n    values_from = c(\"(Intercept)\", \"vot_std\", \"item_rep\")) %>% \n  transmute(\n    id = id, \n    int_English = fixef(mod)[1] + `(Intercept)_English`, \n    int_Spanish = fixef(mod)[1] + fixef(mod)[3] + `(Intercept)_Spanish`, \n    slope_English = fixef(mod)[2] + vot_std_English, \n    slope_Spanish = fixef(mod)[2] + fixef(mod)[4] + vot_std_Spanish, \n    co_English  = int_English / slope_English * -1, \n    co_Spanish  = int_Spanish / slope_Spanish * -1, \n    ccs_English = slope_English * 0.25, \n    ccs_Spanish = slope_Spanish * 0.25) %>% \n  select(-c(2:5)) %>% \n  head\n## # A tibble: 6 × 5\n##   id    co_English co_Spanish ccs_English ccs_Spanish\n##   <chr>      <dbl>      <dbl>       <dbl>       <dbl>\n## 1 id_1       0.374     0.182         1.96        1.89\n## 2 id_10      0.356    -0.0329        1.85        1.19\n## 3 id_11      0.369     0.0343        1.89        1.37\n## 4 id_12      0.350     0.133         1.91        1.79\n## 5 id_13      0.354     0.189         1.63        2.10\n## 6 id_14      0.306     0.114         1.49        1.68\n```\n:::\n\n\n## Reproducibility information\n\n**About this document**  \n\nThis document was written in RMarkdown using `distill`.\n\n**Session info**  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndevtools::session_info()$platform\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23)\n##  os       macOS Big Sur ... 10.16\n##  system   x86_64, darwin17.0\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       America/New_York\n##  date     2023-04-09\n##  pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\nas.data.frame(devtools::package_info())[, c(3, 8)]\n##                loadedversion       date\n## academicWriteR         0.4.1 2022-09-05\n## AICcmodavg             2.3-2 2023-03-20\n## backports              1.4.1 2021-12-13\n## base64enc              0.1-3 2015-07-28\n## boot                1.3-28.1 2022-11-22\n## broom                  1.0.4 2023-03-11\n## broom.mixed          0.2.9.4 2022-04-17\n## cachem                 1.0.7 2023-02-24\n## callr                  3.7.3 2022-11-02\n## checkmate              2.1.0 2022-04-21\n## cli                    3.6.1 2023-03-23\n## cluster                2.1.4 2022-08-22\n## codetools             0.2-19 2023-02-01\n## colorspace             2.1-0 2023-01-23\n## crayon                 1.5.2 2022-09-29\n## data.table            1.14.8 2023-02-17\n## devtools               2.4.5 2022-10-11\n## digest                0.6.31 2022-12-11\n## dplyr                  1.1.1 2023-03-22\n## ds4ling                  0.7 2022-09-22\n## ellipsis               0.3.2 2021-04-29\n## emojifont              0.5.5 2021-04-20\n## evaluate                0.20 2023-01-17\n## fansi                  1.0.4 2023-01-22\n## farver                 2.1.1 2022-07-06\n## fastmap                1.1.1 2023-02-24\n## forcats                1.0.0 2023-01-29\n## foreign               0.8-84 2022-12-06\n## Formula                1.2-5 2023-02-24\n## fs                     1.6.1 2023-02-06\n## furrr                  0.3.1 2022-08-15\n## future                1.32.0 2023-03-07\n## generics               0.1.3 2022-07-05\n## ggplot2                3.4.2 2023-04-03\n## globals               0.16.2 2022-11-21\n## glue                   1.6.2 2022-02-24\n## gridExtra                2.3 2017-09-09\n## gt                     0.8.0 2022-11-16\n## gtable                 0.3.3 2023-03-21\n## here                   1.0.1 2020-12-13\n## Hmisc                  5.0-1 2023-03-08\n## htmlTable              2.4.1 2022-07-07\n## htmltools              0.5.5 2023-03-23\n## htmlwidgets            1.6.2 2023-03-17\n## httpuv                 1.6.9 2023-02-14\n## jsonlite               1.8.4 2022-12-06\n## knitr                   1.42 2023-01-25\n## labeling               0.4.2 2020-10-20\n## later                  1.3.0 2021-08-18\n## latex2exp              0.9.6 2022-11-28\n## lattice              0.20-45 2021-09-22\n## lifecycle              1.0.3 2022-10-07\n## listenv                0.9.0 2022-12-16\n## lme4                  1.1-32 2023-03-14\n## magrittr               2.0.3 2022-03-30\n## MASS                7.3-58.3 2023-03-07\n## Matrix                 1.5-3 2022-11-11\n## memoise                2.0.1 2021-11-26\n## mime                    0.12 2021-09-28\n## miniUI               0.1.1.1 2018-05-18\n## minqa                  1.2.5 2022-10-19\n## munsell                0.5.0 2018-06-12\n## nlme                 3.1-162 2023-01-31\n## nloptr                 2.0.3 2022-05-26\n## nnet                  7.3-18 2022-09-28\n## parallelly            1.35.0 2023-03-23\n## patchwork              1.1.2 2022-08-19\n## pbapply                1.7-0 2023-01-13\n## pillar                 1.9.0 2023-03-22\n## pkgbuild               1.4.0 2022-11-27\n## pkgconfig              2.0.3 2019-09-22\n## pkgload                1.3.2 2022-11-16\n## plyr                   1.8.8 2022-11-11\n## prettyunits            1.1.1 2020-01-24\n## processx               3.8.0 2022-10-26\n## profvis                0.3.7 2020-11-02\n## promises             1.2.0.1 2021-02-11\n## proto                  1.0.0 2016-10-29\n## ps                     1.7.3 2023-03-21\n## purrr                  1.0.1 2023-01-10\n## R6                     2.5.1 2021-08-19\n## Rcpp                  1.0.10 2023-01-22\n## remotes                2.4.2 2021-11-30\n## rlang                  1.1.0 2023-03-14\n## rmarkdown               2.21 2023-03-26\n## rpart                 4.1.19 2022-10-21\n## rprojroot              2.0.3 2022-04-02\n## rstudioapi              0.14 2022-08-22\n## sass                   0.4.5 2023-01-24\n## scales                 1.2.1 2022-08-20\n## sessioninfo            1.2.2 2021-12-06\n## shiny                  1.7.4 2022-12-15\n## showtext               0.9-5 2022-02-09\n## showtextdb               3.0 2020-06-04\n## stringi               1.7.12 2023-01-11\n## stringr                1.5.0 2022-12-02\n## survival               3.5-5 2023-03-12\n## sysfonts               0.8.8 2022-03-13\n## tibble                 3.2.1 2023-03-20\n## tidyr                  1.3.0 2023-01-24\n## tidyselect             1.2.0 2022-10-10\n## unmarked               1.2.5 2022-05-13\n## untidydata             0.1.1 2022-09-22\n## urlchecker             1.0.1 2021-11-30\n## usethis                2.1.6 2022-05-25\n## utf8                   1.2.3 2023-01-31\n## vctrs                  0.6.1 2023-03-22\n## VGAM                   1.1-8 2023-03-09\n## viridisLite            0.4.1 2022-08-22\n## withr                  2.5.0 2022-03-03\n## xfun                    0.38 2023-03-24\n## xtable                 1.8-4 2019-04-21\n## yaml                   2.3.7 2023-01-23\n```\n:::\n",
    "supporting": [
      "2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}