[
  {
    "objectID": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html",
    "href": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html",
    "title": "Exploring phonemic boundaries using logistic regression",
    "section": "",
    "text": "This post is about phonemic boundaries. Imagine we are interested in understanding stop voicing distinctions in English/Spanish bilinguals. English and Spanish have the same stop voicing contrasts at bilabial (/b, p/), coronal (/d, t/), and velar (/g, k/) place, but the phonetic realizations differ in a variety of ways. We will focus on voice-onset time (VOT). English has contrasts between lag stops (short-lag vs. long-lag VOT) and Spanish is a true voicing language, i.e., the contrasts are between phonetically voiced and short-lag stops.\n\n\n\n\n\n\n\n\nLanguage\nStops\nPhonetic realization\n\n\n\n\nEnglish\n/bdg/\nshort-lag VOT\n\n\n\n/ptk/\nlong-lag VOT\n\n\nSpanish\n/bdg/\nlead VOT\n\n\n\n/ptk/\nshort-lag VOT\n\n\n\n\n\n\n\nFor an adult English speaker that wants to learn Spanish, one difficulty they encounter is related to VOT, that is, they have to learn the VOT patterns of Spanish, which differ from those of English. As a method of assessing phonological learning in second language acquisition (SLA), we might be interested in knowing if the boundary between a voiced/voiceless pair is different in English than in Spanish for a group of individuals who learned Spanish as adults.\nOne way researchers do this is by (re)synthesizing acoustic stimuli to create a VOT continuum and then asking learners to categorize the sounds. What we typically see is that for one end of the continuum all the stimuli are categorized as being ‘voiced’ and then at some point there is a shift to ‘voiceless’. Where this shift occurs is what we are after in this post.\n\n\n\n\n\n\n\n\n\nThe shift usually occurs further to the left for Spanish speakers than for English speakers, which is a consequence of the phonetic nature of the voicing contrasts, i.e., lead vs. short-lag (Spanish) or short-lag vs. long-lag (English). So, for an adult English speaker that is proficient in Spanish, one might expect different identification functions depending on which language they are identifying, Spanish or English.\nIn this post I am going to simulate data from this type of experiment and analyze them in a variety of ways. One fun detail, the experimental design assumes that the participants are always identifying the same stimuli, but we will tell them that they are hearing a different language, Spanish or English, in different experimental sessions.\n\nThere are a series of experiments that do this. I won’t go into more detail here, but check out Gonzales et. al (2019), and Lozano et. al (2020) for recent examples.\n\nThese are the packages I will primarily be using:\n\nlibrary(\"dplyr\")      # Data wrangling\nlibrary(\"tidyr\")      # Data wrangling\nlibrary(\"purrr\")      # Iteration on lists\nlibrary(\"lme4\")       # Model fitting\nlibrary(\"AICcmodavg\") # Model preds\nlibrary(\"ggplot2\")    # Plotting"
  },
  {
    "objectID": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#a-bit-of-background",
    "href": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#a-bit-of-background",
    "title": "Exploring phonemic boundaries using logistic regression",
    "section": "",
    "text": "This post is about phonemic boundaries. Imagine we are interested in understanding stop voicing distinctions in English/Spanish bilinguals. English and Spanish have the same stop voicing contrasts at bilabial (/b, p/), coronal (/d, t/), and velar (/g, k/) place, but the phonetic realizations differ in a variety of ways. We will focus on voice-onset time (VOT). English has contrasts between lag stops (short-lag vs. long-lag VOT) and Spanish is a true voicing language, i.e., the contrasts are between phonetically voiced and short-lag stops.\n\n\n\n\n\n\n\n\nLanguage\nStops\nPhonetic realization\n\n\n\n\nEnglish\n/bdg/\nshort-lag VOT\n\n\n\n/ptk/\nlong-lag VOT\n\n\nSpanish\n/bdg/\nlead VOT\n\n\n\n/ptk/\nshort-lag VOT\n\n\n\n\n\n\n\nFor an adult English speaker that wants to learn Spanish, one difficulty they encounter is related to VOT, that is, they have to learn the VOT patterns of Spanish, which differ from those of English. As a method of assessing phonological learning in second language acquisition (SLA), we might be interested in knowing if the boundary between a voiced/voiceless pair is different in English than in Spanish for a group of individuals who learned Spanish as adults.\nOne way researchers do this is by (re)synthesizing acoustic stimuli to create a VOT continuum and then asking learners to categorize the sounds. What we typically see is that for one end of the continuum all the stimuli are categorized as being ‘voiced’ and then at some point there is a shift to ‘voiceless’. Where this shift occurs is what we are after in this post.\n\n\n\n\n\n\n\n\n\nThe shift usually occurs further to the left for Spanish speakers than for English speakers, which is a consequence of the phonetic nature of the voicing contrasts, i.e., lead vs. short-lag (Spanish) or short-lag vs. long-lag (English). So, for an adult English speaker that is proficient in Spanish, one might expect different identification functions depending on which language they are identifying, Spanish or English.\nIn this post I am going to simulate data from this type of experiment and analyze them in a variety of ways. One fun detail, the experimental design assumes that the participants are always identifying the same stimuli, but we will tell them that they are hearing a different language, Spanish or English, in different experimental sessions.\n\nThere are a series of experiments that do this. I won’t go into more detail here, but check out Gonzales et. al (2019), and Lozano et. al (2020) for recent examples.\n\nThese are the packages I will primarily be using:\n\nlibrary(\"dplyr\")      # Data wrangling\nlibrary(\"tidyr\")      # Data wrangling\nlibrary(\"purrr\")      # Iteration on lists\nlibrary(\"lme4\")       # Model fitting\nlibrary(\"AICcmodavg\") # Model preds\nlibrary(\"ggplot2\")    # Plotting"
  },
  {
    "objectID": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#getting-data",
    "href": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#getting-data",
    "title": "Exploring phonemic boundaries using logistic regression",
    "section": "Getting data",
    "text": "Getting data\nThe first thing we need to do is get some data. In this post I am going to simulate data that is similar to the output you would get from a two-alternative forced choice (2AFC) task, but before we simulate we need to discuss the experimental paradigm a bit so that everything makes sense.\nA 2AFC task is quite simple. The participant is presented something—in this case auditory stimuli—and then make a binary decision about it.\n\nYou can see code and examples of this type of task in python here.\n\nIn this particular hypothetical experiment participants are presented stimuli that is randomly drawn from a VOT continuum ranging from -60 to 60 ms in 10 ms steps (that’s 13 steps total). We will present the entire continuum 15 times, so each participant will provide 195 responses. This would be an extremely boring experiment, but that’s another discussion. We will assume the experiment is given in two sessions, a Spanish session and an English session. The only difference between sessions is that the participants will be told that they are going to categorize English stimuli in the English session and Spanish stimuli in the Spanish session. Importantly, the actual continuum of stimuli they hear is exactly the same. Tricky, right?\n\nThe crucial question here is whether or not proficient adult language learners adjust their perceptual boundaries based on their underlying expectations about the language. It turns out they do! Here is second shameless plug for the Lozano et. al (2020) paper. 😄\n\nWe will simulate data for 25 participants, and two language sessions (or language modes), English and Spanish. If you’re doing the math, that is 25 participants \\(\\times\\) 13 steps \\(\\times\\) 15 item repetitions \\(\\times\\) 2 language modes, which gives us a data set with a grand total of 9750 responses (i.e., 9750 rows in the dataframe). (Note: If you aren’t interested in the whole simulation process just skip the next section.)"
  },
  {
    "objectID": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#specifying-the-model",
    "href": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#specifying-the-model",
    "title": "Exploring phonemic boundaries using logistic regression",
    "section": "Specifying the model",
    "text": "Specifying the model\nOur criterion is binary (0/1) responses. Specifically, this refers to whether the participant responds ‘voiced’ (0) or ‘voiceless’ (1) to each pull from the VOT continuum. For this reason we will simulate from the binomial distribution. Our model will look something like this:\n\\[\n\\begin{aligned}\nresponse_{i} \\sim & \\ Binomial(p_{i}, m_{i}) \\\\\nlogit(p_{i}) = & \\ \\beta_{0} + \\beta_{1} * VOT_{1} + \\beta_{2} * I_{(language_{i} = Spanish)2} + \\beta_{3} * VOT_{1} * I_{2}\n\\end{aligned}\n\\]\n…where we analyze the log odds of ‘voiceless’ responses as a function of VOT, i.e., the step in the continuum, language mode (if they think they are hearing English or Spanish) and the interaction between the two.\n\n# Set seed for reproducibility\nset.seed(20210514)\n\n# dataframe params\nn_ids       &lt;- 25\nn_steps     &lt;- 13\nn_lang      &lt;- 2\nn_item_reps &lt;- 15\n\n# Set up dataframe\nid        &lt;- rep(glue::glue(\"id_{1:n_ids}\"), each = n_steps * n_lang)\nvot       &lt;- rep(seq(-60, 60, 10), times = n_ids * n_lang)\nlanguage  &lt;- rep(c(\"English\", \"Spanish\"), each = n_steps, times = n_ids)\ndat       &lt;- data.frame(id, vot, language, n_item_reps)\n\n# Model params\nb0          &lt;- -1.10 # intercept\nb1          &lt;-  0.09 # slope VOT\nb2          &lt;-  0.80 # language effect\nb12         &lt;- -0.06 # slope adj. for Spanish\nid_var      &lt;-  0.20 # id variability\nstep_var    &lt;-  0.50 # step variability\nlang_var    &lt;-  0.11 # lang variability\n\n# Simulate random effects\nid_eff   &lt;- rep(rnorm(n = n_ids, mean = 0, sd = id_var), each = n_steps * n_lang)\nstep_eff &lt;- replicate(n = n_ids, rep(rnorm(n_steps, 0, step_var), times = n_lang), \n              simplify = F) %&gt;% \n            unlist()\n\n# Get log odds from linear predictor and convert to probability\nlog_odds &lt;- b0 + \n            b1 * vot + \n            b2 * (language == \"Spanish\") + \n            b1 * vot * b12 * (language == \"Spanish\") + \n            id_eff + step_eff \nprop     &lt;- plogis(log_odds)\n\n# Generate binomial responses\ndat$response &lt;- rbinom(n = n_ids * n_steps * n_lang, size = n_item_reps, prob = prop)\n\n# Expand binomial responses to binary\ndat_long &lt;- dat %&gt;%\n  nest(data = c(response, n_item_reps)) %&gt;%\n  mutate(response = map(data, ~c(rep(1, .x$response),\n                                 rep(0, .x$n_item_reps - .x$response)))) %&gt;%\n  select(-data) %&gt;%\n  unnest(response) %&gt;% \n  group_by(id, vot, language) %&gt;% \n  mutate(item_rep = seq_along(vot)) %&gt;% \n  ungroup() %&gt;% \n  mutate(item_rep = (item_rep - mean(item_rep)) / sd(item_rep), \n         vot_std = (vot - mean(vot)) / sd(vot))\n  \n\nThe code above simulates the data set. I won’t go into detail about how it works (maybe for another post), but I do want to point out two things: 1) I’ve added an item_rep variable to keep track of what repetition (out of 15) a given response comes from, and 2) I have standardized vot (vot_std) and item_rep in order to improve computational efficiency of the model. It will be important to keep this in mind when we begin analyzing and plotting the results.\n\nThese models are notoriously slow in lme4 and often have convergence issues. I normally work in a Bayesian framework, so I might update this at some point.\n\nHere is what the output of one block of the experiment for one participant looks like:\n\ndat_long %&gt;% \n  filter(item_rep == 0) %&gt;% \n  select(-item_rep, -vot_std) %&gt;% \n  head(., 13) %&gt;% \n  gt::gt()\n\n\n\n\n\n\n\nid\nvot\nlanguage\nresponse\n\n\n\n\nid_1\n-60\nEnglish\n0\n\n\nid_1\n-50\nEnglish\n0\n\n\nid_1\n-40\nEnglish\n0\n\n\nid_1\n-30\nEnglish\n0\n\n\nid_1\n-20\nEnglish\n0\n\n\nid_1\n-10\nEnglish\n0\n\n\nid_1\n0\nEnglish\n0\n\n\nid_1\n10\nEnglish\n1\n\n\nid_1\n20\nEnglish\n1\n\n\nid_1\n30\nEnglish\n1\n\n\nid_1\n40\nEnglish\n1\n\n\nid_1\n50\nEnglish\n1\n\n\nid_1\n60\nEnglish\n1\n\n\n\n\n\n\n\nLooks good. Now we are ready to fit the model."
  },
  {
    "objectID": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#multilevel-logistic-regression-model",
    "href": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#multilevel-logistic-regression-model",
    "title": "Exploring phonemic boundaries using logistic regression",
    "section": "Multilevel logistic regression model",
    "text": "Multilevel logistic regression model\nAs mentioned above, our data is binary and we have repeated measures. We will fit a multilevel logistic regression model to account for nesting in the data. A key part here is the random effects structure, which will allow us to do some interesting individual differences analyses post-hoc.\n\n# Fit partial pooling model\nmod &lt;- glmer(\n  formula = response ~ vot_std * language + \n    (1 | id) + \n    (1 + vot_std + item_rep | id:language), \n  control = glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 2e6)), \n  family = binomial(link = \"logit\"), \n  data = dat_long\n  )\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-1.237854\n0.4765846\n-2.597343\n0.0093948\n\n\nvot_std\n3.538826\n0.4931981\n7.175262\n0.0000000\n\n\nlanguageSpanish\n1.598023\n0.1950572\n8.192588\n0.0000000\n\n\nvot_std:languageSpanish\n-0.338594\n0.2672184\n-1.267106\n0.2051175\n\n\n\n\n\nWe won’t focus on interpreting the output. Instead let’s use the model to generate predictions and plot those.\n\n# Setup new dataframe to predict on\nnew_dat &lt;- select(dat, -n_item_reps, -response) %&gt;% \n  mutate(vot_std = (vot - mean(vot)) / sd(vot))\n\n# Get model predictions and SE\nfits &lt;- predictSE(mod, new_dat) %&gt;%\n  as_tibble %&gt;%\n  mutate(ymin = fit - se.fit, ymax = fit + se.fit) %&gt;%\n  bind_cols(new_dat) \n\n# Plot it\np_sigmoids &lt;- fits %&gt;% \n  ggplot(., aes(x = vot_std, y = fit, color = language, fill = language)) + \n    geom_ribbon(aes(ymax = ymax, ymin = ymin), \n      alpha = 0.2, color = NA, show.legend = F) +\n    geom_line(linewidth = 0.75) + \n    geom_point(color = \"white\", stroke = 1.5, size = 4, pch = 21) + \n    geom_jitter(data = dat_long, \n      width = 0.2, height = 0.01, alpha = 0.02, pch = 21, \n      aes(x = vot_std, \n        y = if_else(response == 1, response + 0.05, response - 0.05))) + \n    labs(y = \"P(response = /p/)\", x = \"VOT (ms)\") + \n    scale_y_continuous(breaks = seq(0, 1, 0.25)) + \n    scale_x_continuous(breaks = unique(fits$vot_std)[c(TRUE, FALSE)], \n      labels = seq(-60, 60, 20)) + \n    scale_fill_viridis_d(name = NULL, begin = 0.3, end = 0.7) + \n    scale_color_viridis_d(name = NULL, begin = 0.3, end = 0.7) + \n    ds4ling::ds4ling_bw_theme(base_family = \"Palatino\") + \n    theme(legend.position = c(0.1, 0.87), legend.background = element_blank())\n\np_sigmoids\n\n\n\n\n\n\n\n\nCool. We can see that in our simulated data the Spanish sigmoid function is shifted to the left with regard to the English sigmoid function. This equates to more ‘voiceless’ responses when the participants believe they are hearing Spanish.\n\nCategory boundaries\nOne way this literature has assessed categorical perception in bilinguals is by calculating and comparing the 50% cross over point for each language. This is the point where the probability of responding ‘voiceless’ is exactly 0.5. If we just eyeball the plot above, we can guess that this is around -5 ms for Spanish and around 13 ms for English, but we can do better than just eyeballing it. We will use the following formula to calculate the boundary, which we’ll just call the “crossover” (CO), between /b-p/ for each language session:\n\\[\nCO_{En} = \\frac{\\beta_{0}}{\\beta_{1}} * -1\n\\]\nThis means, for English, we can calculate the 50% crossover by dividing the intercept by the slope for VOT and multiplying by -1. In case it’s not clear, intercept and slope refer to the fixed effect parameters we just estimated in the model. We can grab those estimates using fixef.\n\nfixef(mod)\n##             (Intercept)                 vot_std         languageSpanish \n##               -1.237854                3.538825                1.598023 \n## vot_std:languageSpanish \n##               -0.338594\n\nThe fixef function returns a vector containing the parameter estimates. Since English is the reference level, we just need the first two elements of the vector and we can calculate the boundary like this:\n\nen_co &lt;- (fixef(mod)[1] / fixef(mod)[2]) * -1\nen_co\n## (Intercept) \n##   0.3497923\n\nSo the boundary is at 0.35 standard deviations above the mean (0). We can make this value easier to interpret by back-transforming to milliseconds. We do this by adding the mean of the original VOT vector of the dataframe and multiplying by the standard deviation:\n\n# Calculate En CO in ms (note the mean is 0, so we could skip that)\n(en_co + mean(dat_long$vot)) * sd(dat_long$vot)\n## (Intercept) \n##     13.0887\n\nSo the English boundary is at about 13.09 ms (my guess was pretty close!). Let’s calculate the boundary for Spanish and plot them:\n\n# Add language effect on the intercept and slope adj for language == Spanish\nsp_co &lt;- (fixef(mod)[1] + fixef(mod)[3]) / (fixef(mod)[2] + fixef(mod)[4]) * -1\nsp_co\n## (Intercept) \n##  -0.1125447\n\n\n# Create tibble with boundaries and text\nco_text &lt;- tribble(\n  ~'vot_std', ~'fit', ~'language', ~'text', \n  -1.6, 0.5, \"Spanish\", paste0(\"Spanish boundary = \", round(sp_co * sd(dat_long$vot), 2), \" ms\"), \n   0.6, 0.5, \"English\", paste0(\"English boundary = \", round(en_co * sd(dat_long$vot), 2), \" ms\")\n)\n\n# Add to base plot\np_sigmoids + \n  geom_vline(xintercept = c(en_co, sp_co), lty = 3) + \n  geom_text(data = co_text, aes(label = text), \n            hjust = 0, size = 4, family = \"Times\") \n\n\n\n\n\n\n\n\n\n\nContrast coefficient slopes\nAnother way we can assess how the acoustic stimuli are categorized is by looking at the slope of the sigmoid functions at the category boundary (i.e., the 50% crossover point). We do this by calculating the contrast coefficient slope (CCS). Essentially the CCS in the logistic space is related to the slope of the sigmoid function and represents the rate of change from one category to another (i.e., from /b/ to /p/ in our case) in the probability space.\nMorrison (2007) describes CCSs as “indicators of the crispness of the boundary between the two categories” (p. 232). Native speakers typically have crisp boundaries between categories, whereas non-native speakers can have “fuzzier” boundaries for a number of reasons.\n\nSee: Morrison, G. (2007). Logistic regression modeling for first- and second-language perception data. In: Solé M-J, Prieto P, and Mascaró J (eds), Segmental and prosodic issues in Romance phonology. Amsterdam: John Benjamins, 219–36.\n\nI will spare you the calculus, but in a few words the CCS in the probability space is the partial derivative of the slope of the sigmoid function at its steepest point. Conveniently, the steepest value of the slope in the binomial case is when the probability of the criterion is 0.5, i.e., at the crossover boundary. We can calculate the CCS by multiplying the slope of the continuous measure by 0.25:\n\\[\nCCS_{En} = \\beta_{VOT} * 0.25\n\\]\nSo for English, the CCS is calculated as:\n\nen_ccs &lt;- fixef(mod)[2] * 0.25\nen_ccs\n##   vot_std \n## 0.8847064\n\nThis means that when the the probability of responding ‘voiceless’ is 0.5, the slope of the sigmoid for English is 0.88 in the probability space. We can calculate this for both languages and plot the lines:\n\nsp_ccs &lt;- (fixef(mod)[2] + fixef(mod)[4]) * 0.25\n\nccs_text &lt;- tribble(\n  ~'vot_std', ~'fit', ~'language', ~'text', \n  -1.2, 0.5, \"Spanish\", paste0(\"Spanish CCS = \", round(sp_ccs, 2)), \n   0.6, 0.5, \"English\", paste0(\"English CCS = \", round(en_ccs, 2))\n)\n\np_sigmoids + \n  geom_abline(intercept = 0.5 - en_ccs * en_co, slope = en_ccs, lty = 2) + \n  geom_abline(intercept = 0.5 - sp_ccs * sp_co, slope = sp_ccs, lty = 2) + \n  geom_text(data = ccs_text, aes(label = text), \n            hjust = 0, size = 4, family = \"Times\") \n\n\n\n\n\n\n\n\nAs you can see, the two category boundaries are ‘crisp’ in both cases. This is because I simulated the data to be this way, but this leads us to more interesting territory… we can explore crossover boundaries and contrast coefficient slopes for individuals. Perhaps we are interested in 50% crossover differences as a function of language dominance, or boundary crispness as a function of proficiency. We’ll look at a few ways to do that now."
  },
  {
    "objectID": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#individual-differences",
    "href": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#individual-differences",
    "title": "Exploring phonemic boundaries using logistic regression",
    "section": "Individual differences",
    "text": "Individual differences\nThere are at least 2 ways to calculate 50% crossover boundaries and contrast coefficient slopes for individual participants. One method is to use the random effects from the omnibus model we fit above (i.e., mod). Another method is fit a logistic regression to the data of each participant. I’ll go with this no-pooling method, but one should certainly give careful thought to both methods and decide which makes the most sense for the research questions of interest.\nWe can easily fit a model to each individual using the lmList function from the lme4 package:\n\n# Fit no pooling model(s)\nno_pool_full &lt;- lmList(response ~ vot_std * language | id, family = \"binomial\", \n  data = as.data.frame(dat_long))\n\nI’ll use the coef and head functions to take a peak at the structure of the resulting object.\n\ncoef(no_pool_full) %&gt;% head\n##       (Intercept)  vot_std languageSpanish vot_std:languageSpanish\n## id_1   -1.0814034 3.663940       0.6900609             -0.30420433\n## id_10  -1.1861547 3.059800       1.2626094             -0.24044950\n## id_11  -1.4045661 3.184317       1.1704759             -0.30283595\n## id_12  -0.5402269 3.552218       0.6148052             -0.80768856\n## id_13  -1.0842951 3.457762       0.6257084             -0.46301851\n## id_14  -0.6622088 2.935729       0.5329204             -0.07208159\n\nNice! With a little bit of wrangling and the formulas we looked at previously, we can calculate the CO and CCS of each individual for English and Spanish.\n\nid_diffs &lt;- no_pool_full %&gt;% \n  coef() %&gt;% \n  as_tibble() %&gt;% \n  transmute(\n    id = rownames(coef(no_pool_full)), \n    int_English = `(Intercept)`, \n    vot_English = vot_std, \n    int_Spanish = int_English + languageSpanish, \n    vot_Spanish = vot_English + `vot_std:languageSpanish`, \n    co_English  = int_English / vot_English * -1, \n    co_Spanish  = int_Spanish / vot_Spanish * -1, \n    ccs_English = vot_English * 0.25, \n    ccs_Spanish = vot_Spanish * 0.25) %&gt;% \n  select(-vot_English, -vot_Spanish) %&gt;% \n  pivot_longer(\n    cols = -id, \n    names_to = c(\".value\", \"language\"), \n    names_sep = \"_\"\n    ) %&gt;% \n  mutate(co_ms = co * sd(dat_long$vot))\n\nhead(id_diffs)\n## # A tibble: 6 × 6\n##   id    language     int      co   ccs co_ms\n##   &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 id_1  English  -1.08    0.295  0.916 11.0 \n## 2 id_1  Spanish  -0.391   0.116  0.840  4.36\n## 3 id_10 English  -1.19    0.388  0.765 14.5 \n## 4 id_10 Spanish   0.0765 -0.0271 0.705 -1.01\n## 5 id_11 English  -1.40    0.441  0.796 16.5 \n## 6 id_11 Spanish  -0.234   0.0812 0.720  3.04\n\nNow we are ready to make some plots.\n\n# COs\np_co &lt;- id_diffs %&gt;% \n  ggplot(., aes(x = co_ms, y = language)) + \n    geom_jitter(width = 0.1, height = 0.2, alpha = 0.5, pch = 16) + \n    stat_summary(fun.data = mean_sdl, geom = \"pointrange\", pch = 21, \n      fill = \"white\", size = 1.2, fun.args = list(mult = 1)) + \n    labs(y = \"Language\", x = \"Crossover boundary (ms)\", caption = \"\") + \n    ds4ling::ds4ling_bw_theme(base_family = \"Palatino\")\n\n# CCSs\np_ccs &lt;- id_diffs %&gt;% \n  ggplot(., aes(x = ccs, y = language)) + \n    geom_jitter(width = 0.1, height = 0.2, alpha = 0.5, pch = 16) + \n    stat_summary(fun.data = mean_sdl, geom = \"pointrange\", pch = 21, \n      fill = \"white\", size = 1.2, fun.args = list(mult = 1)) + \n    labs(y = NULL, x = \"Contrast coefficient slopes\", caption = \"Mean +/- SD\") + \n    ds4ling::ds4ling_bw_theme(base_family = \"Palatino\") + \n    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())\n\np_co + p_ccs\n\n\n\n\n\n\n\n\nWe can also plot the sigmoids of individuals along with the 50% crossovers, as well as the contrast coefficient slopes. Let’s find the individuals with the largest and smallest differences between English and Spanish boundaries, plus 6 more participants at random.\n\n# Calculate boundary diffs\nco_diffs &lt;- id_diffs %&gt;% \n  select(id, language, co) %&gt;% \n  pivot_wider(names_from = language, values_from = co) %&gt;% \n  mutate(diff = English - Spanish) \n\n# Find smallest and largest diffs\nco_min_max &lt;- c(\n  slice_max(co_diffs, diff, n = 1) %&gt;% pull(id), \n  slice_min(co_diffs, diff, n = 1) %&gt;% pull(id)\n)\n\n# Vector of min, max, plus 6 random subjects\nn_8 &lt;- c(\n  co_min_max, \n  filter(dat_long, (!id %in% co_min_max)) %&gt;% \n  distinct(id) %&gt;% \n  sample_n(6) %&gt;% pull\n)\n\n# Use diff column to order from smallest to largest\nordered_8 &lt;- co_diffs %&gt;% \n  filter(id %in% n_8) %&gt;% \n  arrange(diff) %&gt;% \n  pull(id)\n\nco_base &lt;- dat_long %&gt;% \n  filter(id %in% n_8) %&gt;% \n  mutate(id = forcats::fct_relevel(id, ordered_8)) %&gt;% \n  ggplot(., aes(x = vot_std, y = response, color = language)) + \n    facet_wrap(~id, nrow = 2) + \n    geom_jitter(width = 0.2, height = 0.01, alpha = 0.1, pch = 21, size = 0.6, \n      aes(y = if_else(response == 1, response + 0.05, response - 0.05))) + \n    stat_summary(fun = mean, geom = \"line\", \n      aes(y = fitted(no_pool_full)[names(fitted(no_pool_full)) %in% ordered_8])) + \n    labs(y = \"P(response = /p/)\", x = \"VOT (ms)\") + \n    scale_y_continuous(breaks = seq(0, 1, 0.25)) + \n    scale_x_continuous(breaks = unique(dat_long$vot_std)[c(TRUE, FALSE, FALSE)], \n      labels = seq(-60, 60, 30)) + \n    scale_fill_viridis_d(name = NULL, begin = 0.3, end = 0.7) + \n    scale_color_viridis_d(name = NULL, begin = 0.3, end = 0.7) + \n    ds4ling::ds4ling_bw_theme(base_family = \"Palatino\", base_size = 10) + \n    theme(legend.position = \"bottom\", \n      strip.background = element_blank(),\n      strip.placement = \"outside\")\n\nco_base + \n  geom_vline(\n    data = filter(id_diffs, id %in% n_8) %&gt;% \n      mutate(id = forcats::fct_relevel(id, ordered_8)), \n    aes(xintercept = co, color = language), lty = 3, show.legend = F)\n\n\n\n\n\n\n\n\nco_base + \n  geom_abline(\n    data = filter(id_diffs, id %in% n_8) %&gt;% \n      mutate(id = forcats::fct_relevel(id, ordered_8)),\n    aes(intercept = 0.5 - co * ccs, slope = ccs, group = language), lty = 3, \n    show.legend = F)\n\n\n\n\n\n\n\n\nAwesome! We can see that there are some individuals that have category boundaries in essentially the same place, while others show clear differences between English and Spanish. I simulated the data to have similar slopes (the VOT x language interaction), but we still see a bit of variability in CCS plot."
  },
  {
    "objectID": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#wrapping-up",
    "href": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#wrapping-up",
    "title": "Exploring phonemic boundaries using logistic regression",
    "section": "Wrapping up",
    "text": "Wrapping up\nI think that is enough for one post. We’ve seen that multilevel logistic regression is an awesome tool for exploring different aspects of bilingualism and second language acquisition. Category boundaries and contrast coefficient slopes are a few metrics I have found to be quite handy in my research.\n\nBonus\nI mentioned that you could calculate the individual boundaries using the random effects from the omnibus model or fit a model to each individual. Crossover boundaries tend to be a bit unwieldy in the wild, i.e., when you aren’t simulating data with 15 item repetitions. It may be the case that having the regularization that comes with partial pooling is preferable when assessing different areas of individual differences. This is just as easy to do by using the ranef function with the original model object, mod.\n\nranef(mod)[[1]] %&gt;% \n  tibble::rownames_to_column(var = \"id\") %&gt;% \n  separate(col = id, into = c(\"id\", \"language\"), sep = \":\") %&gt;% \n  pivot_wider(names_from = language, \n    values_from = c(\"(Intercept)\", \"vot_std\", \"item_rep\")) %&gt;% \n  transmute(\n    id = id, \n    int_English = fixef(mod)[1] + `(Intercept)_English`, \n    int_Spanish = fixef(mod)[1] + fixef(mod)[3] + `(Intercept)_Spanish`, \n    slope_English = fixef(mod)[2] + vot_std_English, \n    slope_Spanish = fixef(mod)[2] + fixef(mod)[4] + vot_std_Spanish, \n    co_English  = int_English / slope_English * -1, \n    co_Spanish  = int_Spanish / slope_Spanish * -1, \n    ccs_English = slope_English * 0.25, \n    ccs_Spanish = slope_Spanish * 0.25) %&gt;% \n  select(-c(2:5)) %&gt;% \n  head\n## # A tibble: 6 × 5\n##   id    co_English co_Spanish ccs_English ccs_Spanish\n##   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n## 1 id_1       0.374     0.182         1.96        1.89\n## 2 id_10      0.356    -0.0329        1.85        1.19\n## 3 id_11      0.369     0.0343        1.89        1.37\n## 4 id_12      0.350     0.133         1.91        1.79\n## 5 id_13      0.354     0.189         1.63        2.10\n## 6 id_14      0.306     0.114         1.49        1.68"
  },
  {
    "objectID": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#reproducibility-information",
    "href": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries.html#reproducibility-information",
    "title": "Exploring phonemic boundaries using logistic regression",
    "section": "Reproducibility information",
    "text": "Reproducibility information\nAbout this document\nThis document was written in RMarkdown using distill.\nSession info\n\ndevtools::session_info()$platform\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23)\n##  os       macOS Big Sur ... 10.16\n##  system   x86_64, darwin17.0\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       America/New_York\n##  date     2023-04-09\n##  pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\nas.data.frame(devtools::package_info())[, c(3, 8)]\n##                loadedversion       date\n## academicWriteR         0.4.1 2022-09-05\n## AICcmodavg             2.3-2 2023-03-20\n## backports              1.4.1 2021-12-13\n## base64enc              0.1-3 2015-07-28\n## boot                1.3-28.1 2022-11-22\n## broom                  1.0.4 2023-03-11\n## broom.mixed          0.2.9.4 2022-04-17\n## cachem                 1.0.7 2023-02-24\n## callr                  3.7.3 2022-11-02\n## checkmate              2.1.0 2022-04-21\n## cli                    3.6.1 2023-03-23\n## cluster                2.1.4 2022-08-22\n## codetools             0.2-19 2023-02-01\n## colorspace             2.1-0 2023-01-23\n## crayon                 1.5.2 2022-09-29\n## data.table            1.14.8 2023-02-17\n## devtools               2.4.5 2022-10-11\n## digest                0.6.31 2022-12-11\n## dplyr                  1.1.1 2023-03-22\n## ds4ling                  0.7 2022-09-22\n## ellipsis               0.3.2 2021-04-29\n## emojifont              0.5.5 2021-04-20\n## evaluate                0.20 2023-01-17\n## fansi                  1.0.4 2023-01-22\n## farver                 2.1.1 2022-07-06\n## fastmap                1.1.1 2023-02-24\n## forcats                1.0.0 2023-01-29\n## foreign               0.8-84 2022-12-06\n## Formula                1.2-5 2023-02-24\n## fs                     1.6.1 2023-02-06\n## furrr                  0.3.1 2022-08-15\n## future                1.32.0 2023-03-07\n## generics               0.1.3 2022-07-05\n## ggplot2                3.4.2 2023-04-03\n## globals               0.16.2 2022-11-21\n## glue                   1.6.2 2022-02-24\n## gridExtra                2.3 2017-09-09\n## gt                     0.8.0 2022-11-16\n## gtable                 0.3.3 2023-03-21\n## here                   1.0.1 2020-12-13\n## Hmisc                  5.0-1 2023-03-08\n## htmlTable              2.4.1 2022-07-07\n## htmltools              0.5.5 2023-03-23\n## htmlwidgets            1.6.2 2023-03-17\n## httpuv                 1.6.9 2023-02-14\n## jsonlite               1.8.4 2022-12-06\n## knitr                   1.42 2023-01-25\n## labeling               0.4.2 2020-10-20\n## later                  1.3.0 2021-08-18\n## latex2exp              0.9.6 2022-11-28\n## lattice              0.20-45 2021-09-22\n## lifecycle              1.0.3 2022-10-07\n## listenv                0.9.0 2022-12-16\n## lme4                  1.1-32 2023-03-14\n## magrittr               2.0.3 2022-03-30\n## MASS                7.3-58.3 2023-03-07\n## Matrix                 1.5-3 2022-11-11\n## memoise                2.0.1 2021-11-26\n## mime                    0.12 2021-09-28\n## miniUI               0.1.1.1 2018-05-18\n## minqa                  1.2.5 2022-10-19\n## munsell                0.5.0 2018-06-12\n## nlme                 3.1-162 2023-01-31\n## nloptr                 2.0.3 2022-05-26\n## nnet                  7.3-18 2022-09-28\n## parallelly            1.35.0 2023-03-23\n## patchwork              1.1.2 2022-08-19\n## pbapply                1.7-0 2023-01-13\n## pillar                 1.9.0 2023-03-22\n## pkgbuild               1.4.0 2022-11-27\n## pkgconfig              2.0.3 2019-09-22\n## pkgload                1.3.2 2022-11-16\n## plyr                   1.8.8 2022-11-11\n## prettyunits            1.1.1 2020-01-24\n## processx               3.8.0 2022-10-26\n## profvis                0.3.7 2020-11-02\n## promises             1.2.0.1 2021-02-11\n## proto                  1.0.0 2016-10-29\n## ps                     1.7.3 2023-03-21\n## purrr                  1.0.1 2023-01-10\n## R6                     2.5.1 2021-08-19\n## Rcpp                  1.0.10 2023-01-22\n## remotes                2.4.2 2021-11-30\n## rlang                  1.1.0 2023-03-14\n## rmarkdown               2.21 2023-03-26\n## rpart                 4.1.19 2022-10-21\n## rprojroot              2.0.3 2022-04-02\n## rstudioapi              0.14 2022-08-22\n## sass                   0.4.5 2023-01-24\n## scales                 1.2.1 2022-08-20\n## sessioninfo            1.2.2 2021-12-06\n## shiny                  1.7.4 2022-12-15\n## showtext               0.9-5 2022-02-09\n## showtextdb               3.0 2020-06-04\n## stringi               1.7.12 2023-01-11\n## stringr                1.5.0 2022-12-02\n## survival               3.5-5 2023-03-12\n## sysfonts               0.8.8 2022-03-13\n## tibble                 3.2.1 2023-03-20\n## tidyr                  1.3.0 2023-01-24\n## tidyselect             1.2.0 2022-10-10\n## unmarked               1.2.5 2022-05-13\n## untidydata             0.1.1 2022-09-22\n## urlchecker             1.0.1 2021-11-30\n## usethis                2.1.6 2022-05-25\n## utf8                   1.2.3 2023-01-31\n## vctrs                  0.6.1 2023-03-22\n## VGAM                   1.1-8 2023-03-09\n## viridisLite            0.4.1 2022-08-22\n## withr                  2.5.0 2022-03-03\n## xfun                    0.38 2023-03-24\n## xtable                 1.8-4 2019-04-21\n## yaml                   2.3.7 2023-01-23"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "OverviewProjectsPublicationsPresentations\n\n\n\nI am currently in the process of setting up my research laboratory at Rutgers University. You can find more information here: https://RAP-group.github.io. My main interests are in phonetics, laboratory phonology, and second language acquisition. A principle aim of my research is to better understand the relationship between language use and sound representation in the mind, as well as the structure of sound systems in human languages. Most of my research is conducted on bilinguals of varying proficiency and linguistic experience. Feel free to explore the tabs on this page if you are interested in knowing more about my research projects.\n\n\n\n\nCurrent projects\n\n\n\n\n\n\nLongitudinal development of fine-phonetic detail in late learners\n\n\n\n\n\n\nThis ongoing project explores L2 category formation and the relationship between speech production and speech perception during the early stages of L2 acquisition. The data were/are collected in a stateside immersion program over the course of a summer. The participants complete a variety of tasks aimed at analyzing their acquisition of various L2 segments, such as: stops, trills, laterals and vowels.\n\n\n\n\n\n\n\n\n\n\nLanguage-specific perceptual normalization in adult L2 acquisition\n\n\n\n\n\n\nThis project explores a long history of ‘language set’ experiments with the goal of furthering our understanding of how bilinguals deal with the lack of invariance in the speech signal, both between and within languages. The project has implications for category formation and the development of bilingual language modes.\n(with Miquel Simonet)\n\n\n\n\n\n\n\n\n\n\nProduction/perception of English/Spanish coronal stops\n\n\n\n\n\n\nThis project has explored the acoustic characteristics of coronal stops in Spanish and English (link), the effects of stress on VOT in the Spanish/English monolinguals and bilinguals (link), as well as acoustic evidence for language-specific places of articulation (in preparation).\n(with Miquel Simonet and Yamile Díaz)\n\n\n\n\n\n\n\n\n\n\nSemantic predictability and speech rate effects in second language speech\n\n\n\n\n\ncategorization\n\nMore info coming soon.\n(with Miquel Simonet and Imanol Suárez Palma)\n\n\n\n\n\n\n\n\n\n\nMorphosyntactic predictability\n\n\n\n\n\n\nMore info coming soon.\n\n\n\n\n\n\nPrevious Projects\n\n\n\n\n\n\nProduction/perception of switch dominance speakers of English\n\n\n\n\n\n\nYou can read about this project in my 2015 article published in Phonetica, or in a co-authored 2016 article that appeared in Second Language Research.\n\n\n\n\n\n\n\n\n\n\nSelective adaptation\n\n\n\n\n\n\nThis project was co-authored with Miquel Llompart García. You can read the final publication in JASA.\n\n\n\n\n\n\n\n\nIn press\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas Unraveling the Complexities of L2 Lexical Stress: L1 Transfer, L2 Proficiency, and L2 Exposure.\n\n\nRecent Publications\nBochynska, A., L. Keeble, C. Halfacre, J. V. Casillas, I. Champagne, K. Chen, M. Röthlisberger, E. M. Buchanan, and T. B. Roettger (2023). “Reproducible research practices and transparency across Linguistics”. In: Glossa Psycholinguistics 2 (1), pp. 1-36. DOI: 10.5070/G6011239.\nSagarra, N. and J. V. Casillas (2023). “Practice beats age: Co-activation shapes heritage speakers’ lexical access more than age of onset”. In: Frontiers in Psychology 14, pp. 1-18. DOI: 10.3389/fpsyg.2023.1141174.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2023). “Interpreting experience and working memory effects on L1 and L2 morphological prediction”. In: Frontiers in Language Sciences 1, pp. 1-16. DOI: 10.3389/flang.2022.1065014.\nCoretta, S., J. V. Casillas, S. Roessig, M. Franke, B. Ahn, A. H. Al-Hoorie, J. Al-Tamimi, N. E. Alotaibi, M. K. AlShakhori, R. M. Altmiller, et al. (2023). “Multidimensional Signals and Analytic Flexibility: Estimating Degrees of Freedom in Human-Speech Analyses”. In: Advances in Methods and Practices in Psychological Science 6.3, pp. 1-29. DOI: 10.1177/25152459231162567.\nCasillas, J. V., J. J. Garrido-Pozú, K. Parrish, L. Fernández Arroyo, N. Rodríguez, R. Esposito, I. Chang, K. Gómez, G. Constantin-Dureci, J. Shao, et al. (2023). “Using intonation to disambiguate meaning: The role of empathy and proficiency in L2 perceptual development”. In: Applied Psycholinguistics 44.5, pp. 913-940. DOI: 10.1017/S0142716423000310.\nCarignan, C., J. V. Casillas, E. Chodroff, and G. Zellou (2022). “Editorial: Fuzzy boundaries: Ambiguity in speech production and comprehension”. In: Frontiers in Communication 7, pp. 1-3. DOI: 10.3389/fcomm.2022.1112753.\nJiménez-Crespo, M. and J. V. Casillas (2021). “Literal is not always easier: Literal and default translation, post-editing effort, and comparable corpora”. In: Translation, Cognition & Behavior 4.1, pp. 98-123. DOI: https://doi.org/10.1075/tcb.00048.jim.\nCasillas, J. V. (2021). “Interlingual Interactions Elicit Performance Mismatches Not ‘Compromise’ Categories in Early Bilinguals: Evidence from Meta-Analysis and Coronal Stops”. In: Languages 6.9, pp. 1-20. DOI: https://doi.org/10.3390/languages6010009.\nLozano-Argüelles, C., L. F. Arroyo, N. Rodríguez, E. Durand, J. J. G. Pozú, J. M. Rojas, J. Varela, N. de Rocafiguera, and J. V. Casillas (2021). “Conceptually cued perceptual categorization in adult L2 learners”. In: Studies in Second Language Acquisition 43.1, pp. 204-219. DOI: https://doi.org/10.1017/S0272263120000273.\nCasillas, J. V. (2020). “The longitudinal development of fine-phonetic detail: Stop production in a domestic immersion program”. In: Language Learning 70.3, pp. 768-806. DOI: https://doi.org/https://doi.org/10.1111/lang.12392.\nCasillas, J. V. (2020). “Phonetic category formation is perceptually driven during the early stages of adult L2 development”. In: Language and Speech 63.3, pp. 550-581. DOI: https://doi.org/10.1177/0023830919866225.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2020). “Slowly but surely: Interpreting facilitates L2 morphological anticipation based on suprasegmental and segmental information”. In: Bilingualism: Language and Cognition 23.4, pp. 752-762. DOI: https://doi.org/10.1017/S1366728919000634.\nCasillas, J. V. (2019). “Semantic processing triggers cross-linguistic interference during early phonetic category development”. In: ICPhS 19. Ed. by S. Calhoun, P. Escudero, M. Tabain and aul Warren. In Proceedings of the 19th International Congress of Phonetic Sciences. Melbourne, Australia 2019 (ISBN: 978-0-646-80069-1), pp. 3348-3352.\nCasillas, J. V. and M. Simonet (2018). “Perceptual categorization and bilingual language modes: Assessing the double phonemic boundary in early and late bilinguals”. In: Journal of Phonetics 71, pp. 51-64. DOI: https://doi.org/10.1016/j.wocn.2018.07.002.\nSagarra, N. and J. V. Casillas (2018). “Suprasegmental information cues morphological anticipation during L1/L2 lexical access”. In: Journal of Second Language Studies 1.1, pp. 31-59. DOI: https://doi.org/10.1075/jsls.17026.sag.\nBessett, R. M., J. V. Casillas, and M. Ramírez Martínez (2017). “Language choice and accommodation: Casual encounters in San Ysidro and Nogales”. In: Spanish in Context 14.1, pp. 78-98. DOI: https://doi.org/10.1075/sic.14.1.04bes.\nLlompart, M. and J. V. Casillas (2016). “Lexically driven selective adaptation by ambiguous auditory stimuli occurs after limited exposure to adaptors”. In: Journal of the Acoustical Society of America 139.5, pp. EL172-EL177. DOI: https://doi.org/10.1121/1.4951704.\nCasillas, J. V. and M. Simonet (2016). “Production and perception of the English /æ/-/ɑ/ contrast in switched-dominance speakers”. In: Second Language Research 32.2, pp. 171-195. DOI: https://doi.org/10.1177/0267658315608912.\nCasillas, J. V. (2015). “Production and perception of the /i/-/ɪ/ vowel contrast: The case of L2-dominant early learners of English”. In: Phonetica 72.2-3, pp. 182-205. DOI: https://doi.org/10.1159/000431101.\nCasillas, J. V., Y. Díaz, and M. Simonet (2015). “Acoustics of Spanish and English coronal stops”. In: ICPhS 18. Ed. by T. S. C. for ICPhS 2015. Proceedings of the 18th International Congress of Phonetic Sciences. University of Glasgow: Glasgow. http://www.icphs2015.info, ISSN: 241-0669, pp. 1-5.\nSimonet, M., J. V. Casillas, and Y. Díaz (2014). “The effects of stress/accent on VOT depend on language (English, Spanish), consonant (/d/, /t/) and linguistic experience (monolinguals, bilinguals)”. In: Speech Prosody 7. Ed. by N. Campbell, D. Gibbon and D. Hirst. Proceedings of the 7th international conference on Speech Prosody: Social and Linguistic Speech Prosody. Trinity College, Dublin. speechprosody2014.org, ISSN: 2333-2042, pp. 202-206.\nCasillas, J. V. (2013). “La fricativización del africado /tʃ/: actitudes lingüísticas cerca de la frontera”. In: Selected Proceedings of the 6th Workshop on Spanish Sociolinguistics. Ed. by A. M. Carvalho and S. Beaudrie. Somerville, MA: Cascadilla Proceedings Project. www.lingref.com, document #2867, pp. 177-188.\nCasillas, J. V. (2012). “La fricativización del africado /tʃ/ en el habla de las mujeres del sur de Arizona”. In: Divergencias: Revista de estudios lingüísticos y literarios 10.1, pp. 56-70.\nCasillas, J. V. (2010). “La vibrante múltiple intervocálica: los ejercicios de canto como ayuda a su pronunciación en español”. In: La Gaceta Hispánica de Madrid VIII. ISSN: 1886-1741.\nCasillas, J. V. (2009). “El uso de los refranes en El Quijote”. In: La Gaceta Hispánica de Madrid VIII. ISSN: 1886-1741.\n\n\nUnder review\nColina, S. and J. V. Casillas Variation in syllabification: Onglides in Sonoran Spanish.\nAndreu Rascón, I. and J. V. Casillas From Eyes to Ears: L2 visual and audio perception of Spanish vowels.\nCasillas, J. V., G. Constantin-Dureci, I. Andreu Rascón, J. Shao, S. A. Rodríguez, A. Gadamsetty, A. Minetti, K. Laungani, J. Thatcher, R. T. Gardere, et al. Opening open science to all: Demystifying reproducibility and transparency practices in linguistic research.\nCasillas, J. V. Bayesian statistics in Applied Linguistics. The Encyclopedia of Applied Linguistics, 2nd Edition.\nCoretta, S. and J. V. Casillas Generalized Additive Models for bilingual speech data.\n\n\nIn preparation\nGarrido Pozú, J. J. and J. V. Casillas Assessing language proficiency via vocabulary size.\nRodríguez, N. and J. V. Casillas A cross-sectional look at the production of lexical stress in Spanish-English early bilingual children.\nRodríguez, N. and J. V. Casillas The perception of lexical stress in early heritage bilinguals.\nRodríguez, N. and J. V. Casillas Perceptual gains via instructional games: An examination of perception and production of lexical stress in heritage bilingual children.\nCasillas, J. V., M. Simonet, and A. Aldrich Production of coronal stops in English and Spanish.\nCasillas, J. V. Semantic processing affects L2 stop production in late learners.\nCasillas, J. V. L1/L2 cue-weighting strategies in the perception of lexical stress.\n\n\n\n\nRefereed Presentations\nRoettger T., B. and J. V. Casillas (2023). Changing research culture: Toward big team speech science. The 20th International Congress of Phonetic Sciences (ICPhS). Prague Congress Center, Prague, Czech Republic.\nAndreu Rascón, I. and J. V. Casillas (2023). The impact of visual articulation on L2 perception of vowels. Hispanic Linguistics Symposium. Bringham Young University, Provo, UT.\nGarrido-Pozú, J. J. and J. V. Casillas (2022). L2 learners’ intuitions in explicit syllabification of Spanish and English. Hispanic Linguistics Symposium, Online. Arizona State University, Tempe, AZ.\nSagarra, N. and J. V. Casillas (2022). Language Proficiency And Use Affect Stress-Suffix Connections Differently In Early And Late Bilinguals. Hispanic Linguistics Symposium, Online. Arizona State University, Tempe, AZ.\nCasillas, J. V. (2022). Open Science practices and reproducible research in the classroom: A case study. Linguistic Associaition of Great Britain (LAGB) Annual Meeting. Ulster University, Belfast, Northern Ireland.\nCasillas, J. V. (2022). Forking paths and researchers degrees of freedom: Analytic considerations in perception-production research. The 10th International Symposium on the Acquisition of Second Language Speech (NewSounds). University of Barcelona, Barcelona, Spain.\nCasillas, J. V., J. J. Garrido-Pozú, N. Rodríguez, K. Parrish, L. Fernández Arroyo, R. Esposito, I. Chang, K. Gómez, G. Constantin-Dureci, J. Shao, et al. (2022). Inferring meaning from intonation: The effects of proficiency and empathy on L2 pragmatic skills. Current Approaches to Spanish and Portuguese Second Language Phonology (CASPSLaP), Online. University of Wisconsin-Madison, Madison, WI.\nCasillas, J. V., J. J. Garrido-Pozú, N. Rodríguez, K. Parrish, L. Fernández Arroyo, R. Esposito, I. Chang, and K. Gómez (2021). Using intonation to disambiguate meaning: The role of empathy and proficiency in L2 perceptual development. Hispanic Linguistics Symposium, Online. Wake Forest University, Winston-Salem, NC.\nSagarra, N. and J. V. Casillas (2021). The effects of prosody, proficiency and working memory on L2 lexical prediction. EuroSLA, Online, Universitat de Barcelona, Spain.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2021). The role of working memory during L2 prediction of morphology: Evidence from professional interpreters. 3rd International Symposium on Bilingual and L2 Processing in Adults and Children (ISBPAC 2021), Online.\nJimémez-Crespo, M. A. and J. V. Casillas (2020). Are ‘literal translations’ always easier to process?: A process-based study of effort based on comparable corpus data. Translation in Transition: Human and Machine Aspects, Online. Kent State University, Kent, OH.\nRodríguez, N., C. Lozano-Argüelles, L. F. Arroyo, E. Durand, J. J. G. Pozu, J. M. Rojas, J. Varela, N. de Rocafiguera, and J. V. Casillas (2020). If you can believe it you can perceive it: Conceptually cueing the double phonemic boundary effect in late bilinguals. Current Approaches to Spanish and Portuguese Second Language Phonology (CASPSLaP), San José State University, San José, CA.\nWiseman, A. M., J. V. Casillas, M. Lacorte, and A. C. Lara (2020). How do you pull off all that intercultural stuff at home? Enhancing intercultural development in the L2 classroom in a domestic immersion environment. Workshop on Intercultural Skills Enhancement (WISE) Conference, Wake Forest University, Winston-Salem, NC.\nLozano-Argüelles, C., L. F. Arroyo, N. Rodríguez, E. Durand, J. J. G. Pozú, J. M. Rojas, J. Varela, N. de Rocafiguera, and J. V. Casillas (2019). Conceptually cued perceptual categorization in late bilinguals. Hispanic Linguistics Symposium, University of Texas at El Paso, El Paso, TX.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2019). Predicting the end: monolinguals, L2 learners and interpreters’ use of prosody to predict word endings. Hispanic Linguistics Symposium, University of Texas at El Paso, El Paso, TX.\nSimonet, M. and J. V. Casillas (2019). Perceptual normalization in bilinguals and second language learner. Coloquio del Laboratorio de Adquisición del Lenguaje, Valladolid, Spain: Universidad de Valladolid, Department of English Studies.\nColina, S., J. V. Casillas, and Y. Díaz (2018). Syllabic Affiliation of Prevocalic Glides in Sonoran Spanish: Dialectal variation in syllabic affiliation. Hispanic Linguistics Symposium, University of Texas at Austin, Austin, TX.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2018). The use of lexical stress and vowel duration for morphological anticipation in L2 learners of Spanish. Hispanic Linguistics Symposium, University of Texas at Austin, Austin, TX.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2018). The time-course of verbal morphology anticipation: When interpreting experience makes a difference. International Symposium on Bilingual and L2 Processing in Adults and Children (ISBPAC). Universität Branschweig, Germany.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2017). Practice makes perfect. L2 morphological anticipation in simultaneous interpreters. International Symposium on Bilingualism. University of Limerick, Ireland.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2017). The Role of Stress in Morphological Anticipation: Evidence from Interpreters. Hispanic Linguistics Symposium, Texas Tech University, Lubbock, TX.\nSagarra, N., J. V. Casillas, and N. Rodríguez (2017). The use of stress in lexical access in early and late bilinguals. Hispanic Linguistics Symposium, Texas Tech University, Lubbock, TX.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2017). Anticipatory eye-movements in morphological prediction: Evidence from interpreters and bilinguals. Second Language Research Forum, The Ohio State University.\nSagarra, N. and J. V. Casillas (2017). Lexical stress predicts L1 and L2 morphosyntactic processing. 47th Linguistics Symposium on Romance Languages. University of Delaware, Newark, DE.\nCasillas, J. V. (2017). The longitudinal development of fine-phonetic detail: Production and perception of Spanish stops in a stateside immersion context. 47th Linguistics Symposium on Romance Languages. University of Delaware, Newark, DE.\nCasillas, J. V. (2017). Coronal stop production in Spanish heritage speakers. 4th National Symposium on Spanish as a Heritage Language. University of California at Irvine, Irvine, CA.\nCasillas, J. V. (2017). Crossing borders? The status and future of Spanish in the U.S.. School of Spanish Round Table, Middlebury College, Middlebury, VT.\nCasillas, J. V. (2016). Learning to hear fine-phonetic detail: Longitudinal development of language-specific speech perception in adults. Hispanic Linguistic Symposium. Georgetown University, Washinton D.C.\nSimonet, M., J. V. Casillas, and D. Osborne (2016). Second language acquisition and the double perceptual boundary effect. Sound to Word in Bilingual and Second Language Speech Perception. University of Iowa, Iowa City, Iowa.\nSimonet, M., J. V. Casillas, and D. Osborne (2016). Second language acquisition and the double perceptual boundary effect. Colloquium of the Institute for Phonetics and Speech Processing, Ludwig-Maximilian University of Munich, Munich, Germany.\nSimonet, M., J. V. Casillas, and D. Osborne (2016). Second language acquisition and the double perceptual boundary effect. Colloquium of the Second Language Acquisition and Teaching Program, University of Arizona, Tucson, Arizona.\nCasillas, J. V., Y. Díaz, and M. Simonet (2015). Acoustics of coronal stops in Spanish-English bilingual speech. Hispanic Linguistics Symposium. University of Illinois at Urbana-Champaign, Urbana, IL.\nBessett, R. M., J. V. Casillas, and M. R. Martínez (2014). Language Choice and Accommodation: Casual Encounters Along the U.S. Border. 7th Workshop on Spanish Sociolinguistics. University of Wisconsin-Madison, Madison, WI.\nCasillas, J. V. (2013). Perception of English /i/-/ɪ/ tense/lax vowel contrast by early learners of English. Second Language Research Forum (SRLF). Brigham Young University. Provo, Utah.\nCasillas, J. V. (2013). English-dominant early Spanish-English bilinguals production and perception of English tense lax vowel contrasts. Phonetics and Phonology in Iberia. Universidade de Lisboa, Lisbon. Portugal.\nCasillas, J. V. (2013). La fricativización del africado /tʃ/: actitudes lingüísticas cerca de la frontera. 6th Workshop on Spanish Sociolinguistics. University of Arizona, Tucson, AZ.\nCasillas, J. V. (2012). Los piojos, las pulgas y el canto… ¡oh my! Una segunda mirada a la teoría de Dunbar, el cotilleo y el papel de la música en la evolución del lenguage. 22nd Annual Symposium on Hispanic and Luso-Brazilian Literature, Language and Culture. University of Arizona, Tucson, AZ.\nCasillas, J. V. (2011). La fricativización del africado /tʃ/ en el habla de las mujeres del sur de Arizona. 21st Annual Symposium on Hispanic and Luso-Brazilian Literature. University of Arizona, Tucson, AZ.\nCasillas, J. V. (2011). Going mental with vocabulary: the use of iDevice applications in the classroom. Spanish Heritage Language Program Share Day. University of Arizona, Tucson, AZ.\n\n\nUnrefereed Presentations\nSubina, M., K. Parrish, I. Andreu Rascón, G. Constantin-Dureci, J. Shao, I. Chang, A. Gadamsetty, K. Taveras, and J. V. Casillas (2023). Fostering Open Science in Linguistics. Aresty Undergraduate Research Symposium. Rutgers University, New Brunswick.\nTaveras, K. and J. V. Casillas (2022). The Development of Intonation Perception During Second Language Acquisition: the Role of Empathy and Proficiency. Aresty Undergraduate Research Symposium. Rutgers University, New Brunswick.\nChang, I., K. Gómez, and J. V. Casillas (2021). Intonation acquisition in adult L2 learners of Spanish. Aresty Undergraduate Research Symposium, Rutgers University, New Brunswick.\nField, A. and J. V. Casillas (2020). Semantic processing effects on L2 stop production. Aresty Undergraduate Research Symposium, Rutgers University, New Brunswick.\nCasillas, J. V. (2017). Crossing borders? The status and future of Spanish in the U.S.. School of Spanish Round Table, Middlebury College, Middlebury, VT.\nSagarra, N., J. V. Casillas, C. Lozano-Argüelles, F. Eriksson, J. Uscamayta, and J. Overton (2017). Using lexical stress to predict inflectional morphology. Aresty Undergraduate Research Symposium. Rutgers University, New Brunswick.\n\n\nPoster presentations\nCoretta, S., J. V. Casillas, and T. B. Roettger (2022). Research Management in “Many Analysts” Projects: Lessons From the Many Speech Analyses Project. Edinburgh Open Research Conference (poster presentation). University of Edinburgh, Edinburgh, Scotland.\nCasillas, J. V. (2019). Semantic processing triggers cross-linguistic interference during early phonetic category development. The 19th International Congress of Phonetic Sciences (ICPhS) (poster presentation).\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2018). Anticipación de morfología en hablantes de español como L2. II Congreso para profesionales de la educación bilingüe (poster presentation). Madrid, Spain.\nSagarra, N. and J. V. Casillas (2018). Prosodic cues facilitate morphological anticipation in monolinguals and bilinguals. International Symposium on Bilingual and L2 Processing in Adults and Children (poster presentation). Universität Braunschweig, Germany.\nLozano-Argüelles, C., N. Sagarra, and J. V. Casillas (2018). Anticipation in Professional Interpreters: Predicting Morphology. Bridging Attention and Prediction (poster presentation). Universitat de Barcelona, Spain.\nSagarra, N., J. V. Casillas, C. Lozano-Argüelles, and N. Rodríguez (2017). Eye-tracking reveals bilinguals use stress to predict morphology. 11th annual Perceptual and Cognitive Science Forum. Rutgers University, New Brunswick.\nMartínez, M. R. and J. V. Casillas (2016). La producción de la vibrante múltiple en los estudiantes de español como lengua heredada y en los estudiantes de español como lengua extranjera. 8th Workshop on Spanish Sociolinguistics (poster presentation). University of Puerto Rico, Río Piedras, PR.\nCasillas, J. V., Y. Díaz, and M. Simonet (2015). Acoustics of Spanish and English coronal stops. Proceedings of the 18th International Congress of Phonetic Sciences (poster presentation). University of Glasgow, Glasgow, Scotland.\nSimonet, M., J. V. Casillas, and Y. Díaz (2014). A contrastive acoustic analysis of dental and alveolar stops in Spanish and English. Hispanic Linguistics Symposium (poster presentation). Purdue University, West Lafayette, IN.\nSimonet, M., J. V. Casillas, and Y. Díaz (2014). The effects of stress/accent on VOT depend on language (English, Spanish), consonant (/d/, /t/) and linguistic experience (monolinguals, bilinguals). Speech Prosody 7: Social and Linguistic Speech Prosody (poster presentation). Trinity College, Dublin, Ireland.\nCasillas, J. V. and M. Simonet (2013). English-dominant early Spanish/English bilinguals perception of English tense-lax vowel contrasts. PPLC 13: Phonetics, phonology and languages in contact: Contact varieties, multilingualism, and second language learning (poster presentation). Paris, Délégation Générale Wallonie-Bruxelles."
  },
  {
    "objectID": "posts/2017-05-15_analysis_of_justin_bieber_singing_in_spanish_-_despacito/2017-05-15_analysis_of_justin_bieber_singing_in_spanish_-_despacito.html",
    "href": "posts/2017-05-15_analysis_of_justin_bieber_singing_in_spanish_-_despacito/2017-05-15_analysis_of_justin_bieber_singing_in_spanish_-_despacito.html",
    "title": "Justin Bieber sings in Spanish: How’d he do?",
    "section": "",
    "text": "TL;DR\n\n\n\n\n\n\n\n\n\nIn the remixed version of the song “despacito”, Justin Bieber sings in Spanish. Some articles online criticize his pronunciation. I analyzed his realization of “p” and “t” in Praat and find that, while his pronunciation is not perfect, it is pretty good. I don’t believe he commits the “errors” suggested in the article.\n\n\nOverview\nI recently heard the song despacito featuring teen hero Justin Bieber (my wife mentioned to me that he sings in Spanish and my curiosity got the best of me). I distinctly remember being rather impressed by how well he sang in Spanish, so I was surprised when I saw this article pop up in my facebook feed. Basically, J Balvin and Nicky Jam (I have no idea who these guys are) make fun of J Biebs accent. Specifically, they harp on his pronunciation of the title of the song, suggesting the /t/ in the diminutive form of “despacio” (slow) is realized as [ɹ]. In fact, they sing it a few times [des.pa.si.ɹo] (des-pa-see-row, if you aren’t familiar with IPA) and, in jest, claim at one point that he sings ‘dorito’ [ðo.ɹi.ɾo]. You can watch this specific part here:\n\n\n\n\n\n\nNow, this type of non-native pronunciation actually makes a lot of sense, at least I think the ‘dorito’ comment does. In American and Canadian English an intervocalic “t” (and “d”) is usually pronounced as a flap, which in essence corresponds with Spanish “r” in the same position (note: it has to be in the same position, otherwise it would pronounced as a trill). This leads to all kinds of difficulties for learners of Spanish because they have to avoid a phonological process of their native language. For example, a common mispronunciation of the Spanish word “todo” (all) is [to.ɾo], which actually means “toro” (bull). That is, English speakers (mis)pronounce the intervocalic /d/ as a flap, which is most perceptually similar to Spanish “r”. On the other hand, when they try to pronounce “toro”, the “r” is realized as the English rhotic [ɹ].\nThus, if Bieber were pronouncing /ito/ as most native English speakers do, as a flap, it would be perceived as a Spanish “r” (the flap, not the trill). However, there is no real explanation for why he would pronounce it with an English rhotic ([ɹ]) as J Balvin and Nicky Jam claim. I personally did not hear this pronunciation, so I assume they were just teasing the teenage heart throb. Nonetheless, I noticed a lot of comments in the article were also making fun of his pronunciation, so I decided I would take a look in praat to determine if I am going crazy or if the internet is just full of haters. Here is an example of what we will look at:\n\n\n\n\nYour browser does not support the audio element. \n\n\n\nThe analysis\nI downloaded the music video from youtube and converted the .mp4 file to .m4a, and then to .wav. In praat I converted the .wav from stereo to mono. Justin sings the chorus as well as some of the verses. I’m just going to look at the chorus because the verses are accompanied by Daddy Yankee and/or Luis Fonsi. Luckily, pretty much every time he says “despacito” in the chorus there is silence, so we can use that for our analysis. I am going to focus on how he pronounces the stop /t/ (though I did get formant frequency measurements for all the vowels… maybe for another post). This only leaves us with about 5 useful tokens, but there are also a good amount of /p/’s that we can compare them with. Here is arguably the best token:\n\n\n\nIt’s clear—at least to me—that Justin is not producing an English rhotic where he should be producing [t]. In other words, he is not saying des-pa-see-row. How do I know? Well, if we zoom in on the final /ito/, we notice two things: 1) there is clearly a closure and 2) there is a burst. These are characteristics of a stop consonant. Now, you might be thinking “Yeah, but a flap looks pretty similar in a spectrogram” and you wouldn’t be wrong, but the clear difference here is that after the release there is a short gap before the voicing of the final /o/. This short gap is called voice-onset time (VOT). Stops have VOT; flaps do not. Here is a close up:\n\n\n\nNow a characteristic of English voiceless stops (“p”, “t”, “k”) is that in word initial position they are produced with aspiration and have long-lag VOT, usually around 60 ms. We refer to them in IPA with: [ph, th, kh]. Voiceless stops are different in Spanish, as they are not aspirated and have short-lag VOT, usually from 0 to 25 ms. The “ito” of “despacito” is word internal, thus, in theory, for an English speaker it should not be aspirated because it is normally realized as a flap, though in emphatic speech it could be realized as [th]. Hopefully I have already convinced you that Biebs is not flapping. So our next question is: what kind of VOT do his stops have? If they are short-lag, we can conclude that they are more Spanish-like. If, on the other hand, they are aspirated, then they would be more English-like. So let’s take a look!\nI measured VOT of every p and t every time Justin sings “despacito”. First, let’s load some packages we will need.\n\nlibrary(lingStuff)\nlibrary(tidyverse)\n\nNow we can load the data and check the structure.\n\n# Load data\nbieber_vot &lt;- read_csv(\"./assets/data/despacito.csv\")\n\n\n# Check structure of dataframe\nbieber_vot %&gt;%\n  select(., prefix, votP, votT) %&gt;%\n  gather(., key = phon, value = vot, -prefix) %&gt;%\n  str(.)\n## tibble [10 × 3] (S3: tbl_df/tbl/data.frame)\n##  $ prefix: chr [1:10] \"despacito\" \"despacito1\" \"despacito2\" \"despacito3\" ...\n##  $ phon  : chr [1:10] \"votP\" \"votP\" \"votP\" \"votP\" ...\n##  $ vot   : num [1:10] 23.3 19.2 19 19.4 15.6 ...\n\nLooks good. Let’s plot the VOT of the p’s and t’s and see how they look. I’ve set the x-limit to range from 0 to 60.\n\n# Plot vot as a function of phon\nbieber_vot %&gt;%\n  select(., prefix, votP, votT) %&gt;%\n  gather(., key = phon, value = vot, -prefix) %&gt;%\n  ggplot(., aes(x = phon, y = vot, color = phon)) + \n    stat_summary(fun.data = 'mean_cl_boot', geom = 'pointrange', size = 1.1) +\n    stat_summary(fun.y = 'mean', geom = 'point', color = 'darkred', size = 2.75) +\n    ylim(0, 60) + ylab(\"VOT (ms)\") + xlab(\"\") + \n    scale_x_discrete(labels = c('/p/', '/t/')) + \n    coord_flip() + \n    scale_color_brewer(name = '', guide = F) + \n    theme_dark(base_size = 22, base_family = \"Times\")\n\n\nRecall that an English-like VOT would be around 60 ms (but could range from around 40 to over 100!). We can see that the p’s have a VOT of approximately 20 ms (19.29 ms ± 2.72 sd, to be exact), and the t’s have a VOT of around 25 ms (23.1 ms ± 7.39 sd). Both are certainly within range of native Spanish pronunciations.\nInterim conclusion: the internet is full of haters.\n\n\n\nNot so fast…\nThere is one last thing to keep in mind before we give JBiebs a pass on his Spanish and it’s an important one. Spanish /t/ and English /t/ are articulated at different places in the mouth. Specifically, Spanish /t/ is dental and English /t/ is alveolar. What this means is that when an English speaker pronounces a word with a “t” in Spanish, like ‘despacito’, she also needs to change the place of articulation, i.e. the tongue needs to make contact with the back of the top teeth, and not the hard ridge right above them. When we looked at VOT in the present analysis we didn’t take this difference into account. My personal opinion is that el señorito does a pretty good job, but if you listen closely to the very last ‘despacito’ in the song, it does sound rather alveolar, i.e. gringo-y.\nConclusion: the internet is full of haters."
  },
  {
    "objectID": "posts/2014-05-28_tikz_-_standalone_plots/2014-05-28_tikz_-_standalone_plots.html",
    "href": "posts/2014-05-28_tikz_-_standalone_plots/2014-05-28_tikz_-_standalone_plots.html",
    "title": "TikzDevice tutorial III: standalone plots",
    "section": "",
    "text": "In this post I’m going to show you how to use tikzDevice to create high quality plots that use the same font as your \\(\\LaTeX\\) document. I’m assuming that you have already installed tikz. If not, see part I in this series. Moreover, this tutorial assumes that you have set up your project in the same way outlined in part II. An added benefit to this approach is that it allows you to insert IPA symbols into the plot via the tipa package.\n\nThe LaTeX file\nOk. You should start with a \\(\\LaTeX\\) file that looks like this:\n\\documentclass{article}\n\\usepackage{tikz}\n\\usepackage{tipa}\n\n\\begin{document}\n\n&lt;&lt;&gt;&gt;=\nrequire(tikzDevice)\ntikz('plot.tex', standAlone=TRUE)\nlibrary(stats)\nplot(cars)\nlines(lowess(cars))\ndev.off()\n@\n\n\\end{document}\nIf you have experience working with \\(\\LaTeX\\), the preamble should be pretty straightforward (If you need a quick primer on \\(\\LaTeX\\), see this tutorial). The important part so far is that you have to include \\usepackage{tikz} and \\usepackage{tipa} before \\begin{document}.\n\n\nThe R code\nIn knitr, R code goes between &lt;&lt;&gt;&gt;= and ends with @. So all of this is R code:\n\nrequire(tikzDevice)\ntikz('plots/cars-plot.tex', standAlone=TRUE)\nlibrary(stats)\nplot(cars)\nlines(lowess(cars))\ndev.off()\n\nThe command require(tikzDevice) loads tikz into the R workspace. Then, tikz('plots/cars-plot.tex', standAlone=TRUE) calls the tikz device and creates the file cars-plot.tex in the folder plots. It is important to set standAlone to TRUE if you want to have a separate .tex file (this is what allows us to keep the fonts the same as the rest of the document). From this point on until the call dev.off(), we enter what we want to appear in our .tex file. In this case I have plotted the typical cars data from the library stats. Here is the PDF output produced when cars-plot.tex is compiled. Notice the font is different from what you typical get in R.\n\nNow let’s try something a little more involved and add some IPA. I will use a fake dataset and load it into R.\n\nmy_data &lt;- read.delim(\"assets/my_data.txt\")\n\nWe will use ggplot2 for this plot.\n\nlibrary(ggplot2)\n\nNow we will call tikz device.\n\nrequire(tikzDevice)\noptions(tikzLatexPackages = c(getOption(\"tikzLatexPackages\"), \"\\\\usepackage{tipa}\"))\ntikz('plots/ipa_plot.tex', standAlone=TRUE, width=10, height=6)\nmy_data$group &lt;- factor(my_data$group, levels = c(\"EL\", \"NE\", \"LL\"))\ndf&lt;-with(my_data, aggregate(fpro, list(group=group, fstim=fstim), mean))\ndf$se&lt;-with(my_data, aggregate(fpro, list(group=group, fstim=fstim), function(x) sd(x)/sqrt(10)))[,3]\ngp &lt;- ggplot(df, aes(x=fstim, y=x, colour=group, ymin=x-se, ymax=x+se))\ngp + geom_line(aes(linetype=group), size = .5) + \n    geom_point(aes(shape=group)) + \n    geom_ribbon(alpha = 0.15, linetype=0) + \n    ylim(0, 1) + \n    scale_x_continuous(breaks=seq(0, 10, by=1)) +\n    labs(list(title = \"[\\\\textesh ip/\\\\textesh\\\\textsci p]\", \n            x = \"Stimuli\", y = \"\\\\% [\\\\textesh\\\\textsci p]\")) +\n    theme_bw() +\n    theme(legend.background = element_rect(colour = 'grey50', \n        fill = 'grey97', size = .75, linetype='solid')) +\n    scale_linetype_discrete(\"Group\") +\n    scale_shape_discrete(\"Group\") +\n    scale_colour_discrete(\"Group\")\ndev.off()\n\nNotice that after the require(tikzDevice) call, we included\n\noptions(tikzLatexPackages = c(getOption(\"tikzLatexPackages\"), \"\\\\usepackage{tipa}\")) \n\nThe key component here is \\\\usepackage{tipa}. This means that tipa will be included in the .tex produced from the code, which, in turn, means that we can include IPA sybols in the plot before it is produced. The tikz('plots/ipa_plot.tex', standAlone=TRUE, width=5, height=5) call creates ipa_plot.tex in the folder plots. The rest of the code (up to dev.off()) is the actual plot. Notice that we have included ipa in the following command:\n\nlabs(list(title = \"[\\\\textesh ip/\\\\textesh\\\\textsci p]\", \n          x = \"Stimuli\", y = \"\\\\% [\\\\textesh\\\\textsci p]\"))\n\nThis is the plot that is produced when the resulting .tex file is compiled:\n\n\n\n\n\n\n\n\n\nAnd that’s it. We have produced a beautiful plot that uses the same font as our document and includes IPA symbols. You can download all the files here and try it yourself."
  },
  {
    "objectID": "posts/2013-05-09_colored_spectrograms_in_r/2013-05-09_colored_spectrograms_in_r.html",
    "href": "posts/2013-05-09_colored_spectrograms_in_r/2013-05-09_colored_spectrograms_in_r.html",
    "title": "Colored spectrograms in R",
    "section": "",
    "text": "This is how I made the colored spectrogram from the homepage (it’s me saying ‘welcome’). You need to load the package phonTools into R.\n\nlibrary(phonTools)\n\nNow you have to load the sound you want to make a spectrogram of (it has to be in your working directory). I recorded mine in Praat.\n\nsound &lt;- loadsound('welcome.wav')\n\nNow we’re ready to make a spectrogram.\n\nspectrogram(sound, fs = 44100, colors = TRUE, \n            maintitle = \"Welcome\", maxfreq = 5500)\n\n\n\n\n\n\n\n\n\n\nWe can also see the oscillogram by using\n\nplot(sound)\n\n\n\n\n\n\n\n\n\n\nThat’s it."
  },
  {
    "objectID": "posts/2015-05-18_data_pipelines/2015-05-18_data_pipelines.html",
    "href": "posts/2015-05-18_data_pipelines/2015-05-18_data_pipelines.html",
    "title": "Data pipelines in R",
    "section": "",
    "text": "So you thought up a clever experiment, got IRB approval, recruited participants and collected data… now what? New researchers are often confronted with an unfortunate surprise when it comes time to perform some kind of analysis on their data: they don’t know how, or even where to start. This can be a problem for something trivial, like obtaining simple descriptive statistics, or something much more complex, like fitting models, creating plots and making predictions. When we conduct experiments we don’t usually begin by thinking about how we will analyze our data, and in many academic programs this is not explicitly taught to new students. For most people, especially beginners, the data analysis issue arises later on in the process, usually after the data have already been collected (although I think this ultimately changes with experience).\nIn light of all of this, I think that something handy to learn and evaluate early on is how data analysis typically flows: from obtaining data to obtaining new insight from the data. This is the data analysis pipeline, which usually looks something like this:\n\n\n\n\n\n\n\n\n\nIn essence, the process is simple. After collecting your data, you need to tidy it (step 2) so that it can be loaded and analyzed by your statistical software. After tidying your data, you usually have to transform it (step 3) in some way (also called data preprocessing). This can be occur via the creation of new variables, combining variables, sub-setting variables, etc. Once you have transformed your data, it’s time to visualize it (step 4a) via graphs/plots, and, finally, analyze it. In exploratory data analysis the visualization and analysis steps are often iterative: you might notice something in a graph that leads you to a new analysis, or some kind of insight that requires more data transformation and a new analysis, and so on and so forth until you have obtained new insight that might lead you to generate new research question(s).\nSo, at the heart of data analysis is tidy data. Most new researchers don’t know what it means to tidy and transform their data, nor that it is probably the most important part of any data analysis. Basically, if your data are not formatted in a way in which they can be easily analyzed (via excel, SPSS, R, etc.), then you can’t do anything with them.\nIn order to facilitate the data analysis pipeline, it is crucial to have tidy data. What this means is that every column in your data frame represents a variable and every row represents an observation. This is also referred to as long format (as opposed to wide format). Most statistical software requires your data to be in long format, with few exceptions (i.e. repeated measures ANOVA in SPSS).\nIn what follows, I take you through three packages that have been created in order to facilitate the data analysis pipeline in R. Each package was created by Hadley Wickham with steps 2, 3, and 4a of the pipeline in mind. Thus we can associate each package with the corresponding step:\n\n\ntidyr\ndplyr\nbasic plotting in r / ggvis\n\n(coming soon)"
  },
  {
    "objectID": "posts/2015-05-18_data_pipelines/2015-05-18_data_pipelines.html#overview",
    "href": "posts/2015-05-18_data_pipelines/2015-05-18_data_pipelines.html#overview",
    "title": "Data pipelines in R",
    "section": "",
    "text": "So you thought up a clever experiment, got IRB approval, recruited participants and collected data… now what? New researchers are often confronted with an unfortunate surprise when it comes time to perform some kind of analysis on their data: they don’t know how, or even where to start. This can be a problem for something trivial, like obtaining simple descriptive statistics, or something much more complex, like fitting models, creating plots and making predictions. When we conduct experiments we don’t usually begin by thinking about how we will analyze our data, and in many academic programs this is not explicitly taught to new students. For most people, especially beginners, the data analysis issue arises later on in the process, usually after the data have already been collected (although I think this ultimately changes with experience).\nIn light of all of this, I think that something handy to learn and evaluate early on is how data analysis typically flows: from obtaining data to obtaining new insight from the data. This is the data analysis pipeline, which usually looks something like this:\n\n\n\n\n\n\n\n\n\nIn essence, the process is simple. After collecting your data, you need to tidy it (step 2) so that it can be loaded and analyzed by your statistical software. After tidying your data, you usually have to transform it (step 3) in some way (also called data preprocessing). This can be occur via the creation of new variables, combining variables, sub-setting variables, etc. Once you have transformed your data, it’s time to visualize it (step 4a) via graphs/plots, and, finally, analyze it. In exploratory data analysis the visualization and analysis steps are often iterative: you might notice something in a graph that leads you to a new analysis, or some kind of insight that requires more data transformation and a new analysis, and so on and so forth until you have obtained new insight that might lead you to generate new research question(s).\nSo, at the heart of data analysis is tidy data. Most new researchers don’t know what it means to tidy and transform their data, nor that it is probably the most important part of any data analysis. Basically, if your data are not formatted in a way in which they can be easily analyzed (via excel, SPSS, R, etc.), then you can’t do anything with them.\nIn order to facilitate the data analysis pipeline, it is crucial to have tidy data. What this means is that every column in your data frame represents a variable and every row represents an observation. This is also referred to as long format (as opposed to wide format). Most statistical software requires your data to be in long format, with few exceptions (i.e. repeated measures ANOVA in SPSS).\nIn what follows, I take you through three packages that have been created in order to facilitate the data analysis pipeline in R. Each package was created by Hadley Wickham with steps 2, 3, and 4a of the pipeline in mind. Thus we can associate each package with the corresponding step:\n\n\ntidyr\ndplyr\nbasic plotting in r / ggvis\n\n(coming soon)"
  },
  {
    "objectID": "posts/2013-05-17_tikz_-_projects/2013-05-17_tikz_-_projects.html",
    "href": "posts/2013-05-17_tikz_-_projects/2013-05-17_tikz_-_projects.html",
    "title": "TikzDevice tutorial II: structuring a project",
    "section": "",
    "text": "Overview\nThis mini tutorial is part II about incorporating tikzDevice into your workflow. It explains the file structure necessary to successfully include tikzDevice plots into your \\(\\LaTeX\\) document. You must first have tikzDevice installed. If you don’t, see part I for more information.\n\n\nThe structure\nA simple yet effective way to do reproducible research is to use R (for statistical analysis) directly in a \\(\\LaTeX\\) environment. There are two ways to accomplish this: (1) Sweave and (2) knitr. knitr seems to be the better choice, as it builds on some of the deficiencies of Sweave, and is what I am currently using in my workflow. In order to successfully “knit” R code into a .tex format we must use a no-web (.nw) file to create the .tex file. There are two types of no-web files: .Rnw and .Snw. I am not completely sure what the differences are between then, but I use .Rnw and that is what I will mention in this tutorial.\nThe first step is to create a project folder. For the purposes of this tutorial let’s call this folder “master”. Next, we will need some data and some R code that analyzes it. The most common, no-hassle way to accomplish this in R is to save your R code in a separate .R file. For this tutorial, we will call our data “my-data.txt” and our R code “example.R”. The fake data we are going to analyze is for a two-alternative forced choice identification experiment. So, our fake data is in the “my-data.txt” file and the R code that analyzes it is in the example.R file.\nThe next step is to create the “no web” .Rnw file. This is as simple as creating a document in your text editor of choice (I use TextMate 2 and Sublime Text 3) and saving it with a .Rnw extension. For this tutorial we will call this file “example.Rnw”. Its purpose is to call the R code written in “example.R” (which uses the fake data in “my-data.txt”) in order to produce a .tex file (in this case “example.tex”). Still with me? Good.\nNext we need to prepare where we are going to keep the plots produced by tikzDevice. I find it most convenient to have a specific folder, “plots_folder”, where I only keep the tikzDevice plots. So, create this folder inside the “master” folder. tikzDevice creates the R plots and converts them to a \\(\\LaTeX\\) format (the benefits of this are further explained in part III of this tutorial), saves them in “plots_folder” and we will then include them in the example.tex file which can be compiled into a PDF. The image below shows what this should look like when it’s all said and done.\n\n\n\n\n\n\n\n\n\nCheck out part III to learn how to create standalone plots that can include IPA sybols."
  },
  {
    "objectID": "code/snippets_latex_ipa/index.html",
    "href": "code/snippets_latex_ipa/index.html",
    "title": "LaTeX IPA",
    "section": "",
    "text": "I made this repository to simplify the process of using IPA in \\(\\LaTeX\\). It is merely a collection of snippets for the package TIPA. To install LaTeX-IPA see the package control page.\n\nFile naming\nConsonants are labeled in the following way:\n\nvoicing -&gt; point of articulation -&gt; mode of articulation\nEx. voiceless-bilabial-aprox.sublime-snippet = [β]\n\nVowels are labeled in the following way:\n\nvowel -&gt; tense/lax -&gt; height -&gt; frontedness -&gt; rounding\nEx. vowel-tense-high-front-unrounded.sublime-snippet = [i]\n\n\n\nTab triggers\nThere are 6 main groups:\n\nDiacritics: type “diac” + tab\n\nVowels: type “vowel” + tab\n\nConsonants are divided into four subcategories:\n\nFricatives type “fric” + tab\n\nAffricates type “affr” + tab\n\nLiquids: type “liquid” + tab\n\nNasals: type “nasal” + tab\n\n\n\nNotes\nAs of now (10/19/2013), I have only included the symbols that I use the most in English and Spanish. I will continue adding to the repository over time. It should be noted that the consonants do not include all categories (i.e. stops). This is because they are not represented by unsual symbols in IPA."
  },
  {
    "objectID": "code/shiny_clt/index.html",
    "href": "code/shiny_clt/index.html",
    "title": "Central limit theorem",
    "section": "",
    "text": "knitr::include_graphics(\"featured.png\")"
  },
  {
    "objectID": "posts/2014-01-07_converting_rmarkdown_files_to_html5/2014-01-07_converting_rmarkdown_files_to_html5.html",
    "href": "posts/2014-01-07_converting_rmarkdown_files_to_html5/2014-01-07_converting_rmarkdown_files_to_html5.html",
    "title": "Using Rmarkdown to knit HTML5 documents in RStudio",
    "section": "",
    "text": "HTML5 slides\nI recently learned how to create HTML5 slides using .Rmd files and pandoc. Click here to check out an example. I will be posting a tutorial on how to do this in the near future (I hope).\nUpdate Here is a much cooler example I found on mages’ blog\nUpdate 2 This process has been streamlined in the newest update to RStudio (check it out here). The results are quite impressive (Ex. 1, Ex. 2)"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog posts",
    "section": "",
    "text": "How to create elegant waveform/spectrogram images in R\n\n\n\n\n\n\nphonetics\n\n\npraat\n\n\ndataviz\n\n\n\nIn this post I show how to generate waveform/spectrogram graphics in R. \n\n\n\n\n\nApr 18, 2024\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nHow to load many csv files at once\n\n\n\n\n\n\nstats\n\n\ntidy\n\n\nprogramming\n\n\n\nIn this post I show how to load many .csv files in a single data frame in R. \n\n\n\n\n\nMar 30, 2024\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nExploring phonemic boundaries using logistic regression\n\n\n\n\n\n\nstats\n\n\nglm\n\n\nbilinguals\n\n\ndouble phonemic boundary\n\n\n\nIn this post I show how to use logistic regression to get interesting info about bilinguals in a two-alternative forced choice task. \n\n\n\n\n\nMay 16, 2021\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a whisper room sound booth\n\n\n\n\n\n\nphonetics\n\n\nsoundbooth\n\n\n\nIt is harder than it looks. \n\n\n\n\n\nSep 16, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nJustin Bieber sings in Spanish: How’d he do?\n\n\n\n\n\n\nphonetics\n\n\nstops\n\n\nvot\n\n\n\nThe title really says it all. \n\n\n\n\n\nMay 15, 2017\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\ntidyr tutorial\n\n\n\n\n\n\nr\n\n\ntidyverse\n\n\ndata\n\n\n\nTutorial showing the functionality of the tidyr package for data wrangling. \n\n\n\n\n\nJun 22, 2015\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nHow to scrape data from Google Sheets in R\n\n\n\n\n\n\nr\n\n\nresearch\n\n\n\nHow to get data from a google sheet into R. \n\n\n\n\n\nJun 16, 2015\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nData pipelines in R\n\n\n\n\n\n\nr\n\n\nresearch\n\n\nworkflow\n\n\n\nWhat button do I press to learn the truth? \n\n\n\n\n\nMay 18, 2015\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nBasic plotting in R\n\n\n\n\n\n\nr\n\n\ndataviz\n\n\n\nStep-by-step examples for using the three main plotting systems in R. \n\n\n\n\n\nApr 20, 2015\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nHTML widgets in Rmarkdown\n\n\n\n\n\n\nr\n\n\nrmarkdown\n\n\nhtml\n\n\n\nWalkthrough for incorporating HTML widgets into an Rmarkdown document. \n\n\n\n\n\nApr 13, 2015\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nSlidify tutorial\n\n\n\n\n\n\nr\n\n\nrmarkdown\n\n\nhtml\n\n\n\nTutorial for creating HTML presentations using R and slidify. \n\n\n\n\n\nMar 22, 2015\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nTikzDevice tutorial III: standalone plots\n\n\n\n\n\n\nipa\n\n\nr\n\n\nresearch\n\n\nlatex\n\n\n\nQuick and dirty test for knitr boostrap framework. \n\n\n\n\n\nMay 28, 2014\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nKnitr bootstrap\n\n\n\n\n\n\nr\n\n\nrmarkdown\n\n\nknitr\n\n\n\nQuick and dirty test for knitr boostrap framework. \n\n\n\n\n\nMay 26, 2014\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Rmarkdown to knit HTML5 documents in RStudio\n\n\n\n\n\n\nr\n\n\nrmarkdown\n\n\nhtml\n\n\n\nSome simple examples of how to go from .Rmd to .html. \n\n\n\n\n\nJan 7, 2014\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nTikzDevice tutorial II: structuring a project\n\n\n\n\n\n\nr\n\n\nlatex\n\n\ntikz\n\n\n\nHow to setup a reproducible workflow that integrates tikzDevice. \n\n\n\n\n\nMay 17, 2013\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nTikzDevice tutorial I: install tikzDevice in R\n\n\n\n\n\n\nr\n\n\ntikz\n\n\nlatex\n\n\nipa\n\n\n\nHow to install tikzDevice for plotting in R. \n\n\n\n\n\nMay 11, 2013\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nColored spectrograms in R\n\n\n\n\n\n\nr\n\n\nphonetics\n\n\nacoustics\n\n\n\nHow to make colored spectrograms in R with phonTools. \n\n\n\n\n\nMay 5, 2013\n\n\nJoseph V. Casillas\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "academicWriteR\n\n\n\n\n\n\nr\n\n\nstatistics\n\n\nprogramming\n\n\nlinguistics\n\n\n\nAn R package of helper functions that are useful for writing academic reports/manuscripts. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\ncontributoR\n\n\n\n\n\n\nr\n\n\nstatistics\n\n\nprogramming\n\n\nlinguistics\n\n\n\nAn R package for documenting scholarly contributions. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nds4ling\n\n\n\n\n\n\nr\n\n\nstatistics\n\n\nprogramming\n\n\nlinguistics\n\n\nteaching\n\n\n\nAn R package of datasets and functions made to complement the ds4ling course. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nlingStuff\n\n\n\n\n\n\nr\n\n\nstatistics\n\n\nprogramming\n\n\nlinguistics\n\n\n\nAn R package with handy functions I use in my linguistic research. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nuntidydata\n\n\n\n\n\n\nr\n\n\nstatistics\n\n\nprogramming\n\n\nlinguistics\n\n\n\nAn R package of untidy datasets made for the purpose of teaching the tidyverse. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nBivariate linear regression\n\n\n\n\n\n\nr\n\n\nstatistics\n\n\nshiny\n\n\nteaching\n\n\nprogramming\n\n\n\nA shiny web app built in R for teaching the linear model. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nCentral limit theorem\n\n\n\n\n\n\nr\n\n\nstatistics\n\n\nshiny\n\n\nteaching\n\n\nprogramming\n\n\n\nA shiny web app built in R for teaching the central limit theorem. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nCrossover\n\n\n\n\n\n\nr\n\n\nstatistics\n\n\nshiny\n\n\nteaching\n\n\nprogramming\n\n\n\nA shiny web app built in R for calculating boundary crossover points in logistic regression. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nSpanish allophones and distinctive features\n\n\n\n\n\n\nr\n\n\nshiny\n\n\nteaching\n\n\nprogramming\n\n\nspanish\n\n\nphonology\n\n\n\nA shiny web app built in R for teaching the distinctive features of Spanish speech sounds. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralized linear model\n\n\n\n\n\n\nr\n\n\nshiny\n\n\nteaching\n\n\nprogramming\n\n\nstatistics\n\n\n\nA shiny web app built in R for teaching the generalized linear model. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nPower/Sample size calculator\n\n\n\n\n\n\nr\n\n\nshiny\n\n\nteaching\n\n\nprogramming\n\n\nstatistics\n\n\n\nA shiny web app built in R for teaching statistical power and sample sizes. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nR for linguists\n\n\n\n\n\n\nr\n\n\nshiny\n\n\nteaching\n\n\nprogramming\n\n\n\nA shiny web app built in R for teaching R using the tidyverse. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nLaTeX IPA\n\n\n\n\n\n\nteaching\n\n\nprogramming\n\n\nipa\n\n\nlatex\n\n\nsublimtext\n\n\n\nA collection of snippets for SublimeText that simplify the process of using IPA in LaTeX. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n\n\n\n\n\n\nR-Snippets\n\n\n\n\n\n\nteaching\n\n\nprogramming\n\n\nr\n\n\nworkflow\n\n\nsublimtext\n\n\n\nA collection of snippets for SublimeText that facilitate doing statistical analysis in R. \n\n\n\n\n\nApr 6, 2018\n\n\nJoseph V. Casillas\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Beginning Spanish\nElementary Spanish\nIntermediate Spanish\nIntroduction to Data Science\nIntroduction to the study of language\nIntroduction to Spanish Phonetics and Phonology\nIntroduction to Spanish Phonetics and Phonology for the Heritage Speaker\nCulture and composition for Heritage Speakers\nIntroduction to Hispanic Linguistics\nCurrent Issues in Second Language Acquisition\nHistory of the Spanish Language\nApplied Linguistics\nLanguage Discrimination and Ideologies in the U.S.\nHigh Beginner Spanish in Context (Middlebury College)"
  },
  {
    "objectID": "teaching.html#undergraduate",
    "href": "teaching.html#undergraduate",
    "title": "Teaching",
    "section": "",
    "text": "Beginning Spanish\nElementary Spanish\nIntermediate Spanish\nIntroduction to Data Science\nIntroduction to the study of language\nIntroduction to Spanish Phonetics and Phonology\nIntroduction to Spanish Phonetics and Phonology for the Heritage Speaker\nCulture and composition for Heritage Speakers\nIntroduction to Hispanic Linguistics\nCurrent Issues in Second Language Acquisition\nHistory of the Spanish Language\nApplied Linguistics\nLanguage Discrimination and Ideologies in the U.S.\nHigh Beginner Spanish in Context (Middlebury College)"
  },
  {
    "objectID": "teaching.html#graduate",
    "href": "teaching.html#graduate",
    "title": "Teaching",
    "section": "Graduate",
    "text": "Graduate\n\nSpanish phonetics/phonology\nThe phonetics/phonology of bilingualism\nData science for linguists\nResearch methods: Open science and reproducible research in Linguistics\nSpanish Phonetics for Teachers"
  },
  {
    "objectID": "teaching.html#workshops",
    "href": "teaching.html#workshops",
    "title": "Teaching",
    "section": "Workshops",
    "text": "Workshops\n\nSpanish pronunciation workshop for beginners\nUsing PsychoPy for linguistic research\nIntroduction to Praat\nIntroduction to R\nLaTeX for linguists\nIntroduction to Open Science and Reproducible Research\nBayesian Data Analysis for the Speech Sciences"
  },
  {
    "objectID": "code/shiny_bivariate_regression/index.html",
    "href": "code/shiny_bivariate_regression/index.html",
    "title": "Bivariate linear regression",
    "section": "",
    "text": "knitr::include_graphics(\"featured.png\")"
  },
  {
    "objectID": "code/snippets_rsnippets/index.html",
    "href": "code/snippets_rsnippets/index.html",
    "title": "R-Snippets",
    "section": "",
    "text": "This repository is a collection of snippets that I use in SublimeText for doing statistical analysis in R. The goal is straightforward: document the code that I use most often while doing linguistic research and make it readily available (and understandable) to other linguists. If you are interested in helping see the github repository. To install R-snippets see the package control page. To use a snippet, type the trigger and hit the tab key. For example, typing lm brings up the following window:\n\n\n\n\n\n\n\n\n\nSelecting Random slope and random intercept model expands to…\n# load lme4 for mixed models\nlibrary(lme4)\n\n# random intercept and random slope model\nmodelName = lmer(DV ~ fixedFactor1 +* fixedFactor2 + (1 + randomSlope|randomInt), data=df)\nmodelName\n\nhist(residuals(modelName))\nqqnorm(residuals(modelName))\nqqline(residuals(modelName))\nMain triggers:\n\n“plot”: templates for plotting in base R\n“edit”: options useful for data cleansing and saving\n“desc”: descriptive statistics of data\n“ttest”: distinct types of t-test\n“aov”: distinct analysis of variance models\n“lm”: linear and logistic regression\n“lmem”: linear mixed effects models\n\nExtras:\n\n“subset”: make subsets of a DF\n“read”: read/load/install data/packages into R\n“save”: save plots, dfs, tables, etc.\n“tikz”: template for creating R plots in LaTeX"
  },
  {
    "objectID": "posts/2014-05-26_knitr_bootstrap/2014-05-26_knitr_bootstrap.html",
    "href": "posts/2014-05-26_knitr_bootstrap/2014-05-26_knitr_bootstrap.html",
    "title": "Knitr bootstrap",
    "section": "",
    "text": "Knitr bootstrap makes generating standalone reports extremely easy and the output looks really neat. Check out the example here. To recreate this you need to download the preview release of R Studio, and set up the front matter as follows:\n---\noutput:\n  knitrBootstrap::bootstrap_document:\n    title: \"\"\n    theme: default\n    highlight: sunburst\n    theme.chooser: TRUE\n    highlight.chooser: TRUE\n---"
  },
  {
    "objectID": "posts/2013-05-11_tikz_-_installation/2013-05-11_tikz_-_installation.html",
    "href": "posts/2013-05-11_tikz_-_installation/2013-05-11_tikz_-_installation.html",
    "title": "TikzDevice tutorial I: install tikzDevice in R",
    "section": "",
    "text": "Overview\nThis is a short tutorial for getting tikzDevice running on R version 3.0. If you write in LaTeX and use R for statistics, this is a good way to get your plots/graphs/etc. into your .tex document. The advantages are:\n\nmuch higher quality and\nyou can use IPA symbols\n\n\n\nDownload tiksDevice\ntiksDevice is no longer officially supported by CRAN because the author was having trouble keeping it updated in a timely manner (check out this webpage if you want to read a little more it). Nonetheless, the tikzdevice package is very usable and still available for download. You can download the tar.gz file directly by clicking here.\n\n\nInstall tiksDevice\nInstalling a package that is no longer supported is by no means difficult, but not as simple as install.package('tikzDevice') (try it if you want to see why). Use the following code install the tar file (make sure to specify your file path to wherever you downloaded the file). This is what it looked like for me.\n\ninstall.packages(\"/Users/USERNAME/Downloads/tikzDevice_0.6.2.tar\", \n  repos = NULL, type = \"source\")\n\n\n\nInstall dependencies\nIn order for tikzDevice to work, you must also install the filehash package. This is much easier.\n\ninstall.packages('filehash')\n\nThat’s it. Check out this tutorial to see how to set up a project."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JVC",
    "section": "",
    "text": "P5 = require(\"p5\")"
  },
  {
    "objectID": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html",
    "href": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html",
    "title": "Setting up a whisper room sound booth",
    "section": "",
    "text": "Previous\n\n\n\nNext"
  },
  {
    "objectID": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html#packaging",
    "href": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html#packaging",
    "title": "Setting up a whisper room sound booth",
    "section": "",
    "text": "Previous\n\n\n\nNext"
  },
  {
    "objectID": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html#assembly",
    "href": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html#assembly",
    "title": "Setting up a whisper room sound booth",
    "section": "Assembly",
    "text": "Assembly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrevious\n\n\n\nNext"
  },
  {
    "objectID": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html#aftermath",
    "href": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html#aftermath",
    "title": "Setting up a whisper room sound booth",
    "section": "Aftermath",
    "text": "Aftermath\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrevious\n\n\n\nNext"
  },
  {
    "objectID": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html#walkthrough",
    "href": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/2018-09-16_setting_up_a_whisper_room_sound_booth.html#walkthrough",
    "title": "Setting up a whisper room sound booth",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrevious\n\n\n\nNext"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Joseph V. Casillas, Ph.D.",
    "section": "",
    "text": "Associate Professor of Spanish Linguistics\n\nRutgers University\n\nI am an Associate Professor of Spanish Linguistics in the Spanish and Portuguese Department and Associate Faculty in the Department of Linguistics at Rutgers University, New Brunswick. My main interests are in phonetics, laboratory phonology, and second language acquisition. A principle aim of my research is to better understand the relationship between language use and sound representation in the multilingual mind, as well as the structure of sound systems in human languages. Most of my research is conducted on bilinguals of varying proficiency and linguistic experience. Some of my recent projects have centered on native phonetic experience and its influence on L2 speech production, perception and lexical processing. I also focus my attention on coding, statistical analysis, data visualization, and reproducible research, as well as training researchers to implement open research practices in the speech sciences, particularly in Bilingualism/Second Language Acquisition research. I also enjoy playing music, Casio watches and anything related to el andalú.\n\n\n\n\nInterests\n\nPhonetics/Phonology\nSpeech production, perception,spoken-word recognition\nSecond language acquisition\nBilingualism\nStatistics/Data visualization\n\n\n\nEducation\n\n\nPhD in Spanish Linguistics, 2016 University of Arizona\n\n\nMA in Spanish Linguistics, 2012 University of Arizona\n\n\nBA in Psychology, 2006 Western Washington University"
  },
  {
    "objectID": "posts/2015-06-16_google_sheets_in_r/2015-06-16_google_sheets_in_r.html",
    "href": "posts/2015-06-16_google_sheets_in_r/2015-06-16_google_sheets_in_r.html",
    "title": "How to scrape data from Google Sheets in R",
    "section": "",
    "text": "Google Forms offers a convenient way to collect data online. It is particularly useful because you can embed the form in a webpage, link the results with a spreadsheet and publish the results online. This post shows how to scrape the data from the spreadsheet (google form) in r using the package RCurl. You should be able to follow along by copying and pasting the code into an R session.\nIdeally you can use this method once you have collected data using a google form. For our purposes I just created a google sheet and I will scrape the data from there.\n\nGet some data\nTo show how this works, I simulated some data with the following code:\n\n# create fake data\n# to save in google sheet\n\nset.seed(1)\ndf &lt;- data.frame(\n    subj = 1:30, \n    group = gl(2, 15, labels = c(\"mono\", \"bi\")), \n    score = c(rnorm(15, 87, 8), rnorm(15, 94, 3))\n    )\n\nI then copy and pasted the data frame into a google sheet. To do this, open google drive and create a new sheet.\n\n\n\n\n\n\n\n\n\nOnce you have some data in a sheet you need to do a few things before you are ready to fire up R.\nFirst, you need to publish your sheet to the web (File &gt; Publish to the web…):\n\nPublish the sheet and copy the public link from the window.\n\nAs you can see, my link is:\nhttps://docs.google.com/spreadsheets/d/1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM/pubhtml\nCopy your link and save it somewhere. We will need it in just a second.\nNow we’re ready for R. Here are the packages I used:\n\n# load libraries\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(RCurl)\nlibrary(ggplot2)\nlibrary(DT)\nlibrary(pander)\n\n\n\nScrape\nWe will use the RCurl package to scrape the data. The command we need is getForm(). The first arguement represents the URI to which the form is posted. You can just use the one shown below for a google sheet. The important part here is the key arguement. You need to copy it from the link you saved above. The key can be found in the last part of the link. Here is my link again:\n\nhttps://docs.google.com/spreadsheets/d/1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM/pubhtml\n\nSpecifically we want:\n1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM\nTherefore we can delete https://docs.google.com/spreadsheets/d/ from the beginning, as well as /pubhtml from the end. Check the key arguement below. Finally, we use the read.csv() command to import the data.\n\n# scrape data\n\nsheet = getForm(\"https://spreadsheets.google.com/spreadsheet/pub\", \n                hl =\"en_US\", \n                key = \"1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM\", \n                output = \"csv\", \n                .opts = list(followlocation = TRUE, \n                             verbose = TRUE, \n                             ssl.verifypeer = FALSE)) \n\ndf &lt;- read.csv(textConnection(sheet))\n\nLet’s see if it worked…\n\npandoc.table(df, style = \"rmarkdown\", round = 2)\n\n\n\n\nsubj\ngroup\nscore\n\n\n\n\n1\nmono\n81.99\n\n\n2\nmono\n88.47\n\n\n3\nmono\n80.31\n\n\n4\nmono\n99.76\n\n\n5\nmono\n89.64\n\n\n6\nmono\n80.44\n\n\n7\nmono\n90.9\n\n\n8\nmono\n92.91\n\n\n9\nmono\n91.61\n\n\n10\nmono\n84.56\n\n\n11\nmono\n99.09\n\n\n12\nmono\n90.12\n\n\n13\nmono\n82.03\n\n\n14\nmono\n69.28\n\n\n15\nmono\n96\n\n\n16\nbi\n93.87\n\n\n17\nbi\n93.95\n\n\n18\nbi\n96.83\n\n\n19\nbi\n96.46\n\n\n20\nbi\n95.78\n\n\n21\nbi\n96.76\n\n\n22\nbi\n96.35\n\n\n23\nbi\n94.22\n\n\n24\nbi\n88.03\n\n\n25\nbi\n95.86\n\n\n26\nbi\n93.83\n\n\n27\nbi\n93.53\n\n\n28\nbi\n89.59\n\n\n29\nbi\n92.57\n\n\n30\nbi\n95.25\n\n\n\nLooks good. Now we can visualize and analyze the data.\n\ndf %&gt;%\n  ggplot(., aes(x = as.numeric(group), y = score)) +\n  scale_x_discrete(limits = c(2, 1), labels = c(\"Bilingual\", \"Monolingual\")) +\n  geom_jitter() +\n  geom_point() +\n  geom_smooth(method = \"lm\") + \n  labs(x = \"Group\", y = \"Score\")\n\n\nAnd that’s it."
  },
  {
    "objectID": "posts/2024-04-18_praatpicture/index.html",
    "href": "posts/2024-04-18_praatpicture/index.html",
    "title": "How to create elegant waveform/spectrogram images in R",
    "section": "",
    "text": "Generating elegant dataviz for spectrogram/waveforms can be cumbersome. Praat has excellent plotting capabilities, but can be rather difficult to teach, especially if you want to plot the waveform/spectrogram/textgrid combination. I posted on the topic a long time ago for a solution in R, and this post is an update of sorts, particularly for those not interested in working in Praat directly."
  },
  {
    "objectID": "posts/2024-04-18_praatpicture/index.html#reproducibility-information",
    "href": "posts/2024-04-18_praatpicture/index.html#reproducibility-information",
    "title": "How to create elegant waveform/spectrogram images in R",
    "section": "Reproducibility information",
    "text": "Reproducibility information\nThis document was written in quarto.\nSession info\n\n\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       macOS Sonoma 14.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/New_York\n date     2024-04-18\n pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n\n\n             loadedversion       date\nbit                  4.0.5 2022-11-15\nbit64                4.0.5 2020-08-30\ncachem               1.0.8 2023-05-01\ncli                  3.6.2 2023-12-11\ncolorspace           2.1-0 2023-01-23\ncrayon               1.5.2 2022-09-29\ndevtools             2.4.5 2022-10-11\ndigest              0.6.35 2024-03-11\ndplyr                1.1.4 2023-11-17\nellipsis             0.3.2 2021-04-29\nevaluate              0.23 2023-11-01\nfansi                1.0.6 2023-12-08\nfastmap              1.1.1 2023-02-24\nfs                   1.6.3 2023-07-20\ngenerics             0.1.3 2022-07-05\nggplot2              3.5.0 2024-02-23\nglue                 1.7.0 2024-01-09\ngridExtra              2.3 2017-09-09\ngtable               0.3.4 2023-08-21\nhere                 1.0.1 2020-12-13\nhms                  1.1.3 2023-03-21\nhtmltools            0.5.7 2023-11-03\nhtmlwidgets          1.6.4 2023-12-06\nhttpuv              1.6.14 2024-01-26\njsonlite             1.8.8 2023-12-04\nknitr                 1.45 2023-10-30\nlater                1.3.2 2023-12-06\nlifecycle            1.0.4 2023-11-07\nmagrittr             2.0.3 2022-03-30\nMASS            7.3-60.0.1 2024-01-13\nmemoise              2.0.1 2021-11-26\nmime                  0.12 2021-09-28\nminiUI             0.1.1.1 2018-05-18\nmunsell              0.5.0 2018-06-12\nphonTools          0.2-2.2 2023-11-20\npillar               1.9.0 2023-03-22\npkgbuild             1.4.3 2023-12-10\npkgconfig            2.0.3 2019-09-22\npkgload              1.3.4 2024-01-16\npraatpicture         1.0.0 2024-03-07\nprofvis              0.3.8 2023-05-02\npromises             1.2.1 2023-08-10\npurrr                1.0.2 2023-08-10\nR6                   2.5.1 2021-08-19\nRColorBrewer         1.1-3 2022-04-03\nRcpp                1.0.12 2024-01-09\nreadr                2.1.5 2024-01-10\nremotes            2.4.2.1 2023-07-18\nrlang                1.1.3 2024-01-10\nrmarkdown             2.26 2024-03-05\nrPraat             1.3.2-1 2021-02-27\nrprojroot            2.0.4 2023-11-05\nrstudioapi          0.16.0 2024-03-24\nscales               1.3.0 2023-11-28\nsessioninfo          1.2.2 2021-12-06\nshiny                1.8.0 2023-11-17\nsignal               1.8-0 2023-11-27\nstringi              1.8.3 2023-12-11\nstringr              1.5.1 2023-11-14\ntibble               3.2.1 2023-03-20\ntidyselect           1.2.1 2024-03-11\ntuneR                1.4.6 2023-11-27\ntzdb                 0.4.0 2023-05-12\nurlchecker           1.0.1 2021-11-30\nusethis              2.2.3 2024-02-19\nutf8                 1.2.4 2023-10-22\nvctrs                0.6.5 2023-12-01\nviridis              0.6.5 2024-01-29\nviridisLite          0.4.2 2023-05-02\nvroom                1.6.5 2023-12-05\nwrassp               1.0.5 2024-01-09\nxfun                  0.42 2024-02-08\nxtable               1.8-4 2019-04-21\nyaml                 2.3.8 2023-12-11"
  },
  {
    "objectID": "posts/2024-03-30_load_many_files/index.html",
    "href": "posts/2024-03-30_load_many_files/index.html",
    "title": "How to load many csv files at once",
    "section": "",
    "text": "Sometimes we collect data from different sources and need to load it all into a single data frame in R. In my research this happens quite often, usually when collecting behavioral data. For example, I tend to use psychopy a lot to present stimuli. This outputs a separate .csv file for each participant. So, how do you get all of those .csv files into R? In this post, I show you the way I usually do it, as well as a new(er) (to me) method that is more flexible."
  },
  {
    "objectID": "posts/2024-03-30_load_many_files/index.html#reproducibility-information",
    "href": "posts/2024-03-30_load_many_files/index.html#reproducibility-information",
    "title": "How to load many csv files at once",
    "section": "Reproducibility information",
    "text": "Reproducibility information\nThis document was written in quarto.\nSession info\n\n\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       macOS Sonoma 14.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/New_York\n date     2024-03-30\n pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n\n\n            loadedversion       date\nbit                 4.0.5 2022-11-15\nbit64               4.0.5 2020-08-30\ncachem              1.0.8 2023-05-01\ncli                 3.6.2 2023-12-11\ncrayon              1.5.2 2022-09-29\ndevtools            2.4.5 2022-10-11\ndigest             0.6.35 2024-03-11\nellipsis            0.3.2 2021-04-29\nevaluate             0.23 2023-11-01\nfansi               1.0.6 2023-12-08\nfastmap             1.1.1 2023-02-24\nfs                  1.6.3 2023-07-20\nglue                1.7.0 2024-01-09\nhms                 1.1.3 2023-03-21\nhtmltools           0.5.7 2023-11-03\nhtmlwidgets         1.6.4 2023-12-06\nhttpuv             1.6.14 2024-01-26\njsonlite            1.8.8 2023-12-04\nknitr                1.45 2023-10-30\nlater               1.3.2 2023-12-06\nlifecycle           1.0.4 2023-11-07\nmagrittr            2.0.3 2022-03-30\nmemoise             2.0.1 2021-11-26\nmime                 0.12 2021-09-28\nminiUI            0.1.1.1 2018-05-18\npillar              1.9.0 2023-03-22\npkgbuild            1.4.3 2023-12-10\npkgconfig           2.0.3 2019-09-22\npkgload             1.3.4 2024-01-16\nprofvis             0.3.8 2023-05-02\npromises            1.2.1 2023-08-10\npurrr               1.0.2 2023-08-10\nR6                  2.5.1 2021-08-19\nRcpp               1.0.12 2024-01-09\nreadr               2.1.5 2024-01-10\nremotes           2.4.2.1 2023-07-18\nrlang               1.1.3 2024-01-10\nrmarkdown            2.26 2024-03-05\nrstudioapi         0.16.0 2024-03-24\nsessioninfo         1.2.2 2021-12-06\nshiny               1.8.0 2023-11-17\nstringi             1.8.3 2023-12-11\nstringr             1.5.1 2023-11-14\ntibble              3.2.1 2023-03-20\ntidyselect          1.2.1 2024-03-11\ntzdb                0.4.0 2023-05-12\nurlchecker          1.0.1 2021-11-30\nusethis             2.2.3 2024-02-19\nutf8                1.2.4 2023-10-22\nvctrs               0.6.5 2023-12-01\nvroom               1.6.5 2023-12-05\nxfun                 0.42 2024-02-08\nxtable              1.8-4 2019-04-21\nyaml                2.3.8 2023-12-11"
  },
  {
    "objectID": "posts/2024-03-30_load_many_files/index.html#footnotes",
    "href": "posts/2024-03-30_load_many_files/index.html#footnotes",
    "title": "How to load many csv files at once",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: this strategy won’t work with the base R function read.csv because it is not vectorized.↩︎"
  }
]