[
  {
    "path": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/",
    "title": "Exploring phonemic boundaries using logistic regression",
    "description": "In this post I show how to use logistic regression to get interesting info \nabout bilinguals in a two-alternative forced choice task.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2021-05-16",
    "categories": [
      "stats",
      "glm",
      "bilinguals",
      "double phonemic boundary"
    ],
    "contents": "\nA bit of background\nThis post is about phonemic boundaries. Imagine we are interested in understanding stop voicing distinctions in English/Spanish bilinguals. English and Spanish have the same stop voicing contrasts at bilabial (/b, p/), coronal (/d, t/), and velar (/g, k/) place, but the phonetic realizations differ in a variety of ways. We will focus on voice-onset time (VOT). English has contrasts between lag stops (short-lag vs.¬†long-lag VOT) and Spanish is a true voicing language, i.e., the contrasts are between phonetically voiced and short-lag stops.\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#vlfpmkrsov .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#vlfpmkrsov .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#vlfpmkrsov .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#vlfpmkrsov .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#vlfpmkrsov .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#vlfpmkrsov .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#vlfpmkrsov .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#vlfpmkrsov .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#vlfpmkrsov .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#vlfpmkrsov .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#vlfpmkrsov .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#vlfpmkrsov .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#vlfpmkrsov .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#vlfpmkrsov .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vlfpmkrsov .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vlfpmkrsov .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#vlfpmkrsov .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#vlfpmkrsov .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vlfpmkrsov .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#vlfpmkrsov .gt_left {\n  text-align: left;\n}\n\n#vlfpmkrsov .gt_center {\n  text-align: center;\n}\n\n#vlfpmkrsov .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#vlfpmkrsov .gt_font_normal {\n  font-weight: normal;\n}\n\n#vlfpmkrsov .gt_font_bold {\n  font-weight: bold;\n}\n\n#vlfpmkrsov .gt_font_italic {\n  font-style: italic;\n}\n\n#vlfpmkrsov .gt_super {\n  font-size: 65%;\n}\n\n#vlfpmkrsov .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nLanguage\n      Stops\n      Phonetic realization\n    English\n      /bdg/\n      short-lag VOT\n     \n      /ptk/\n      long-lag VOT\n    Spanish\n      /bdg/\n      lead VOT\n     \n      /ptk/\n      short-lag VOT\n    \n\nFor an adult English speaker that wants to learn Spanish, one difficulty they encounter is related to VOT, that is, they have to learn the VOT patterns of Spanish, which differ from those of English. As a method of assessing phonological learning in second language acquisition (SLA), we might be interested in knowing if the boundary between a voiced/voiceless pair is different in English than in Spanish for a group of individuals who learned Spanish as adults.\nOne way researchers do this is by (re)synthesizing acoustic stimuli to create a VOT continuum and then asking learners to categorize the sounds. What we typically see is that for one end of the continuum all the stimuli are categorized as being ‚Äòvoiced‚Äô and then at some point there is a shift to ‚Äòvoiceless‚Äô. Where this shift occurs is what we are after in this post.\n\n\n\nThe shift usually occurs further to the left for Spanish speakers than for English speakers, which is a consequence of the phonetic nature of the voicing contrasts, i.e., lead vs.¬†short-lag (Spanish) or short-lag vs.¬†long-lag (English). So, for an adult English speaker that is proficient in Spanish, one might expect different identification functions depending on which language they are identifying, Spanish or English.\nIn this post I am going to simulate data from this type of experiment and analyze them in a variety of ways. One fun detail, the experimental design assumes that the participants are always identifying the same stimuli, but we will tell them that they are hearing a different language, Spanish or English, in different experimental sessions.\n\nThere are a series of experiments that do this. I won‚Äôt go into more detail here, but check out Gonzales et. al (2019), and Lozano et. al (2020) for recent examples.\nThese are the packages I will primarily be using:\n\n\nlibrary(\"dplyr\")      # Data wrangling\nlibrary(\"tidyr\")      # Data wrangling\nlibrary(\"purrr\")      # Iteration on lists\nlibrary(\"lme4\")       # Model fitting\nlibrary(\"AICcmodavg\") # Model preds\nlibrary(\"ggplot2\")    # Plotting\n\n\n\nGetting data\nThe first thing we need to do is get some data. In this post I am going to simulate data that is similar to the output you would get from a two-alternative forced choice (2AFC) task, but before we simulate we need to discuss the experimental paradigm a bit so that everything makes sense.\nA 2AFC task is quite simple. The participant is presented something‚Äîin this case auditory stimuli‚Äîand then make a binary decision about it.\n\nYou can see code and examples of this type of task in python here.\nIn this particular hypothetical experiment participants are presented stimuli that is randomly drawn from a VOT continuum ranging from -60 to 60 ms in 10 ms steps (that‚Äôs 13 steps total). We will present the entire continuum 15 times, so each participant will provide 195 responses. This would be an extremely boring experiment, but that‚Äôs another discussion. We will assume the experiment is given in two sessions, a Spanish session and an English session. The only difference between sessions is that the participants will be told that they are going to categorize English stimuli in the English session and Spanish stimuli in the Spanish session. Importantly, the actual continuum of stimuli they hear is exactly the same. Tricky, right?\n\nThe crucial question here is whether or not proficient adult language learners adjust their perceptual boundaries based on their underlying expectations about the language. It turns out they do! Here is second shameless plug for the Lozano et. al (2020) paper. üòÑ\nWe will simulate data for 25 participants, and two language sessions (or language modes), English and Spanish. If you‚Äôre doing the math, that is 25 participants \\(\\times\\) 13 steps \\(\\times\\) 15 item repetitions \\(\\times\\) 2 language modes, which gives us a data set with a grand total of 9750 responses (i.e., 9750 rows in the dataframe). (Note: If you aren‚Äôt interested in the whole simulation process just skip the next section.)\nSpecifying the model\nOur criterion is binary (0/1) responses. Specifically, this refers to whether the participant responds ‚Äòvoiced‚Äô (0) or ‚Äòvoiceless‚Äô (1) to each pull from the VOT continuum. For this reason we will simulate from the binomial distribution. Our model will look something like this:\n\\[\n\\begin{aligned}\nresponse_{i} \\sim & \\ Binomial(p_{i}, m_{i}) \\\\\nlogit(p_{i}) = & \\ \\beta_{0} + \\beta_{1} * VOT_{1} + \\beta_{2} * I_{(language_{i} = Spanish)2} + \\beta_{3} * VOT_{1} * I_{2}\n\\end{aligned}\n\\]\n‚Ä¶where we analyze the log odds of ‚Äòvoiceless‚Äô responses as a function of VOT, i.e., the step in the continuum, language mode (if they think they are hearing English or Spanish) and the interaction between the two.\n\n\n# Set seed for reproducibility\nset.seed(20210514)\n\n# dataframe params\nn_ids       <- 25\nn_steps     <- 13\nn_lang      <- 2\nn_item_reps <- 15\n\n# Set up dataframe\nid        <- rep(glue::glue(\"id_{1:n_ids}\"), each = n_steps * n_lang)\nvot       <- rep(seq(-60, 60, 10), times = n_ids * n_lang)\nlanguage  <- rep(c(\"English\", \"Spanish\"), each = n_steps, times = n_ids)\ndat       <- data.frame(id, vot, language, n_item_reps)\n\n# Model params\nb0          <- -1.10 # intercept\nb1          <-  0.09 # slope VOT\nb2          <-  0.80 # language effect\nb12         <- -0.01 # slope adj. for Spanish\nid_var      <-  0.20 # id variability\nstep_var    <-  0.50 # step variability\nlang_var    <-  0.11 # lang variability\n\n# Simulate random effects\nid_eff   <- rep(rnorm(n = n_ids, mean = 0, sd = id_var), each = n_steps * n_lang)\nstep_eff <- replicate(n = n_ids, rep(rnorm(n_steps, 0, step_var), times = n_lang), \n              simplify = F) %>% \n            unlist()\n\n# Get log odds from linear predictor and convert to probability\nlog_odds <- b0 + \n            b1 * vot + \n            b2 * (language == \"Spanish\") + \n            b1 * vot * b12 * (language == \"Spanish\") + \n            id_eff + step_eff \nprop     <- plogis(log_odds)\n\n# Generate binomial responses\ndat$response <- rbinom(n = n_ids * n_steps * n_lang, size = n_item_reps, prob = prop)\n\n# Expand binomial responses to binary\ndat_long <- dat %>%\n  nest(data = c(response, n_item_reps)) %>%\n  mutate(response = map(data, ~c(rep(1, .x$response),\n                                 rep(0, .x$n_item_reps - .x$response)))) %>%\n  select(-data) %>%\n  unnest(response) %>% \n  group_by(id, vot, language) %>% \n  mutate(item_rep = seq_along(vot)) %>% \n  ungroup() %>% \n  mutate(item_rep = (item_rep - mean(item_rep)) / sd(item_rep), \n         vot_std = (vot - mean(vot)) / sd(vot))\n  \n\n\n\nThe code above simulates the data set. I won‚Äôt go into detail about how it works (maybe for another post), but I do want to point out two things: 1) I‚Äôve added an item_rep variable to keep track of what repetition (out of 15) a given response comes from, and 2) I have standardized vot (vot_std) and item_rep in order to improve computational efficiency of the model. It will be important to keep this in mind when we begin analyzing and plotting the results.\n\nThese models are notoriously slow in lme4 and often have convergence issues. I normally work in a Bayesian framework, so I might update this at some point.\nHere is what the output of one block of the experiment for one participant looks like:\n\n\ndat_long %>% \n  filter(item_rep == 0) %>% \n  select(-item_rep, -vot_std) %>% \n  head(., 13) %>% \n  gt::gt()\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#wixribalbk .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#wixribalbk .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wixribalbk .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#wixribalbk .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#wixribalbk .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wixribalbk .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wixribalbk .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#wixribalbk .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#wixribalbk .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#wixribalbk .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#wixribalbk .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#wixribalbk .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wixribalbk .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wixribalbk .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#wixribalbk .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#wixribalbk .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#wixribalbk .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#wixribalbk .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wixribalbk .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#wixribalbk .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wixribalbk .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#wixribalbk .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#wixribalbk .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wixribalbk .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wixribalbk .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#wixribalbk .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wixribalbk .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#wixribalbk .gt_left {\n  text-align: left;\n}\n\n#wixribalbk .gt_center {\n  text-align: center;\n}\n\n#wixribalbk .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#wixribalbk .gt_font_normal {\n  font-weight: normal;\n}\n\n#wixribalbk .gt_font_bold {\n  font-weight: bold;\n}\n\n#wixribalbk .gt_font_italic {\n  font-style: italic;\n}\n\n#wixribalbk .gt_super {\n  font-size: 65%;\n}\n\n#wixribalbk .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nid\n      vot\n      language\n      response\n    id_1\n      -60\n      English\n      0\n    id_1\n      -50\n      English\n      0\n    id_1\n      -40\n      English\n      0\n    id_1\n      -30\n      English\n      0\n    id_1\n      -20\n      English\n      0\n    id_1\n      -10\n      English\n      0\n    id_1\n      0\n      English\n      0\n    id_1\n      10\n      English\n      1\n    id_1\n      20\n      English\n      1\n    id_1\n      30\n      English\n      1\n    id_1\n      40\n      English\n      1\n    id_1\n      50\n      English\n      1\n    id_1\n      60\n      English\n      1\n    \n\nLooks good. Now we are ready to fit the model.\nMultilevel logistic regression model\nAs mentioned above, our data is binary and we have repeated measures. We will fit a multilevel logistic regression model to account for nesting in the data. A key part here is the random effects structure, which will allow us to do some interesting individual differences analyses post-hoc.\n\n\n# Fit partial pooling model\nmod <- glmer(\n  formula = response ~ vot_std * language + \n    (1 | id) + \n    (1 + vot_std + item_rep | id:language), \n  control = glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 2e6)), \n  family = binomial(link = \"logit\"), \n  data = dat_long\n  )\n\n\n\n\n\n\n\n\n¬†\n\n\nresponse\n\n\nPredictors\n\n\nLog-Odds\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n-1.16\n\n\n-2.13¬†‚Äì¬†-0.19\n\n\n0.019\n\n\nvot_std\n\n\n3.56\n\n\n2.58¬†‚Äì¬†4.54\n\n\n<0.001\n\n\nlanguage [Spanish]\n\n\n1.60\n\n\n1.22¬†‚Äì¬†1.98\n\n\n<0.001\n\n\nvot_std * language[Spanish]\n\n\n-0.10\n\n\n-0.63¬†‚Äì¬†0.43\n\n\n0.722\n\n\nRandom Effects\n\n\nœÉ2\n\n3.29\n\n\nœÑ00id:language\n\n2.57\n\n\nœÑ00id\n\n0.45\n\n\nœÑ11id:language.vot_std\n\n15.24\n\n\nœÑ11id:language.item_rep\n\n12.96\n\n\nœÅ01id:language.vot_std\n\n-0.98\n\n\nœÅ01id:language.item_rep\n\n0.95\n\n\nICC\n\n\n0.85\n\n\nN id\n\n25\n\n\nN language\n\n2\n\n\nObservations\n\n\n9750\n\n\nMarginal R2 / Conditional R2\n\n0.376 / 0.905\n\n\nWe won‚Äôt focus on interpreting the output. Instead let‚Äôs use the model to generate predictions and plot those.\n\n\n# Setup new dataframe to predict on\nnew_dat <- select(dat, -n_item_reps, -response) %>% \n  mutate(vot_std = (vot - mean(vot)) / sd(vot))\n\n# Get model predictions and SE\nfits <- predictSE(mod, new_dat) %>%\n  as_tibble %>%\n  mutate(ymin = fit - se.fit, ymax = fit + se.fit) %>%\n  bind_cols(new_dat) \n\n# Plot it\np_sigmoids <- fits %>% \n  ggplot(., aes(x = vot_std, y = fit, color = language, fill = language)) + \n    geom_ribbon(aes(ymax = ymax, ymin = ymin), \n      alpha = 0.2, color = NA, show.legend = F) +\n    geom_line(size = 0.75) + \n    geom_point(color = \"white\", stroke = 1.5, size = 4, pch = 21) + \n    geom_jitter(data = dat_long, \n      width = 0.2, height = 0.01, alpha = 0.02, pch = 21, \n      aes(x = vot_std, \n        y = if_else(response == 1, response + 0.05, response - 0.05))) + \n    labs(y = \"P(response = /p/)\", x = \"VOT (ms)\") + \n    scale_y_continuous(breaks = seq(0, 1, 0.25)) + \n    scale_x_continuous(breaks = unique(fits$vot_std)[c(TRUE, FALSE)], \n      labels = seq(-60, 60, 20)) + \n    scale_fill_viridis_d(name = NULL, end = 0.8) + \n    scale_color_viridis_d(name = NULL, end = 0.8) + \n    ds4ling::ds4ling_bw_theme() + \n    theme(legend.position = c(0.1, 0.87))\n\np_sigmoids\n\n\n\n\nCool. We can see that in our simulated data the Spanish sigmoid function is shifted to the left with regard to the English sigmoid function. This equates to more ‚Äòvoiceless‚Äô responses when the participants believe they are hearing Spanish.\nCategory boundaries\nOne way this literature has assessed categorical perception in bilinguals is by calculating and comparing the 50% cross over point for each language. This is the point where the probability of responding ‚Äòvoiceless‚Äô is exactly 0.5. If we just eyeball the plot above, we can guess that this is around -5 ms for Spanish and around 13 ms for English, but we can do better than just eyeballing it. We will use the following formula to calculate the boundary, which we‚Äôll just call the ‚Äúcrossover‚Äù (CO), between /b-p/ for each language session:\n\\[\nCO_{En} = \\frac{\\beta_{0}}{\\beta_{1}} * -1\n\\]\nThis means, for English, we can calculate the 50% crossover by dividing the intercept by the slope for VOT and multiplying by -1. In case it‚Äôs not clear, intercept and slope refer to the fixed effect parameters we just estimated in the model. We can grab those estimates using fixef.\n\n\nfixef(mod)\n\n\n            (Intercept)                 vot_std \n            -1.15871621              3.56213107 \n        languageSpanish vot_std:languageSpanish \n             1.60004724             -0.09617382 \n\nThe fixef function returns a vector containing the parameter estimates. Since English is the reference level, we just need the first two elements of the vector and we can calculate the boundary like this:\n\n\nen_co <- (fixef(mod)[1] / fixef(mod)[2]) * -1\nen_co\n\n\n(Intercept) \n  0.3252874 \n\nSo the boundary is at 0.325 standard deviations above the mean (0). We can make this value easier to interpret by back-transforming to milliseconds. We do this by adding the mean of the original VOT vector of the dataframe and multiplying by the standard deviation:\n\n\n# Calculate En CO in ms (note the mean is 0, so we could skip that)\n(en_co + mean(dat_long$vot)) * sd(dat_long$vot)\n\n\n(Intercept) \n   12.17176 \n\nSo the English boundary is at about 12.17 ms (my guess was pretty close!). Let‚Äôs calculate the boundary for Spanish and plot them:\n\n\n# Add language effect on the intercept and slope adj for language == Spanish\nsp_co <- (fixef(mod)[1] + fixef(mod)[3]) / (fixef(mod)[2] + fixef(mod)[4]) * -1\nsp_co\n\n\n(Intercept) \n -0.1273331 \n\n\n\n# Create tibble with boundaries and text\nco_text <- tribble(\n  ~'vot_std', ~'fit', ~'language', ~'text', \n  -1.6, 0.5, \"Spanish\", paste0(\"Spanish boundary = \", round(sp_co * sd(dat_long$vot), 2), \" ms\"), \n   0.6, 0.5, \"English\", paste0(\"English boundary = \", round(en_co * sd(dat_long$vot), 2), \" ms\")\n)\n\n# Add to base plot\np_sigmoids + \n  geom_vline(xintercept = c(en_co, sp_co), lty = 3) + \n  geom_text(data = co_text, aes(label = text), \n            hjust = 0, size = 4, family = \"Times\") \n\n\n\n\nContrast coefficient slopes\nAnother way we can assess how the acoustic stimuli are categorized is by looking at the slope of the sigmoid functions at the category boundary (i.e., the 50% crossover point). We do this by calculating the contrast coefficient slope (CCS). Essentially the CCS in the logistic space is related to the slope of the sigmoid function and represents the rate of change from one category to another (i.e., from /b/ to /p/ in our case) in the probability space.\nMorrison (2007) describes CCSs as ‚Äúindicators of the crispness of the boundary between the two categories‚Äù (p.¬†232). Native speakers typically have crisp boundaries between categories, whereas non-native speakers can have ‚Äúfuzzier‚Äù boundaries for a number of reasons.\nI will spare you the calculus, but in a few words the CCS in the probability space is the partial derivative of the slope of the sigmoid function at its steepest point. Conveniently, the steepest value of the slope in the binomial case is when the probability of the criterion is 0.5, i.e., at the crossover boundary. We can calculate the CCS by multiplying the slope of the continuous measure by 0.25:\n\\[\nCCS_{En} = \\beta_{VOT} * 0.25\n\\]\nSo for English, the CCS is calculated as:\n\n\nen_ccs <- fixef(mod)[2] * 0.25\nen_ccs\n\n\n  vot_std \n0.8905328 \n\nThis means that when the the probability of responding ‚Äòvoiceless‚Äô is 0.5, the slope of the sigmoid for English is 0.89 in the probability space. We can calculate this for both languages and plot the lines:\n\n\nsp_ccs <- (fixef(mod)[2] + fixef(mod)[4]) * 0.25\n\nccs_text <- tribble(\n  ~'vot_std', ~'fit', ~'language', ~'text', \n  -1.2, 0.5, \"Spanish\", paste0(\"Spanish CCS = \", round(sp_ccs, 2)), \n   0.6, 0.5, \"English\", paste0(\"English CCS = \", round(en_ccs, 2))\n)\n\np_sigmoids + \n  geom_abline(intercept = 0.5 - en_ccs * en_co, slope = en_ccs, lty = 2) + \n  geom_abline(intercept = 0.5 - sp_ccs * sp_co, slope = sp_ccs, lty = 2) + \n  geom_text(data = ccs_text, aes(label = text), \n            hjust = 0, size = 4, family = \"Times\") \n\n\n\n\nAs you can see, the two category boundaries are ‚Äòcrisp‚Äô in both cases. This is because I simulated the data to be this way, but this leads us to more interesting territory‚Ä¶ we can explore crossover boundaries and contrast coefficient slopes for individuals. Perhaps we are interested in 50% crossover differences as a function of language dominance, or boundary crispness as a function of proficiency. We‚Äôll look at a few ways to do that now.\nIndividual differences\nThere are at least 2 ways to calculate 50% crossover boundaries and contrast coefficient slopes for individual participants. One method is to use the random effects from the omnibus model we fit above (i.e., mod). Another method is fit a logistic regression to the data of each participant. I‚Äôll go with this no-pooling method, but one should certainly give careful thought to both methods and decide which makes the most sense for the research questions of interest.\nWe can easily fit a model to each individual using the lmList function from the lme4 package:\n\n\n# Fit no pooling model(s)\nno_pool_full <- lmList(response ~ vot_std * language + item_rep | id, family = \"binomial\", \n  data = as.data.frame(dat_long))\n\n\n\nI‚Äôll use the coef and head functions to take a peak at the structure of the resulting object.\n\n\ncoef(no_pool_full) %>% head\n\n\n      (Intercept)   vot_std languageSpanish  item_rep\nid_1    -3.023503 10.284538       2.0546029 -4.699046\nid_10   -2.092052  5.447278       2.3253664 -2.579286\nid_11   -2.763849  6.322305       2.3987548 -3.010400\nid_12   -1.537861 10.154082       1.7749160 -4.802198\nid_13   -2.422379  7.767657       1.6767039 -3.582840\nid_14   -1.337919  5.998775       0.9518366 -3.129575\n      vot_std:languageSpanish\nid_1               -0.3950494\nid_10              -0.2198048\nid_11              -0.4747364\nid_12              -1.2850084\nid_13              -0.1588766\nid_14               0.1877061\n\nNice! With a little bit of wrangling and the formulas we looked at previously, we can calculate the CO and CCS of each individual for English and Spanish.\n\n\nid_diffs <- no_pool_full %>% \n  coef() %>% \n  as_tibble() %>% \n  transmute(\n    id = rownames(coef(no_pool_full)), \n    int_English = `(Intercept)`, \n    vot_English = vot_std, \n    int_Spanish = int_English + languageSpanish, \n    vot_Spanish = vot_English + `vot_std:languageSpanish`, \n    co_English  = int_English / vot_English * -1, \n    co_Spanish  = int_Spanish / vot_Spanish * -1, \n    ccs_English = vot_English * 0.25, \n    ccs_Spanish = vot_Spanish * 0.25) %>% \n  select(-vot_English, -vot_Spanish) %>% \n  pivot_longer(\n    cols = -id, \n    names_to = c(\".value\", \"language\"), \n    names_sep = \"_\"\n    ) %>% \n  mutate(co_ms = co * sd(dat_long$vot))\n\nhead(id_diffs)\n\n\n# A tibble: 6 x 6\n  id    language    int      co   ccs co_ms\n  <chr> <chr>     <dbl>   <dbl> <dbl> <dbl>\n1 id_1  English  -3.02   0.294   2.57 11.0 \n2 id_1  Spanish  -0.969  0.0980  2.47  3.67\n3 id_10 English  -2.09   0.384   1.36 14.4 \n4 id_10 Spanish   0.233 -0.0446  1.31 -1.67\n5 id_11 English  -2.76   0.437   1.58 16.4 \n6 id_11 Spanish  -0.365  0.0624  1.46  2.34\n\nNow we are ready to make some plots.\n\n\n# COs\np_co <- id_diffs %>% \n  ggplot(., aes(x = co_ms, y = language)) + \n    geom_jitter(width = 0.1, height = 0.2, alpha = 0.5, pch = 16) + \n    stat_summary(fun.data = mean_sdl, geom = \"pointrange\", pch = 21, \n      fill = \"white\", size = 1.2, fun.args = list(mult = 1)) + \n    labs(y = \"Language\", x = \"Crossover boundary (ms)\", caption = \"\") + \n    ds4ling::ds4ling_bw_theme()\n\n# CCSs\np_ccs <- id_diffs %>% \n  ggplot(., aes(x = ccs, y = language)) + \n    geom_jitter(width = 0.1, height = 0.2, alpha = 0.5, pch = 16) + \n    stat_summary(fun.data = mean_sdl, geom = \"pointrange\", pch = 21, \n      fill = \"white\", size = 1.2, fun.args = list(mult = 1)) + \n    labs(y = NULL, x = \"Contrast coefficient slopes\", caption = \"Mean +/- SD\") + \n    ds4ling::ds4ling_bw_theme() + \n    theme(axis.text.y = element_blank())\n\np_co + p_ccs\n\n\n\n\nWe can also plot the sigmoids of individuals along with the 50% crossovers. Let‚Äôs find the individuals with the largest and smallest differences between English and Spanish boundaries, plus 8 more at random.\n\n\n# Calculate boundary diffs\nco_diffs <- id_diffs %>% \n  select(id, language, co) %>% \n  pivot_wider(names_from = language, values_from = co) %>% \n  mutate(diff = English - Spanish) \n\n# Find smallest and largest diffs\nco_min_max <- c(\n  slice_max(co_diffs, diff, n = 1) %>% pull(id), \n  slice_min(co_diffs, diff, n = 1) %>% pull(id)\n)\n\n# Vector of min, max, plus 8 random subjects\nn_10 <- c(\n  co_min_max, \n  filter(dat_long, (!id %in% co_min_max)) %>% \n  distinct(id) %>% \n  sample_n(8) %>% pull\n)\n\n# Use diff column to order from smallest to largest\nordered_10 <- co_diffs %>% \n  filter(id %in% n_10) %>% \n  arrange(diff) %>% \n  pull(id)\n\nco_base <- dat_long %>% \n  filter(id %in% n_10) %>% \n  mutate(id = forcats::fct_relevel(id, ordered_10)) %>% \n  ggplot(., aes(x = vot_std, y = response, color = language)) + \n    facet_wrap(~id, nrow = 2) + \n    geom_jitter(width = 0.2, height = 0.01, alpha = 0.1, pch = 21, size = 0.6, \n      aes(y = if_else(response == 1, response + 0.05, response - 0.05))) + \n    geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), \n      formula = \"y ~ x\", se = F) + \n    labs(y = \"P(response = /p/)\", x = \"VOT (ms)\") + \n    scale_y_continuous(breaks = seq(0, 1, 0.25)) + \n    scale_x_continuous(breaks = unique(fits$vot_std)[c(TRUE, FALSE, FALSE)], \n      labels = seq(-60, 60, 30)) + \n    scale_fill_viridis_d(name = NULL, end = 0.8) + \n    scale_color_viridis_d(name = NULL, end = 0.8) + \n    ds4ling::ds4ling_bw_theme(base_family = \"Times\", base_size = 10) + \n    theme(legend.position = \"bottom\")\n\nco_base + \n  geom_vline(\n    data = filter(id_diffs, id %in% n_10) %>% \n      mutate(id = forcats::fct_relevel(id, ordered_10)), \n    aes(xintercept = co, color = language), lty = 2, show.legend = F)\n\n\n\n\nco_base + \n  geom_abline(\n    data = filter(id_diffs, id %in% n_10) %>% \n      mutate(id = forcats::fct_relevel(id, ordered_10)),\n    aes(intercept = 0.5 - co * ccs, slope = ccs, color = language), lty = 2, \n    show.legend = F)\n\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-05-15_logistic_regression_and_phonemic_boundaries/2021-05-15_logistic_regression_and_phonemic_boundaries_files/figure-html5/sigmoids-1.png",
    "last_modified": "2021-05-18T08:34:34-04:00",
    "input_file": "2021-05-15_logistic_regression_and_phonemic_boundaries.utf8.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2018-09-16_setting_up_a_whisper_room_sound_booth/",
    "title": "Setting up a whisper room sound booth",
    "description": "It is harder than it looks.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2018-09-16",
    "categories": [],
    "contents": "\n\n\n\nPackaging\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrevious\n\n\n\nNext\n\n\n\nAssembly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrevious\n\n\n\nNext\n\n\n\nAftermath\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrevious\n\n\n\nNext\n\n\n\nWalkthrough\n\n\n\n\n\n\n\n\n\n\nPrevious\n\n\n\nNext\n\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-20T16:36:51-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2017-05-15_analysis_of_justin_bieber_singing_in_spanish_-_despacito/",
    "title": "Justin Bieber sings in Spanish: How'd he do?",
    "description": "The title really says it all.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2017-05-15",
    "categories": [
      "phonetics",
      "stops",
      "vot"
    ],
    "contents": "\nTL;DR\n\n\n\nIn the remixed version of the song ‚Äúdespacito‚Äù, Justin Bieber sings in Spanish. Some articles online criticize his pronunciation. I analyzed his realization of ‚Äúp‚Äù and ‚Äút‚Äù in Praat and find that, while his pronunciation is not perfect, it is pretty good. I don‚Äôt believe he commits the ‚Äúerrors‚Äù suggested in the article.\nOverview\nI recently heard the song despacito featuring teen hero Justin Bieber (my wife mentioned to me that he sings in Spanish and my curiosity got the best of me). I distinctly remember being rather impressed by how well he sang in Spanish, so I was surprised when I saw this article pop up in my facebook feed. Basically, J Balvin and Nicky Jam (I have no idea who these guys are) make fun of J Biebs accent. Specifically, they harp on his pronunciation of the title of the song, suggesting the /t/ in the diminutive form of ‚Äúdespacio‚Äù (slow) is realized as […π]. In fact, they sing it a few times [des.pa.si.…πo] (des-pa-see-row, if you aren‚Äôt familiar with IPA) and, in jest, claim at one point that he sings ‚Äòdorito‚Äô [√∞o.…πi.…æo]. You can watch this specific part here:\n\n\n\n\n\n\nNow, this type of non-native pronunciation actually makes a lot of sense, at least I think the ‚Äòdorito‚Äô comment does. In American and Canadian English an intervocalic ‚Äút‚Äù (and ‚Äúd‚Äù) is usually pronounced as a flap, which in essence corresponds with Spanish ‚Äúr‚Äù in the same position (note: it has to be in the same position, otherwise it would pronounced as a trill). This leads to all kinds of difficulties for learners of Spanish because they have to avoid a phonological process of their native language. For example, a common mispronunciation of the Spanish word ‚Äútodo‚Äù (all) is [to.…æo], which actually means ‚Äútoro‚Äù (bull). That is, English speakers (mis)pronounce the intervocalic /d/ as a flap, which is most perceptually similar to Spanish ‚Äúr‚Äù. On the other hand, when they try to pronounce ‚Äútoro‚Äù, the ‚Äúr‚Äù is realized as the English rhotic […π].\nThus, if Bieber were pronouncing /ito/ as most native English speakers do, as a flap, it would be perceived as a Spanish ‚Äúr‚Äù (the flap, not the trill). However, there is no real explanation for why he would pronounce it with an English rhotic ([…π]) as J Balvin and Nicky Jam claim. I personally did not hear this pronunciation, so I assume they were just teasing the teenage heart throb. Nonetheless, I noticed a lot of comments in the article were also making fun of his pronunciation, so I decided I would take a look in praat to determine if I am going crazy or if the internet is just full of haters. Here is an example of what we will look at:\n\n\n\nYour browser does not support the audio element. \n\nThe analysis\nI downloaded the music video from youtube and converted the .mp4 file to .m4a, and then to .wav. In praat I converted the .wav from stereo to mono. Justin sings the chorus as well as some of the verses. I‚Äôm just going to look at the chorus because the verses are accompanied by Daddy Yankee and/or Luis Fonsi. Luckily, pretty much every time he says ‚Äúdespacito‚Äù in the chorus there is silence, so we can use that for our analysis. I am going to focus on how he pronounces the stop /t/ (though I did get formant frequency measurements for all the vowels‚Ä¶ maybe for another post). This only leaves us with about 5 useful tokens, but there are also a good amount of /p/‚Äôs that we can compare them with. Here is arguably the best token:\n\n\n\nIt‚Äôs clear‚Äîat least to me‚Äîthat Justin is not producing an English rhotic where he should be producing [t]. In other words, he is not saying des-pa-see-row. How do I know? Well, if we zoom in on the final /ito/, we notice two things: 1) there is clearly a closure and 2) there is a burst. These are characteristics of a stop consonant. Now, you might be thinking ‚ÄúYeah, but a flap looks pretty similar in a spectrogram‚Äù and you wouldn‚Äôt be wrong, but the clear difference here is that after the release there is a short gap before the voicing of the final /o/. This short gap is called voice-onset time (VOT). Stops have VOT; flaps do not. Here is a close up:\n\n\n\nNow a characteristic of English voiceless stops (‚Äúp‚Äù, ‚Äút‚Äù, ‚Äúk‚Äù) is that in word initial position they are produced with aspiration and have long-lag VOT, usually around 60 ms. We refer to them in IPA with: [ph, th, kh]. Voiceless stops are different in Spanish, as they are not aspirated and have short-lag VOT, usually from 0 to 25 ms. The ‚Äúito‚Äù of ‚Äúdespacito‚Äù is word internal, thus, in theory, for an English speaker it should not be aspirated because it is normally realized as a flap, though in emphatic speech it could be realized as [th]. Hopefully I have already convinced you that Biebs is not flapping. So our next question is: what kind of VOT do his stops have? If they are short-lag, we can conclude that they are more Spanish-like. If, on the other hand, they are aspirated, then they would be more English-like. So let‚Äôs take a look!\nI measured VOT of every p and t every time Justin sings ‚Äúdespacito‚Äù. First, let‚Äôs load some packages we will need.\n\n\nlibrary(lingStuff)\nlibrary(tidyverse)\n\n\n\nNow we can load the data and check the structure.\n\n\n# Load data\nbieber_vot <- read_csv(\"./assets/data/despacito.csv\")\n\n\n\n\n\n\n\n\n# Check structure of dataframe\nbieber_vot %>%\n  select(., prefix, votP, votT) %>%\n  gather(., key = phon, value = vot, -prefix) %>%\n  str(.)\n\n\ntibble [10 √ó 3] (S3: tbl_df/tbl/data.frame)\n $ prefix: chr [1:10] \"despacito\" \"despacito1\" \"despacito2\" \"despacito3\" ...\n $ phon  : chr [1:10] \"votP\" \"votP\" \"votP\" \"votP\" ...\n $ vot   : num [1:10] 23.3 19.2 19 19.4 15.6 ...\n\nLooks good. Let‚Äôs plot the VOT of the p‚Äôs and t‚Äôs and see how they look. I‚Äôve set the x-limit to range from 0 to 60.\n\n\n# Plot vot as a function of phon\nbieber_vot %>%\n  select(., prefix, votP, votT) %>%\n  gather(., key = phon, value = vot, -prefix) %>%\n  ggplot(., aes(x = phon, y = vot, color = phon)) + \n    stat_summary(fun.data = 'mean_cl_boot', geom = 'pointrange', size = 1.1) +\n    stat_summary(fun.y = 'mean', geom = 'point', color = 'darkred', size = 2.75) +\n    ylim(0, 60) + ylab(\"VOT (ms)\") + xlab(\"\") + \n    scale_x_discrete(labels = c('/p/', '/t/')) + \n    coord_flip() + \n    scale_color_brewer(name = '', guide = F) + \n    theme_dark(base_size = 22, base_family = \"Times\")\n\n\n\n\n\n\n\nRecall that an English-like VOT would be around 60 ms (but could range from around 40 to over 100!). We can see that the p‚Äôs have a VOT of approximately 20 ms (19.29 ms ¬± 2.72 sd, to be exact), and the t‚Äôs have a VOT of around 25 ms (23.1 ms ¬± 7.39 sd). Both are certainly within range of native Spanish pronunciations.\nInterim conclusion: the internet is full of haters.\n\nNot so fast‚Ä¶\nThere is one last thing to keep in mind before we give JBiebs a pass on his Spanish and it‚Äôs an important one. Spanish /t/ and English /t/ are articulated at different places in the mouth. Specifically, Spanish /t/ is dental and English /t/ is alveolar. What this means is that when an English speaker pronounces a word with a ‚Äút‚Äù in Spanish, like ‚Äòdespacito‚Äô, she also needs to change the place of articulation, i.e.¬†the tongue needs to make contact with the back of the top teeth, and not the hard ridge right above them. When we looked at VOT in the present analysis we didn‚Äôt take this difference into account. My personal opinion is that el se√±orito does a pretty good job, but if you listen closely to the very last ‚Äòdespacito‚Äô in the song, it does sound rather alveolar, i.e.¬†gringo-y.\nConclusion: the internet is full of haters.\n\n\nblue {\n    color: #0000CC;\n    font-weight: normal;\n    font-size: 20px;\n}\n\ngrey {\n    color: #515151;\n    font-size: 22px;\n    font-weight: normal;\n}\n\n.video-container {\n    position: relative;\n    padding-bottom: 50%;\n    padding-top: 35px;\n    height: 0;\n    overflow: hidden;\n    width: 70%;\n}\n\n.video-container iframe {\n    position: center;\n    top:0;\n    left: 0;\n    width: 100%;\n    height: 100%;\n}\n\n\n\n\n",
    "preview": "http://media2.giphy.com/media/vVj7DgouGmmqI/giphy.gif",
    "last_modified": "2021-02-20T23:34:57-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2015-06-22_tidyr_tutorial/",
    "title": "tidyr tutorial",
    "description": "Tutorial showing the functionality of the tidyr package for data wrangling.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2015-06-22",
    "categories": [
      "r",
      "tidyverse",
      "data"
    ],
    "contents": "\n\n\n\n\n\n\n",
    "preview": "posts/2015-06-22_tidyr_tutorial/tidyr.png",
    "last_modified": "2021-02-20T23:38:09-05:00",
    "input_file": {},
    "preview_width": 2206,
    "preview_height": 2547
  },
  {
    "path": "posts/2015-06-16_google_sheets_in_r/",
    "title": "How to scrape data from Google Sheets in R",
    "description": "How to get data from a google sheet into R.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2015-06-16",
    "categories": [
      "r",
      "research"
    ],
    "contents": "\nGoogle Forms offers a convenient way to collect data online. It is particularly useful because you can embed the form in a webpage, link the results with a spreadsheet and publish the results online. This post shows how to scrape the data from the spreadsheet (google form) in r using the package RCurl. You should be able to follow along by copying and pasting the code into an R session.\nIdeally you can use this method once you have collected data using a google form. For our purposes I just created a google sheet and I will scrape the data from there.\nGet some data\nTo show how this works, I simulated some data with the following code:\n\n\n# create fake data\n# to save in google sheet\n\nset.seed(1)\ndf <- data.frame(\n  subj = 1:30, \n  group = gl(2, 15, labels = c(\"mono\", \"bi\")), \n  score = c(rnorm(15, 87, 8), rnorm(15, 94, 3))\n  )\n\n\n\nI then copy and pasted the data frame into a google sheet. To do this, open google drive and create a new sheet.\n\n\n\nOnce you have some data in a sheet you need to do a few things before you are ready to fire up R.\nFirst, you need to publish your sheet to the web (File > Publish to the web‚Ä¶):\n\nPublish the sheet and copy the public link from the window.\n\nAs you can see, my link is:\nhttps://docs.google.com/spreadsheets/d/1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM/pubhtml\nCopy your link and save it somewhere. We will need it in just a second.\nNow we‚Äôre ready for R. Here are the packages I used:\n\n\n# load libraries\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(RCurl)\nlibrary(ggplot2)\nlibrary(DT)\nlibrary(pander)\n\n\n\n\nScrape\nWe will use the RCurl package to scrape the data. The command we need is getForm(). The first arguement represents the URI to which the form is posted. You can just use the one shown below for a google sheet. The important part here is the key arguement. You need to copy it from the link you saved above. The key can be found in the last part of the link. Here is my link again:\n\nhttps://docs.google.com/spreadsheets/d/1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM/pubhtml\n\nSpecifically we want:\n1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM\nTherefore we can delete https://docs.google.com/spreadsheets/d/ from the beginning, as well as /pubhtml from the end. Check the key arguement below. Finally, we use the read.csv() command to import the data.\n\n\n# scrape data\n\nsheet = getForm(\"https://spreadsheets.google.com/spreadsheet/pub\", \n                hl =\"en_US\", \n                key = \"1AqS_DAThPUJuS2L2E-S5X7fM1kpIdhXQdBDZUyt-bWM\", \n                output = \"csv\", \n                .opts = list(followlocation = TRUE, \n                             verbose = TRUE, \n                             ssl.verifypeer = FALSE)) \n\ndf <- read.csv(textConnection(sheet))\n\n\n\nLet‚Äôs see if it worked‚Ä¶\n\n\npandoc.table(df, style = \"rmarkdown\", round = 2)\n\n\n\nsubj\ngroup\nscore\n1\nmono\n81.99\n2\nmono\n88.47\n3\nmono\n80.31\n4\nmono\n99.76\n5\nmono\n89.64\n6\nmono\n80.44\n7\nmono\n90.9\n8\nmono\n92.91\n9\nmono\n91.61\n10\nmono\n84.56\n11\nmono\n99.09\n12\nmono\n90.12\n13\nmono\n82.03\n14\nmono\n69.28\n15\nmono\n96\n16\nbi\n93.87\n17\nbi\n93.95\n18\nbi\n96.83\n19\nbi\n96.46\n20\nbi\n95.78\n21\nbi\n96.76\n22\nbi\n96.35\n23\nbi\n94.22\n24\nbi\n88.03\n25\nbi\n95.86\n26\nbi\n93.83\n27\nbi\n93.53\n28\nbi\n89.59\n29\nbi\n92.57\n30\nbi\n95.25\nLooks good. Now we can visualize and analyze the data.\n\n\ndf %>%\n  ggplot(., aes(x = as.numeric(group), y = score)) +\n  scale_x_discrete(limits = c(2, 1), labels = c(\"Bilingual\", \"Monolingual\")) +\n  geom_jitter() +\n  geom_point() +\n  geom_smooth(method = \"lm\") + \n  labs(x = \"Group\", y = \"Score\")\n\n\n\n\nAnd that‚Äôs it.\n\n\n\n",
    "preview": "posts/2015-06-16_google_sheets_in_r/assets/img/data.png",
    "last_modified": "2021-02-20T23:45:42-05:00",
    "input_file": {},
    "preview_width": 967,
    "preview_height": 1575
  },
  {
    "path": "posts/2015-05-18_data_pipelines/",
    "title": "Data pipelines in R",
    "description": "What button do I press to learn the truth?",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2015-05-18",
    "categories": [
      "r",
      "research",
      "workflow"
    ],
    "contents": "\nOverview\nSo you thought up a clever experiment, got IRB approval, recruited participants and collected data‚Ä¶ now what? New researchers are often confronted with an unfortunate surprise when it comes time to perform some kind of analysis on their data: they don‚Äôt know how, or even where to start. This can be a problem for something trivial, like obtaining simple descriptive statistics, or something much more complex, like fitting models, creating plots and making predictions. When we conduct experiments we don‚Äôt usually begin by thinking about how we will analyze our data, and in many academic programs this is not explicitly taught to new students. For most people, especially beginners, the data analysis issue arises later on in the process, usually after the data have already been collected (although I think this ultimately changes with experience).\nIn light of all of this, I think that something handy to learn and evaluate early on is how data analysis typically flows: from obtaining data to obtaining new insight from the data. This is the data analysis pipeline, which usually looks something like this:\n\n\n\n\n\n\nIn essence, the process is simple. After collecting your data, you need to tidy it (step 2) so that it can be loaded and analyzed by your statistical software. After tidying your data, you usually have to transform it (step 3) in some way (also called data preprocessing). This can be occur via the creation of new variables, combining variables, sub-setting variables, etc. Once you have transformed your data, it‚Äôs time to visualize it (step 4a) via graphs/plots, and, finally, analyze it. In exploratory data analysis the visualization and analysis steps are often iterative: you might notice something in a graph that leads you to a new analysis, or some kind of insight that requires more data transformation and a new analysis, and so on and so forth until you have obtained new insight that might lead you to generate new research question(s).\nSo, at the heart of data analysis is tidy data. Most new researchers don‚Äôt know what it means to tidy and transform their data, nor that it is probably the most important part of any data analysis. Basically, if your data are not formatted in a way in which they can be easily analyzed (via excel, SPSS, R, etc.), then you can‚Äôt do anything with them.\nIn order to facilitate the data analysis pipeline, it is crucial to have tidy data. What this means is that every column in your data frame represents a variable and every row represents an observation. This is also referred to as long format (as opposed to wide format). Most statistical software requires your data to be in long format, with few exceptions (i.e.¬†repeated measures ANOVA in SPSS).\nIn what follows, I take you through three packages that have been created in order to facilitate the data analysis pipeline in R. Each package was created by Hadley Wickham with steps 2, 3, and 4a of the pipeline in mind. Thus we can associate each package with the corresponding step:\n\n\n\n\ntidyr\ndplyr\nbasic plotting in r / ggvis\n(coming soon)\n\n\n\n",
    "preview": "posts/2015-05-18_data_pipelines/assets/img/pipeline1.png",
    "last_modified": "2021-02-20T23:41:07-05:00",
    "input_file": {},
    "preview_width": 16298,
    "preview_height": 3862
  },
  {
    "path": "posts/2015-04-20_plotting_in_r/",
    "title": "Basic plotting in R",
    "description": "Step-by-step examples for using the three main plotting systems in R.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2015-04-20",
    "categories": [
      "r",
      "dataviz"
    ],
    "contents": "\n\n\n\n\n\n\n",
    "preview": "posts/2015-04-20_plotting_in_r/featured.png",
    "last_modified": "2021-02-20T23:43:19-05:00",
    "input_file": {},
    "preview_width": 469,
    "preview_height": 348
  },
  {
    "path": "posts/2015-04-13_html_widgets/",
    "title": "HTML widgets in Rmarkdown",
    "description": "Walkthrough for incorporating HTML widgets into an Rmarkdown document.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2015-04-13",
    "categories": [
      "r",
      "rmarkdown",
      "html"
    ],
    "contents": "\n\n\n\n\n\n\n",
    "preview": "posts/2015-04-13_html_widgets/featured.png",
    "last_modified": "2021-02-20T23:48:17-05:00",
    "input_file": {},
    "preview_width": 404,
    "preview_height": 314
  },
  {
    "path": "posts/2015-03-22_slidify_tutorial/",
    "title": "Slidify tutorial",
    "description": "Tutorial for creating HTML presentations using R and slidify.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2015-03-22",
    "categories": [
      "r",
      "rmarkdown",
      "html"
    ],
    "contents": "\n\n\n\n\n\n\n",
    "preview": "posts/2015-03-22_slidify_tutorial/featured.png",
    "last_modified": "2021-02-20T23:52:02-05:00",
    "input_file": {},
    "preview_width": 412,
    "preview_height": 310
  },
  {
    "path": "posts/2014-05-28_tikz_-_standalone_plots/",
    "title": "TikzDevice tutorial III: standalone plots",
    "description": "Quick and dirty test for knitr boostrap framework.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2014-05-28",
    "categories": [
      "ipa",
      "r",
      "research",
      "latex"
    ],
    "contents": "\nIn this post I‚Äôm going to show you how to use tikzDevice to create high quality plots that use the same font as your \\(\\LaTeX\\) document. I‚Äôm assuming that you have already installed tikz. If not, see part I in this series. Moreover, this tutorial assumes that you have set up your project in the same way outlined in part II. An added benefit to this approach is that it allows you to insert IPA symbols into the plot via the tipa package.\nThe LaTeX file\nOk. You should start with a \\(\\LaTeX\\) file that looks like this:\n\\documentclass{article}\n\\usepackage{tikz}\n\\usepackage{tipa}\n\n\\begin{document}\n\n<<>>=\nrequire(tikzDevice)\ntikz('plot.tex', standAlone=TRUE)\nlibrary(stats)\nplot(cars)\nlines(lowess(cars))\ndev.off()\n@\n\n\\end{document}\nIf you have experience working with \\(\\LaTeX\\), the preamble should be pretty straightforward (If you need a quick primer on \\(\\LaTeX\\), see this tutorial). The important part so far is that you have to include \\usepackage{tikz} and \\usepackage{tipa} before \\begin{document}.\nThe R code\nIn knitr, R code goes between <<>>= and ends with @. So all of this is R code:\n\n\nrequire(tikzDevice)\ntikz('plots/cars-plot.tex', standAlone=TRUE)\nlibrary(stats)\nplot(cars)\nlines(lowess(cars))\ndev.off()\n\n\n\nThe command require(tikzDevice) loads tikz into the R workspace. Then, tikz('plots/cars-plot.tex', standAlone=TRUE) calls the tikz device and creates the file cars-plot.tex in the folder plots. It is important to set standAlone to TRUE if you want to have a separate .tex file (this is what allows us to keep the fonts the same as the rest of the document). From this point on until the call dev.off(), we enter what we want to appear in our .tex file. In this case I have plotted the typical cars data from the library stats. Here is the PDF output produced when cars-plot.tex is compiled. Notice the font is different from what you typical get in R.\n\nNow let‚Äôs try something a little more involved and add some IPA. I will use a fake dataset and load it into R.\n\n\nmy_data <- read.delim(\"assets/my_data.txt\")\n\n\n\nWe will use ggplot2 for this plot.\n\n\nlibrary(ggplot2)\n\n\n\nNow we will call tikz device.\n\n\nrequire(tikzDevice)\noptions(tikzLatexPackages = c(getOption(\"tikzLatexPackages\"), \"\\\\usepackage{tipa}\"))\ntikz('plots/ipa_plot.tex', standAlone=TRUE, width=10, height=6)\nmy_data$group <- factor(my_data$group, levels = c(\"EL\", \"NE\", \"LL\"))\ndf<-with(my_data, aggregate(fpro, list(group=group, fstim=fstim), mean))\ndf$se<-with(my_data, aggregate(fpro, list(group=group, fstim=fstim), function(x) sd(x)/sqrt(10)))[,3]\ngp <- ggplot(df, aes(x=fstim, y=x, colour=group, ymin=x-se, ymax=x+se))\ngp + geom_line(aes(linetype=group), size = .5) + \n    geom_point(aes(shape=group)) + \n    geom_ribbon(alpha = 0.15, linetype=0) + \n    ylim(0, 1) + \n    scale_x_continuous(breaks=seq(0, 10, by=1)) +\n    labs(list(title = \"[\\\\textesh ip/\\\\textesh\\\\textsci p]\", \n            x = \"Stimuli\", y = \"\\\\% [\\\\textesh\\\\textsci p]\")) +\n    theme_bw() +\n    theme(legend.background = element_rect(colour = 'grey50', \n        fill = 'grey97', size = .75, linetype='solid')) +\n    scale_linetype_discrete(\"Group\") +\n    scale_shape_discrete(\"Group\") +\n    scale_colour_discrete(\"Group\")\ndev.off()\n\n\n\nNotice that after the require(tikzDevice) call, we included\n\n\noptions(tikzLatexPackages = c(getOption(\"tikzLatexPackages\"), \"\\\\usepackage{tipa}\")) \n\n\n\nThe key component here is \\\\usepackage{tipa}. This means that tipa will be included in the .tex produced from the code, which, in turn, means that we can include IPA sybols in the plot before it is produced. The tikz('plots/ipa_plot.tex', standAlone=TRUE, width=5, height=5) call creates ipa_plot.tex in the folder plots. The rest of the code (up to dev.off()) is the actual plot. Notice that we have included ipa in the following command:\n\n\nlabs(list(title = \"[\\\\textesh ip/\\\\textesh\\\\textsci p]\", \n          x = \"Stimuli\", y = \"\\\\% [\\\\textesh\\\\textsci p]\"))\n\n\n\nThis is the plot that is produced when the resulting .tex file is compiled:\n\n\n\nAnd that‚Äôs it. We have produced a beautiful plot that uses the same font as our document and includes IPA symbols. You can download all the files here and try it yourself.\n\n\n\n",
    "preview": "posts/2014-05-28_tikz_-_standalone_plots/assets/img/ipa_plot.png",
    "last_modified": "2021-02-20T23:53:48-05:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 864
  },
  {
    "path": "posts/2014-05-26_knitr_bootstrap/",
    "title": "Knitr bootstrap",
    "description": "Quick and dirty test for knitr boostrap framework.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2014-05-26",
    "categories": [],
    "contents": "\nKnitr bootstrap makes generating standalone reports extremely easy and the output looks really neat. Check out the example here. To recreate this you need to download the preview release of R Studio, and set up the front matter as follows:\n---\noutput:\n  knitrBootstrap::bootstrap_document:\n    title: \"\"\n    theme: default\n    highlight: sunburst\n    theme.chooser: TRUE\n    highlight.chooser: TRUE\n---\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-20T15:43:48-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2014-01-07_converting_rmarkdown_files_to_html5/",
    "title": "Using Rmarkdown to knit HTML5 documents in RStudio",
    "description": "Some simple examples of how to go from .Rmd to .html.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2014-01-07",
    "categories": [],
    "contents": "\nHTML5 slides\nI recently learned how to create HTML5 slides using .Rmd files and pandoc. Click here to check out an example. I will be posting a tutorial on how to do this in the near future (I hope).\nUpdate Here is a much cooler example I found on mages‚Äô blog\nUpdate 2 This process has been streamlined in the newest update to RStudio (check it out here). The results are quite impressive (Ex. 1, Ex. 2)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-20T15:35:20-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-05-17_tikz_-_projects/",
    "title": "TikzDevice tutorial II: structuring a project",
    "description": "How to setup a reproducible workflow that integrates `tikzDevice`.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2013-05-17",
    "categories": [
      "r",
      "latex",
      "tikz"
    ],
    "contents": "\nOverview\nThis mini tutorial is part II about incorporating tikzDevice into your workflow. It explains the file structure necessary to successfully include tikzDevice plots into your \\(\\LaTeX\\) document. You must first have tikzDevice installed. If you don‚Äôt, see part I for more information.\nThe structure\nA simple yet effective way to do reproducible research is to use R (for statistical analysis) directly in a \\(\\LaTeX\\) environment. There are two ways to accomplish this: (1) Sweave and (2) knitr. knitr seems to be the better choice, as it builds on some of the deficiencies of Sweave, and is what I am currently using in my workflow. In order to successfully ‚Äúknit‚Äù R code into a .tex format we must use a no-web (.nw) file to create the .tex file. There are two types of no-web files: .Rnw and .Snw. I am not completely sure what the differences are between then, but I use .Rnw and that is what I will mention in this tutorial.\nThe first step is to create a project folder. For the purposes of this tutorial let‚Äôs call this folder ‚Äúmaster‚Äù. Next, we will need some data and some R code that analyzes it. The most common, no-hassle way to accomplish this in R is to save your R code in a separate .R file. For this tutorial, we will call our data ‚Äúmy-data.txt‚Äù and our R code ‚Äúexample.R‚Äù. The fake data we are going to analyze is for a two-alternative forced choice identification experiment. So, our fake data is in the ‚Äúmy-data.txt‚Äù file and the R code that analyzes it is in the example.R file.\nThe next step is to create the ‚Äúno web‚Äù .Rnw file. This is as simple as creating a document in your text editor of choice (I use TextMate 2 and Sublime Text 3) and saving it with a .Rnw extension. For this tutorial we will call this file ‚Äúexample.Rnw‚Äù. Its purpose is to call the R code written in ‚Äúexample.R‚Äù (which uses the fake data in ‚Äúmy-data.txt‚Äù) in order to produce a .tex file (in this case ‚Äúexample.tex‚Äù). Still with me? Good.\nNext we need to prepare where we are going to keep the plots produced by tikzDevice. I find it most convenient to have a specific folder, ‚Äúplots_folder‚Äù, where I only keep the tikzDevice plots. So, create this folder inside the ‚Äúmaster‚Äù folder. tikzDevice creates the R plots and converts them to a \\(\\LaTeX\\) format (the benefits of this are further explained in part III of this tutorial), saves them in ‚Äúplots_folder‚Äù and we will then include them in the example.tex file which can be compiled into a PDF. The image below shows what this should look like when it‚Äôs all said and done.\n\n\n\nCheck out part III to learn how to create standalone plots that can include IPA sybols.\n\n\n\n",
    "preview": "posts/2013-05-17_tikz_-_projects/assets/img/tikz_workflow.png",
    "last_modified": "2021-02-20T23:56:07-05:00",
    "input_file": {},
    "preview_width": 2330,
    "preview_height": 880
  },
  {
    "path": "posts/2013-05-11_tikz_-_installation/",
    "title": "TikzDevice tutorial I: install tikzDevice in R",
    "description": "How to install tikzDevice for plotting in R.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2013-05-11",
    "categories": [],
    "contents": "\nOverview\nThis is a short tutorial for getting tikzDevice running on R version 3.0. If you write in LaTeX and use R for statistics, this is a good way to get your plots/graphs/etc. into your .tex document. The advantages are:\nmuch higher quality and\nyou can use IPA symbols\nDownload tiksDevice\ntiksDevice is no longer officially supported by CRAN because the author was having trouble keeping it updated in a timely manner (check out this webpage if you want to read a little more it). Nonetheless, the tikzdevice package is very usable and still available for download. You can download the tar.gz file directly by clicking here.\nInstall tiksDevice\nInstalling a package that is no longer supported is by no means difficult, but not as simple as install.package('tikzDevice') (try it if you want to see why). Use the following code install the tar file (make sure to specify your file path to wherever you downloaded the file). This is what it looked like for me.\n\n\ninstall.packages(\"/Users/USERNAME/Downloads/tikzDevice_0.6.2.tar\", \n  repos = NULL, type = \"source\")\n\n\n\nInstall dependencies\nIn order for tikzDevice to work, you must also install the filehash package. This is much easier.\n\n\ninstall.packages('filehash')\n\n\n\nThat‚Äôs it. Check out this tutorial to see how to set up a project.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-20T15:21:30-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-05-09_colored_spectrograms_in_r/",
    "title": "Colored spectrograms in R",
    "description": "How to make colored spectrograms in R with phonTools.",
    "author": [
      {
        "name": "Joseph V. Casillas",
        "url": "https://www.jvcasillas.com"
      }
    ],
    "date": "2013-05-05",
    "categories": [
      "r",
      "phonetics",
      "acoustics"
    ],
    "contents": "\nThis is how I made the colored spectrogram from the homepage (it‚Äôs me saying ‚Äòwelcome‚Äô). You need to load the package phonTools into R.\n\n\nlibrary(phonTools)\n\n\n\nNow you have to load the sound you want to make a spectrogram of (it has to be in your working directory). I recorded mine in Praat.\n\n\nsound <- loadsound('welcome.wav')\n\n\n\nNow we‚Äôre ready to make a spectrogram.\n\n\nspectrogram(sound, fs = 44100, colors = TRUE, \n            maintitle = \"Welcome\", maxfreq = 5500)\n\n\n\n\n\n\nWe can also see the oscillogram by using\n\n\nplot(sound)\n\n\n\n\n\n\nThat‚Äôs it.\n\n\n\n",
    "preview": "posts/2013-05-09_colored_spectrograms_in_r/assets/img/spectrogram.png",
    "last_modified": "2021-02-20T23:57:54-05:00",
    "input_file": {},
    "preview_width": 593,
    "preview_height": 308
  }
]
